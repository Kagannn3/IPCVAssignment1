{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNBgGYg_lpVN"
      },
      "source": [
        "# **Product Recognition of Food Products**\n",
        "\n",
        "## Image Processing and Computer Vision - Assignment Module \\#1\n",
        "\n",
        "\n",
        "Contacts:\n",
        "\n",
        "- Prof. Giuseppe Lisanti -> giuseppe.lisanti@unibo.it\n",
        "- Prof. Samuele Salti -> samuele.salti@unibo.it\n",
        "- Alex Costanzino -> alex.costanzino@unibo.it\n",
        "- Francesco Ballerini -> francesco.ballerini4@unibo.it\n",
        "\n",
        "\n",
        "Computer vision-based object detection techniques can be applied in super market settings to build a system that can identify products on store shelves.\n",
        "An example of how this system could be used would be to assist visually impaired customers or automate common store management tasks like detecting low-stock or misplaced products, given an image of a shelf in a store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW42NlZsyTv0"
      },
      "source": [
        "## Task\n",
        "Develop a computer vision system that, given a reference image for each product, is able to identify such product from one picture of a store shelf.\n",
        "\n",
        "<figure>\n",
        "<a href=\"https://imgbb.com/\">\n",
        "  <center>\n",
        "  <img src=\"https://i.ibb.co/TwkMWnH/Screenshot-2024-04-04-at-14-54-51.png\" alt=\"Screenshot-2024-04-04-at-14-54-51\" border=\"0\" width=\"300\" />\n",
        "</a>\n",
        "</figure>\n",
        "\n",
        "For each type of product displayed in the\n",
        "shelf the system should report:\n",
        "1. Number of instances;\n",
        "1. Dimension of each instance (width and height in pixel of the bounding box that enclose them);\n",
        "1. Position in the image reference system of each instance (center of the bounding box that enclose them).\n",
        "\n",
        "#### Example of expected output\n",
        "```\n",
        "Product 0 - 2 instance found:\n",
        "  Instance 1 {position: (256, 328), width: 57px, height: 80px}\n",
        "  Instance 2 {position: (311, 328), width: 57px, height: 80px}\n",
        "Product 1 – 1 instance found:\n",
        ".\n",
        ".\n",
        ".\n",
        "```\n",
        "\n",
        "### Track A - Single Instance Detection\n",
        "Develop an object detection system to identify single instance of products given one reference image for each item and a scene image.\n",
        "\n",
        "The system should be able to correctly identify all the product in the shelves\n",
        "image.\n",
        "\n",
        "### Track B - Multiple Instances Detection\n",
        "In addition to what achieved at step A, the system should also be able to detect multiple instances of the same product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fIbZJKq16ba"
      },
      "source": [
        "## Data\n",
        "Two folders of images are provided:\n",
        "* **Models**: contains one reference image for each product that the system should be able to identify.\n",
        "* **Scenes**: contains different shelve pictures to test the developed algorithm in different scenarios. The images contained in this folder are corrupted by noise.\n",
        "\n",
        "#### Track A - Single Instance Detection\n",
        "* **Models**: {ref1.png to ref14.png}.\n",
        "* **Scenes**: {scene1.png to scene5.png}.\n",
        "\n",
        "#### Track B - Multiple Instances Detection\n",
        "* **Models**: {ref15.png to ref27.png}.\n",
        "* **Scenes**: {scene6.png to scene12.png}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjP3GCdujYlw",
        "outputId": "97a71b97-dee9-4de1-aff9-91b14924fa3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Classroom\t 'Oğuz Kağan Koçak Gantt Chart.gsheet'\t\t\t'Task 3.1.1.gdoc'\n",
            " ColabNotebooks  'Oğuz Kağan Koçak Task 1.2.1.gsheet'\n",
            " dataset.zip\t 'PROJECT DOCUMENTATION AND ROADMAP FOR TASK 4.1.gdoc'\n",
            "Archive:  dataset.zip\n",
            "replace __MACOSX/._dataset? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "#imports drive library from the module of the google.colab\n",
        "# drive library represents some functions for working with Google Drive in a Google Colab Notebook\n",
        "drive.mount('/content/drive',force_remount=True)   # mounts the Google Drive to the Google Colab runtime virtual file system\n",
        "# That mounting creates a link between Google Drive and Google Colab environment\n",
        "# Therefore, we can access the files which are stored in the Google Drive directly from Google Colab environment\n",
        "\n",
        "!ls /content/drive/MyDrive/  # running that command will display a list of files and directories in the specified directory\n",
        "!cp -r /content/drive/MyDrive/dataset.zip ./\n",
        "# '/content/drive' represents the point of the mount that is a directory path in the Google Colab runtime\n",
        "# thus, we can access to the some data of the Google Drive under the '/content/drive' directory\n",
        "\n",
        "#'!cp -r' command copies the file 'dataset.zip' from the specified Google Drive location\n",
        "#to the current working directory(represented by './')\n",
        "# '-r' indicates that to copy the entire directory sturcture if 'dataset.zip' is a folder. Otherwise it is ignored\n",
        "\n",
        "!unzip dataset.zip\n",
        "#unzips the 'dataset.zip' file which was copied to the current working directory\n",
        "# this assumes the unzip tool is suitable on the Google Colab runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KRBeGbKsEDe"
      },
      "source": [
        "## Evaluation criteria\n",
        "1. **Procedural correctness**. There are several ways to solve the assignment. Design your own sound approach and justify every decision you make;\n",
        "\n",
        "2. **Clarity and conciseness**. Present your work in a readable way: format your code and comment every important step;\n",
        "\n",
        "3. **Correctness of results**. Try to solve as many instances as possible. You should be able to solve all the instances of the assignment, however, a thoroughly justified and sound procedure with a lower number of solved instances will be valued **more** than a poorly designed approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o9O3Cj7cuXX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fb81d8-3eec-4d9e-ffa4-a8f16c15733b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXmwWG3tBDLZ"
      },
      "outputs": [],
      "source": [
        "import cv2 # imports the OpenCV library, that is a computer vision library used for many tasks of image processing\n",
        "import numpy as np # imports the NumPy library, that is used for numerical computations\n",
        "import matplotlib.pyplot as plt # imports the pyplot module from the matplotlib library for using visualizations and plotting\n",
        "from google.colab.patches import cv2_imshow # that function is used to display the original image from the corresponding numpy array\n",
        "\n",
        "\n",
        "#last part, we copied the dataset.zip file to the current working directory(/content), then unzipped that file\n",
        "# therefore, we write the correct path to read the 'ref1.png' image\n",
        "image = cv2.imread('dataset/models/ref1.png') # reads an image file named 'fruit_image.jpg' from the current directory using OpenCV's imread() function\n",
        "# the image is loaded as a NumPy array\n",
        "# this image has BGR format in its numpy array\n",
        "\n",
        "print(image[360])\n",
        "# if the BGR or RGB values are very close to each other, the corresponding color converges to the white color\n",
        "# there are some historical reasons for the adoption of BGR in computer vision and image processing\n",
        "# Actually, RGB is more intutive for perception of human and suitable with in web development and graphic design\n",
        "\n",
        "\n",
        "\n",
        "print(\"=======================================================\")\n",
        "resized_image = cv2.resize(image, (300,300)) # resizes the original image to a new size of 300x300 pixels using OpenCV's resize() function\n",
        "# the resized image is stored in the 'resized_image' variable\n",
        "# there are more than 1 interpolation methods for resizing function in OpenCV library\n",
        "# the method is 'cv2.INTER_LINEAR', which corresponds to bilinear interpolation.\n",
        "# that interpolation computes the new pixel value based on a weighted average of the 4 nearest pixels in the input image\n",
        "# that method is efficient for resizing images\n",
        "\n",
        "plt.imshow(cv2. cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "# displays image using Matplotlib's 'imshow()' function\n",
        "# the image's color channels are converted from BGR(default format used by OpenCV) to RGB with cv2.cvtColor()\n",
        "# Matplotlib expects images in RGB format\n",
        "\n",
        "\n",
        "\n",
        "plt.axis('off') # turns off the axis in the plot, removing the axis labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "normalized_image = resized_image.astype(np.float32) / 255.0\n",
        "# normalizes the pixel values of the resized image to the range [0,1]\n",
        "# the image is translated to type float32 of NumPy array by astype() function\n",
        "# each pixel value is divided by 255.0 to scale them down to the [0,1] range\n",
        "\n",
        "print(\"Original image: \")\n",
        "cv2_imshow(image) # displaying the original image from the corresponding numpy array\n",
        "\n",
        "print('Resized and normalized image: ')\n",
        "#cv2_imshow(normalized_image)\n",
        "\n",
        "# normalized_image is a BGR format with numpy arrays, therfore, first, we should convert it to the RGB format, then, corresponding image format to display\n",
        "plt.imshow(cv2.cvtColor(normalized_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# plt.imshow() function is to display the image\n",
        "# cv2.cvtColor() function convert the BGR format image to RGB format image because RGB format is necessary for the plt.imshow() function\n",
        "\n",
        "cv2.waitKey(0) # wait indefinetly until a key is pressed\n",
        "cv2.destroyAllWindows() #close all windows of OpenCV when the program has finished executing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgVKopehwHZH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ImageDataGenerator library is for image augmentation\n",
        "# cv2 library is for reading and preprocessing images\n",
        "# numpy library is for numerical operations\n",
        "# matplotlib.pyplot library is for plotting images\n",
        "\n",
        "\n",
        "generateData= ImageDataGenerator( #creating ImageDataGenerator object named 'generateData' various augmentation parameters\n",
        "\n",
        "    rotation_range = 15, # randomly rotation of images by up to 15 degrees\n",
        "    brightness_range = (0.7,1.2), # randomly set brightness  between 0.7 and 1.2\n",
        "    height_shift_range = 0.15, # randomly shift images vertically by up to %15 of the image height\n",
        "    width_shift_range = 0.15, # randomly shift images horizontally by up to %15 of the image width\n",
        "    horizontal_flip = True # randomly flip images horizontally\n",
        "# all of these parameters decide on if their values of rotation, brightness, height shift, width shift ranges change for the each images in the dataset\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q-KoXINEZ_d"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.imread('dataset/models/ref1.png')\n",
        " # this imread function convert the image to corresponding numpy array according to BGR order\n",
        "\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        " # image2 numpy array with BGR format is converted to the RGB format by using cvtColor function from the cv2 library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKBSa-Qo1tmS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image2 = np.expand_dims(image2, axis=0)\n",
        "\n",
        "# let's assume that, we have RGB image with (height, width, channels) = (200, 300, 3)\n",
        "# channels means that, different components of color information in the each pixel of the image (Red, Green, Blue)\n",
        "# np.expand_dims(image2, axis=0) means that, resulting array will have dimensions which are (sizeOfBatch, height, width, channels) = (1, 200, 300, 3)\n",
        "# where the sizeOfBatch = 1, indicates that, there is only 1 image in the batch\n",
        "# flow() function of ImageDataGenerator expects input in that format\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bamp5O8F8I9"
      },
      "outputs": [],
      "source": [
        "imagesAugmented = generateData.flow(image2)\n",
        "# generating augmented images using the function of flow which is the function of the generateData object\n",
        "# steps parameter means that, number of the total batches of the images before stopping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFCvUBTFBBsw"
      },
      "outputs": [],
      "source": [
        "figure, gridOfSubplots = plt.subplots(1,4, figsize=(20, 5))\n",
        "\n",
        "# subplots function creates a figure and grid of subplots with 4 columns and 1 row\n",
        "# figsize=(20,5) parameter determines the each figure's size, where the height is 5, width is 20 inches\n",
        "\n",
        "type(imagesAugmented.next()[0])\n",
        "\n",
        "for i in range(4):  # iterating over 4 times to display images which are augmented\n",
        "# 4 is the batch size (number of images to display)\n",
        "\n",
        "\n",
        "  each_imageAugmented = imagesAugmented.next()[0].astype(np.uint8)\n",
        "\n",
        "  # imagesAugmented.next() generates the next augmented images's batch\n",
        "  # in each call of next function, will return the next augmented image (batch)\n",
        "  # [0] is for selecting the first element of the augmented images(batch)\n",
        "  # at the same time, each batch contains both images and corresponding labels\n",
        "  # astype(np.uint8) converts the image's pixel values to unsigned 8 bit integers because that is the standard format for displaying image\n",
        "  # if the image was loaded using cv2.imread() function, the pixel values are represented as unsigned 8 bit integers\n",
        "\n",
        "  # cv2.imread() function reads images as BGR(blue, green, red) format and stores these pixel values as unsigned 8 bit integers\n",
        "\n",
        "  gridOfSubplots[i].imshow(each_imageAugmented)\n",
        "  # displays the batch(augmented image) on the th of  \"i\" subplot\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEiNN9D86weM"
      },
      "outputs": [],
      "source": [
        "!pwd # printing the current working directory (content) in Google Colab\n",
        "\n",
        "!ls # to list the contents of the directory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXl-6v0hi7hf"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/ColabNotebooks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/assignment_module_one.ipynb /content/IPCVAssignment1\n",
        "# to copy the assignment_module_one.ipynb file from the corresponding path to the /content/IPCVAssignment1 directory"
      ],
      "metadata": {
        "id": "zdVKsd27g2_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/IPCVAssignment1/ #to list the contents"
      ],
      "metadata": {
        "id": "PWWjQWhnhj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    
    
    
    
    
    
    
    
    
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
