{"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7391de2c8cd74cf4926965845e9fed5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c6ed142a9a84a25a79130c1c4b36aaa","IPY_MODEL_1c7f75b6754a4816961c65ea76e6368e","IPY_MODEL_4321149fa4db4cf8a4273d27b492e499"],"layout":"IPY_MODEL_b6ae5d93eee346aeae217dd8721b0998"}},"9c6ed142a9a84a25a79130c1c4b36aaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b8080aef9a0413ea8d1f39245c1d35e","placeholder":"​","style":"IPY_MODEL_f50365a5670642eba65844a398822e12","value":"  0%"}},"1c7f75b6754a4816961c65ea76e6368e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d44984a06f0489aa2f5cf44ec94d112","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73ea5c6898134be292c9559afc8201bd","value":0}},"4321149fa4db4cf8a4273d27b492e499":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6daa25dc2c0241d88866c7e9f1fd3968","placeholder":"​","style":"IPY_MODEL_1093b31ac743463a8d09fc710233e45e","value":" 0/30 [00:04&lt;?, ?it/s]"}},"b6ae5d93eee346aeae217dd8721b0998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b8080aef9a0413ea8d1f39245c1d35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50365a5670642eba65844a398822e12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d44984a06f0489aa2f5cf44ec94d112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ea5c6898134be292c9559afc8201bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6daa25dc2c0241d88866c7e9f1fd3968":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1093b31ac743463a8d09fc710233e45e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b30a7a67a894cffaa069bf252ccd513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40c7957c4c7744bc8a3a576f0bf6cae3","IPY_MODEL_0ab5b022aa5a419481a0e99ed82ef986","IPY_MODEL_3119d29894d54b219d400a82f1c7040a"],"layout":"IPY_MODEL_3f145d6039234d51ad1b12a7598c31ed"}},"40c7957c4c7744bc8a3a576f0bf6cae3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fcf225e3f414285bb25e16d8565f4ab","placeholder":"​","style":"IPY_MODEL_e7bb5d3b6b364c39894e73eee97affe0","value":"100%"}},"0ab5b022aa5a419481a0e99ed82ef986":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_084d0b5e95cf4f508fedb093a9cace90","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_708edf09837642f58a4feaa64500ed66","value":20}},"3119d29894d54b219d400a82f1c7040a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_668adb5e9fb645088bc2a794ba2218ce","placeholder":"​","style":"IPY_MODEL_f8ddad473d2b4a66b3b16e4979fc31a9","value":" 20/20 [02:50&lt;00:00,  8.37s/it]"}},"3f145d6039234d51ad1b12a7598c31ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fcf225e3f414285bb25e16d8565f4ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7bb5d3b6b364c39894e73eee97affe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"084d0b5e95cf4f508fedb093a9cace90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708edf09837642f58a4feaa64500ed66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"668adb5e9fb645088bc2a794ba2218ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8ddad473d2b4a66b3b16e4979fc31a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c0341b996374df6b2ec05c8dac7a9b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_261d3c9cb1b142ebbff2e3d0098ad599","IPY_MODEL_de034decd79643eda084b3e563e2c1b9","IPY_MODEL_95ec778bedfb445487d331eda0258ff2"],"layout":"IPY_MODEL_f04623277a3043e892c87a9d5833b792"}},"261d3c9cb1b142ebbff2e3d0098ad599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0619950dfc8441a08c3d501226374cee","placeholder":"​","style":"IPY_MODEL_ad7fa10fa9f342e1adfe9a9ee29da91d","value":"100%"}},"de034decd79643eda084b3e563e2c1b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3db436601d4c7ba7a8f98441d17bb3","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4884041d23241fc98ab49a7f1ae0d7b","value":40}},"95ec778bedfb445487d331eda0258ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3041c773cfd344f39ab8e3c0eb917fe2","placeholder":"​","style":"IPY_MODEL_1cf3e14913e74958a1b5d0453a3a8be6","value":" 40/40 [05:53&lt;00:00,  8.80s/it]"}},"f04623277a3043e892c87a9d5833b792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0619950dfc8441a08c3d501226374cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7fa10fa9f342e1adfe9a9ee29da91d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb3db436601d4c7ba7a8f98441d17bb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4884041d23241fc98ab49a7f1ae0d7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3041c773cfd344f39ab8e3c0eb917fe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cf3e14913e74958a1b5d0453a3a8be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"521788e7ab614c4bb1ec45d9853678db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d18c07c8179043df9447c93111a31dd0","IPY_MODEL_4733ff38e6f54f72a8dca7b6d1d6e1f5","IPY_MODEL_71a09f42d1f34c5faf7c012fbfe5fc1e"],"layout":"IPY_MODEL_f7ded3abfb644ed3aaa967d1bc313eb6"}},"d18c07c8179043df9447c93111a31dd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_febae8e0d3764652bbf57351fbfb5041","placeholder":"​","style":"IPY_MODEL_7b39c4ee962d4b019efe256eb5bc4b42","value":" 82%"}},"4733ff38e6f54f72a8dca7b6d1d6e1f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd9473ac34347508ec6f23534b463b2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d21484dba744589823686ea95ce27f8","value":41}},"71a09f42d1f34c5faf7c012fbfe5fc1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5d0a75de624cc5a80388acd0cafad1","placeholder":"​","style":"IPY_MODEL_84f66999ecb34dd284cbb5b1961e009c","value":" 41/50 [07:47&lt;01:42, 11.43s/it]"}},"f7ded3abfb644ed3aaa967d1bc313eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"febae8e0d3764652bbf57351fbfb5041":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b39c4ee962d4b019efe256eb5bc4b42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cd9473ac34347508ec6f23534b463b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d21484dba744589823686ea95ce27f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a5d0a75de624cc5a80388acd0cafad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f66999ecb34dd284cbb5b1961e009c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment Module 2: Product Classification\n\nThe goal of this assignment is to implement a neural network that classifies smartphone pictures of products found in grocery stores. The assignment will be divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch.\n","metadata":{"id":"MNBgGYg_lpVN"}},{"cell_type":"markdown","source":"## Preliminaries: the dataset\n\nThe dataset you will be using contains natural images of products taken with a smartphone camera in different grocery stores:\n\n<p align=\"center\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Granny-Smith.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Pink-Lady.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Lemon.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Banana.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Vine-Tomato.jpg\" width=\"150\">\n</p>\n<p align=\"center\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Yellow-Onion.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Green-Bell-Pepper.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Arla-Standard-Milk.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Oatly-Natural-Oatghurt.jpg\" width=\"150\">\n  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Alpro-Fresh-Soy-Milk.jpg\" width=\"150\">\n</p>\n\nThe products belong to the following 43 classes:\n```\n0.  Apple\n1.  Avocado\n2.  Banana\n3.  Kiwi\n4.  Lemon\n5.  Lime\n6.  Mango\n7.  Melon\n8.  Nectarine\n9.  Orange\n10. Papaya\n11. Passion-Fruit\n12. Peach\n13. Pear\n14. Pineapple\n15. Plum\n16. Pomegranate\n17. Red-Grapefruit\n18. Satsumas\n19. Juice\n20. Milk\n21. Oatghurt\n22. Oat-Milk\n23. Sour-Cream\n24. Sour-Milk\n25. Soyghurt\n26. Soy-Milk\n27. Yoghurt\n28. Asparagus\n29. Aubergine\n30. Cabbage\n31. Carrots\n32. Cucumber\n33. Garlic\n34. Ginger\n35. Leek\n36. Mushroom\n37. Onion\n38. Pepper\n39. Potato\n40. Red-Beet\n41. Tomato\n42. Zucchini\n```\n\nThe dataset is split into training (`train`), validation (`val`), and test (`test`) set.","metadata":{"id":"dVTQUJ4uYH1w"}},{"cell_type":"markdown","source":"The following code cells download the dataset and define a `torch.utils.data.Dataset` class to access it. This `Dataset` class will be the starting point of your assignment: use it in your own code and build everything else around it.","metadata":{"id":"1pdrmJRnJPd8"}},{"cell_type":"code","source":"!git clone https://github.com/marcusklasson/GroceryStoreDataset.git","metadata":{"id":"POMX_3x-_bZI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fca1c913-e28d-4d56-8973-197218d7cd04","execution":{"iopub.status.busy":"2024-07-05T07:22:30.325458Z","iopub.execute_input":"2024-07-05T07:22:30.326297Z","iopub.status.idle":"2024-07-05T07:22:41.562449Z","shell.execute_reply.started":"2024-07-05T07:22:30.326262Z","shell.execute_reply":"2024-07-05T07:22:41.561429Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'GroceryStoreDataset'...\nremote: Enumerating objects: 6559, done.\u001b[K\nremote: Counting objects: 100% (266/266), done.\u001b[K\nremote: Compressing objects: 100% (231/231), done.\u001b[K\nremote: Total 6559 (delta 45), reused 35 (delta 35), pack-reused 6293\u001b[K\nReceiving objects: 100% (6559/6559), 116.26 MiB | 14.62 MiB/s, done.\nResolving deltas: 100% (275/275), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"from pathlib import Path\nfrom PIL import Image\nfrom typing import List, Tuple\n\nimport torch\nfrom torch import Tensor,device\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torchvision\n\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport random\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f\"Device: {device}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4bU2LAr_LPh","outputId":"367bc232-77af-470b-9bf6-73864b6d9201","execution":{"iopub.status.busy":"2024-07-05T07:23:15.952594Z","iopub.execute_input":"2024-07-05T07:23:15.953214Z","iopub.status.idle":"2024-07-05T07:23:16.007086Z","shell.execute_reply.started":"2024-07-05T07:23:15.953182Z","shell.execute_reply":"2024-07-05T07:23:16.005871Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def fix_random(seed: int) -> None:\n    \"\"\"Fix all the possible sources of randomness.\n\n    Args:\n        seed: the seed to use.\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nfix_random(42)","metadata":{"id":"yWGsm5z5qos9","execution":{"iopub.status.busy":"2024-07-05T07:23:18.766544Z","iopub.execute_input":"2024-07-05T07:23:18.767466Z","iopub.status.idle":"2024-07-05T07:23:18.775766Z","shell.execute_reply.started":"2024-07-05T07:23:18.767432Z","shell.execute_reply":"2024-07-05T07:23:18.774886Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class GroceryStoreDataset(Dataset):\n\n    def __init__(self, split: str, transform=None) -> None:\n        super().__init__()\n\n        self.root = Path(\"GroceryStoreDataset/dataset\")\n        self.split = split\n        self.paths, self.labels = self.read_file()\n\n        self.transform = transform\n\n    def __len__(self) -> int:\n        return len(self.labels)\n\n    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n        img = Image.open(self.root / self.paths[idx])\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n    def read_file(self) -> Tuple[List[str], List[int]]:\n        paths = []\n        labels = []\n\n        with open(self.root / f\"{self.split}.txt\") as f:\n            for line in f:\n                # path, fine-grained class, coarse-grained class\n                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n                paths.append(path), labels.append(int(label))\n\n        return paths, labels\n\n    def get_num_classes(self) -> int:\n        return max(self.labels) + 1","metadata":{"id":"jROSO2qVDxdD","execution":{"iopub.status.busy":"2024-07-05T07:23:22.073366Z","iopub.execute_input":"2024-07-05T07:23:22.074174Z","iopub.status.idle":"2024-07-05T07:23:22.083525Z","shell.execute_reply.started":"2024-07-05T07:23:22.074143Z","shell.execute_reply":"2024-07-05T07:23:22.082533Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor()\n])\ntrain_dataset = GroceryStoreDataset(split='train',transform=transform)\nval_dataset = GroceryStoreDataset(split='val',transform=transform)\ntest_dataset = GroceryStoreDataset(split='test',transform=transform)\ntrain_dataset.__len__(),val_dataset.__len__(),test_dataset.__len__()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNnuPzhOzj0s","outputId":"cea2b931-e4d8-4b3b-ba87-674d7df3ab3d","execution":{"iopub.status.busy":"2024-07-05T07:23:25.398021Z","iopub.execute_input":"2024-07-05T07:23:25.398627Z","iopub.status.idle":"2024-07-05T07:23:25.414149Z","shell.execute_reply.started":"2024-07-05T07:23:25.398597Z","shell.execute_reply":"2024-07-05T07:23:25.413306Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2640, 296, 2485)"},"metadata":{}}]},{"cell_type":"code","source":"def check_image_shapes(dataset):\n    for i in range(dataset.__len__()):\n        img, label = dataset[i]\n        w, h = 0,0\n        #print(f\"Image {i} shape: {img.shape} (width, height)\")\n        if img.shape[1] > w:\n          w = img.shape[1]\n        if img.shape[2] > h:\n          h = img.shape[2]\n    return w,h\n# Check shapes of the first few images\nw_t,h_t = check_image_shapes(train_dataset)\nw_t,h_t\n#w_v,h_v = check_image_shapes(val_dataset)\n#w_T,h_T = check_image_shapes(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASJ8mG9Q074x","outputId":"8db8a7a5-a87c-4beb-cefc-e3b3ba58d491","execution":{"iopub.status.busy":"2024-07-05T07:23:47.200200Z","iopub.execute_input":"2024-07-05T07:23:47.200529Z","iopub.status.idle":"2024-07-05T07:23:51.486459Z","shell.execute_reply.started":"2024-07-05T07:23:47.200491Z","shell.execute_reply":"2024-07-05T07:23:51.485538Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(464, 348)"},"metadata":{}}]},{"cell_type":"code","source":"transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((348, 348)),\n    torchvision.transforms.ToTensor(),\n])\ntrain_dataset = GroceryStoreDataset(split='train',transform=transform)\nbatch_size = 1\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)","metadata":{"id":"row_uJ3o31L4","execution":{"iopub.status.busy":"2024-07-05T07:23:56.501704Z","iopub.execute_input":"2024-07-05T07:23:56.502449Z","iopub.status.idle":"2024-07-05T07:23:56.512375Z","shell.execute_reply.started":"2024-07-05T07:23:56.502412Z","shell.execute_reply":"2024-07-05T07:23:56.511200Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mean = torch.zeros(3)\nstd = torch.zeros(3)\n\nfor images,_ in train_loader:\n    mean += torch.mean(images, dim=(0, 2, 3))\n    std += torch.std(images, dim=(0, 2, 3))\nmean /= train_dataset.__len__()\nstd /= train_dataset.__len__()\n\nprint(f'Mean: {mean}')\nprint(f'Std: {std}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUAr6qnw5MoM","outputId":"f8884b07-d592-49fc-ca48-867c8e3c3281","execution":{"iopub.status.busy":"2024-07-05T07:23:58.742193Z","iopub.execute_input":"2024-07-05T07:23:58.743136Z","iopub.status.idle":"2024-07-05T07:24:09.016652Z","shell.execute_reply.started":"2024-07-05T07:23:58.743103Z","shell.execute_reply":"2024-07-05T07:24:09.015758Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Mean: tensor([0.5306, 0.3964, 0.2564])\nStd: tensor([0.2325, 0.2093, 0.1781])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Part 1: design your own network\n\nYour goal is to implement a convolutional neural network for image classification and train it on `GroceryStoreDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split of **around 60%**. You are free to achieve that however you want, except for a few rules you must follow:\n\n- You **cannot** simply instantiate an off-the-self PyTorch network. Instead, you must construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you **cannot** use e.g. `torchvision.models.alexnet`.\n\n- Justify every *design choice* you make. Design choices include network architecture, training hyperparameters, and, possibly, dataset preprocessing steps. You can either (i) start from the simplest convolutional network you can think of and add complexity one step at a time, while showing how each step gets you closer to the target ~60%, or (ii) start from a model that is already able to achieve the desired accuracy and show how, by removing some of its components, its performance drops (i.e. an *ablation study*). You can *show* your results/improvements however you want: training plots, console-printed values or tables, or whatever else your heart desires: the clearer, the better.\n\nDon't be too concerned with your network performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded **more** points than a poorly experimentally validated model with higher accuracy.","metadata":{"id":"yBch3dpwNSsW"}},{"cell_type":"code","source":"def ncorrect(scores, y):\n    y_hat = torch.argmax(scores, -1)\n    return (y_hat == y).sum()\n\ndef accuracy(scores, y):\n    correct = ncorrect(scores, y)\n    return correct.true_divide(y.shape[0])\n\ndef train_loop(model, train_dl, epochs, opt, val_dl=None, verbose=False, label_smoothing=0):\n    best_val_acc = 0\n    best_params = []\n    best_epoch = -1\n\n    for e in tqdm(range(epochs)):\n        model.train()\n        # Train\n        train_loss = 0\n        train_samples = 0\n        train_acc = 0\n        for train_data in train_dl:\n            imgs = train_data[0].to(device)\n            labels = train_data[1].to(device)\n            scores = model(imgs)\n            loss = F.cross_entropy(scores, labels,label_smoothing=label_smoothing)\n            train_loss += loss.item() * imgs.shape[0]\n            train_samples += imgs.shape[0]\n            train_acc += ncorrect(scores, labels).item()\n\n            opt.zero_grad()  # clear\n            loss.backward()  # fill\n            opt.step()       # use\n\n        train_acc /= train_samples\n        train_loss /= train_samples\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0\n            val_samples = 0\n            val_acc = 0\n            if val_dl is not None:\n                for val_data in val_dl:\n                    imgs = val_data[0].to(device)\n                    labels = val_data[1].to(device)\n                    val_scores = model(imgs)\n                    val_loss += F.cross_entropy(val_scores, labels).item() * imgs.shape[0]\n                    val_samples += imgs.shape[0]\n                    val_acc += ncorrect(val_scores, labels).item()\n                val_acc /= val_samples\n                val_loss /= val_samples\n\n            if val_dl is None or val_acc > best_val_acc:\n                best_val_acc = val_acc if val_dl is not None else 0\n                best_params = model.state_dict()\n                torch.save(best_params, \"best_model.pth\")\n                best_epoch = e\n\n        if verbose: #and e % 5 == 0:\n            print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if val_dl is None else f\" - valid loss {val_loss:.3f} - valid acc {val_acc:.3f}\"))\n\n    if verbose and val_dl is not None:\n        print(f\"Best epoch {best_epoch}, best acc {best_val_acc}\")\n\n    return best_val_acc, best_params, best_epoch","metadata":{"id":"SFKZXhGDAqto","execution":{"iopub.status.busy":"2024-07-05T07:24:17.257096Z","iopub.execute_input":"2024-07-05T07:24:17.257466Z","iopub.status.idle":"2024-07-05T07:24:17.273686Z","shell.execute_reply.started":"2024-07-05T07:24:17.257435Z","shell.execute_reply":"2024-07-05T07:24:17.272445Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{"id":"8RNVD7TQoy1r"}},{"cell_type":"code","source":"image_height, image_width, image_channels = 224,224,3 #348, 348, 3\nnum_classes = train_dataset.get_num_classes()\n\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((348, 348)),\n    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n    torchvision.transforms.ToTensor(),\n    #Mean: tensor([0.5306, 0.3964, 0.2564])    #Std: tensor([0.2325, 0.2093, 0.1781])\n    torchvision.transforms.Normalize((0.5, 0.4, 0.25), (0.23, 0.2, 0.17))\n])\n\ntransform_2 = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(size=(224, 224),antialias=True),\n    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0.5, 0.4, 0.25), (0.23, 0.2, 0.17))\n])\ntrain_dataset = GroceryStoreDataset(split='train',transform=transform_2)\nval_dataset = GroceryStoreDataset(split='val',transform=transform_2)\ntest_dataset = GroceryStoreDataset(split='test',transform=transform_2)\n\nbatch = 8\ntrain_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch, shuffle=True)","metadata":{"id":"kVYlsNGkbuqb","execution":{"iopub.status.busy":"2024-07-05T07:24:24.088396Z","iopub.execute_input":"2024-07-05T07:24:24.089162Z","iopub.status.idle":"2024-07-05T07:24:24.106940Z","shell.execute_reply.started":"2024-07-05T07:24:24.089126Z","shell.execute_reply":"2024-07-05T07:24:24.106052Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class ExtendedCNN(nn.Module):\n    def __init__(self,channels=16, num_classes=num_classes):\n        super(ExtendedCNN, self).__init__()\n        # Define convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=image_channels, out_channels=channels, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=channels, out_channels=channels*2, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=channels*2, out_channels=channels*4, kernel_size=3, stride=1, padding=1)\n\n        # Calculate the size of the feature map after the convolutional layers\n        def conv2d_size_out(size, kernel_size=3, stride=1, padding=1):\n            return (size - kernel_size + 2 * padding) // stride + 1\n        def conv2d_compute_size(conv_number,kernels,max_poolings):  #max pooling ex. [1,0,1] if 1 them there is a max_pool\n          image_w = image_width\n          for i in range(conv_number):\n            image_w = conv2d_size_out(image_w, kernel_size=kernels[i])\n            if max_poolings[i] == 1:\n              image_w = image_w//2\n          return image_w\n\n        #convh = conv2d_size_out(conv2d_size_out(image_height, kernel_size=5, padding=1) // 2, kernel_size=3, padding=1) // 2\n        image_w = conv2d_compute_size(3,[3,3,3],[1,1,1])\n\n        linear_input_size = image_w * image_w * channels*4  # Adjusted based on the output channels of conv2\n\n        # Define fully connected layers\n        self.fc1 = nn.Linear(linear_input_size, 128)\n        #self.drop1 = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(128, 64)\n        #self.drop2 = nn.Dropout(0.3)\n        self.fc3 = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        # Apply convolutional layers with ReLU activation and max pooling\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, kernel_size=2, stride=2)\n\n        # Flatten the tensor\n        x = x.view(x.size(0), -1)\n\n        # Apply fully connected layers\n        x = F.relu(self.fc1(x))\n        #x = self.drop1(x)\n        x = F.relu(self.fc2(x))\n        #x = self.drop2(x)\n        x = self.fc3(x)\n\n        return x\n","metadata":{"id":"CZNxdSS2o3oT","execution":{"iopub.status.busy":"2024-07-05T07:25:07.047988Z","iopub.execute_input":"2024-07-05T07:25:07.048693Z","iopub.status.idle":"2024-07-05T07:25:07.063907Z","shell.execute_reply.started":"2024-07-05T07:25:07.048656Z","shell.execute_reply":"2024-07-05T07:25:07.062723Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"new_model = ExtendedCNN(\n    num_classes = num_classes,\n)\nnew_model.to(device)\n\noptimizer = torch.optim.Adam(new_model.parameters(), lr=0.001,weight_decay=0.01)\nepochs = 50\nlabel_smoothing = 0.01\nbest_val_acc, best_params, best_epoch = train_loop(\n    new_model,\n    train_loader,\n    epochs,\n    optimizer,\n    val_loader,\n    verbose=True,\n    label_smoothing = label_smoothing,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761,"referenced_widgets":["521788e7ab614c4bb1ec45d9853678db","d18c07c8179043df9447c93111a31dd0","4733ff38e6f54f72a8dca7b6d1d6e1f5","71a09f42d1f34c5faf7c012fbfe5fc1e","f7ded3abfb644ed3aaa967d1bc313eb6","febae8e0d3764652bbf57351fbfb5041","7b39c4ee962d4b019efe256eb5bc4b42","7cd9473ac34347508ec6f23534b463b2","0d21484dba744589823686ea95ce27f8","6a5d0a75de624cc5a80388acd0cafad1","84f66999ecb34dd284cbb5b1961e009c"]},"id":"TpE8SRf5ptIM","outputId":"53c4d936-42b1-4d1e-eccd-3435a1820580","execution":{"iopub.status.busy":"2024-07-05T07:25:14.858541Z","iopub.execute_input":"2024-07-05T07:25:14.859205Z","iopub.status.idle":"2024-07-05T07:25:17.797196Z","shell.execute_reply.started":"2024-07-05T07:25:14.859166Z","shell.execute_reply":"2024-07-05T07:25:17.795969Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4684717cb342403b9cf47f74a13c3eb4"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      8\u001b[0m label_smoothing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m----> 9\u001b[0m best_val_acc, best_params, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 25\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dl, epochs, opt, val_dl, verbose, label_smoothing)\u001b[0m\n\u001b[1;32m     23\u001b[0m scores \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(scores, labels,label_smoothing\u001b[38;5;241m=\u001b[39mlabel_smoothing)\n\u001b[0;32m---> 25\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m train_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ncorrect(scores, labels)\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Gridsearch","metadata":{}},{"cell_type":"code","source":"weight_decays = [0.0, 0.01, 0.001]\nlabel_smoothings = [0.01, 0.1,0.5]\nlrs = [0.001, 0.0001]\nchannels = 16\nbatch = 8\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\nepochs = 40\n# Perform grid search\nfor weight_decay in weight_decays:\n    for label_smoothing in label_smoothings:\n        for lr in lrs:\n            model = ExtendedCNN(channels=channels, num_classes=num_classes)\n            model.to(device)\n\n            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n            print(f\"Training with: weight_decay={weight_decay}, label_smoothing={label_smoothing}, lr={lr}, channels={channels}, batch_size={batch_size}\")\n            train_loop(\n                model,\n                train_loader,\n                epochs,\n                optimizer,\n                val_loader,\n                verbose=True,\n                label_smoothing = label_smoothing,\n            )","metadata":{"execution":{"iopub.status.busy":"2024-07-04T20:26:41.230235Z","iopub.execute_input":"2024-07-04T20:26:41.230768Z","iopub.status.idle":"2024-07-04T22:33:35.869618Z","shell.execute_reply.started":"2024-07-04T20:26:41.230729Z","shell.execute_reply":"2024-07-04T22:33:35.868626Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Training with: weight_decay=0.0, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb34a0625c684b3e9245777c59285695"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 2.911 - train acc 0.202 - valid loss 2.900 - valid acc 0.226\nEpoch 1: train loss 2.225 - train acc 0.328 - valid loss 2.608 - valid acc 0.311\nEpoch 2: train loss 1.857 - train acc 0.416 - valid loss 2.811 - valid acc 0.301\nEpoch 3: train loss 1.698 - train acc 0.443 - valid loss 2.360 - valid acc 0.270\nEpoch 4: train loss 1.553 - train acc 0.485 - valid loss 2.339 - valid acc 0.331\nEpoch 5: train loss 1.420 - train acc 0.525 - valid loss 2.383 - valid acc 0.284\nEpoch 6: train loss 1.337 - train acc 0.564 - valid loss 2.187 - valid acc 0.382\nEpoch 7: train loss 1.285 - train acc 0.557 - valid loss 2.082 - valid acc 0.358\nEpoch 8: train loss 1.181 - train acc 0.608 - valid loss 2.430 - valid acc 0.355\nEpoch 9: train loss 1.209 - train acc 0.600 - valid loss 2.016 - valid acc 0.405\nEpoch 10: train loss 1.073 - train acc 0.638 - valid loss 2.107 - valid acc 0.372\nEpoch 11: train loss 1.071 - train acc 0.638 - valid loss 2.266 - valid acc 0.389\nEpoch 12: train loss 0.967 - train acc 0.676 - valid loss 2.277 - valid acc 0.405\nEpoch 13: train loss 1.009 - train acc 0.675 - valid loss 2.164 - valid acc 0.416\nEpoch 14: train loss 0.897 - train acc 0.712 - valid loss 1.918 - valid acc 0.470\nEpoch 15: train loss 0.866 - train acc 0.725 - valid loss 1.990 - valid acc 0.459\nEpoch 16: train loss 0.838 - train acc 0.730 - valid loss 2.065 - valid acc 0.456\nEpoch 17: train loss 0.872 - train acc 0.728 - valid loss 2.344 - valid acc 0.426\nEpoch 18: train loss 0.822 - train acc 0.736 - valid loss 2.628 - valid acc 0.405\nEpoch 19: train loss 0.784 - train acc 0.750 - valid loss 2.409 - valid acc 0.436\nEpoch 20: train loss 0.767 - train acc 0.757 - valid loss 2.078 - valid acc 0.493\nEpoch 21: train loss 0.727 - train acc 0.771 - valid loss 1.842 - valid acc 0.517\nEpoch 22: train loss 0.714 - train acc 0.770 - valid loss 2.172 - valid acc 0.483\nEpoch 23: train loss 0.691 - train acc 0.779 - valid loss 2.462 - valid acc 0.426\nEpoch 24: train loss 0.666 - train acc 0.783 - valid loss 2.226 - valid acc 0.459\nEpoch 25: train loss 0.656 - train acc 0.783 - valid loss 2.250 - valid acc 0.466\nEpoch 26: train loss 0.683 - train acc 0.781 - valid loss 2.364 - valid acc 0.422\nEpoch 27: train loss 0.655 - train acc 0.802 - valid loss 2.386 - valid acc 0.439\nEpoch 28: train loss 0.633 - train acc 0.802 - valid loss 2.478 - valid acc 0.405\nEpoch 29: train loss 0.612 - train acc 0.809 - valid loss 2.240 - valid acc 0.490\nEpoch 30: train loss 0.644 - train acc 0.800 - valid loss 2.322 - valid acc 0.432\nEpoch 31: train loss 0.558 - train acc 0.825 - valid loss 2.559 - valid acc 0.480\nEpoch 32: train loss 0.617 - train acc 0.808 - valid loss 2.242 - valid acc 0.416\nEpoch 33: train loss 0.541 - train acc 0.827 - valid loss 2.240 - valid acc 0.456\nEpoch 34: train loss 0.619 - train acc 0.811 - valid loss 2.423 - valid acc 0.490\nEpoch 35: train loss 0.572 - train acc 0.826 - valid loss 2.830 - valid acc 0.453\nEpoch 36: train loss 0.540 - train acc 0.838 - valid loss 2.509 - valid acc 0.436\nEpoch 37: train loss 0.606 - train acc 0.820 - valid loss 2.479 - valid acc 0.470\nEpoch 38: train loss 0.484 - train acc 0.856 - valid loss 2.228 - valid acc 0.514\nEpoch 39: train loss 0.558 - train acc 0.826 - valid loss 2.473 - valid acc 0.459\nBest epoch 21, best acc 0.5168918918918919\nTraining with: weight_decay=0.0, label_smoothing=0.0, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e73126507c23445eafac45721ed1607d"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.264 - train acc 0.147 - valid loss 3.187 - valid acc 0.162\nEpoch 1: train loss 2.986 - train acc 0.181 - valid loss 3.204 - valid acc 0.169\nEpoch 2: train loss 2.919 - train acc 0.202 - valid loss 3.120 - valid acc 0.193\nEpoch 3: train loss 2.883 - train acc 0.208 - valid loss 3.096 - valid acc 0.159\nEpoch 4: train loss 3.189 - train acc 0.170 - valid loss 3.527 - valid acc 0.074\nEpoch 5: train loss 3.435 - train acc 0.105 - valid loss 3.490 - valid acc 0.074\nEpoch 6: train loss 3.413 - train acc 0.102 - valid loss 3.503 - valid acc 0.074\nEpoch 7: train loss 3.412 - train acc 0.105 - valid loss 3.502 - valid acc 0.074\nEpoch 8: train loss 3.412 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 9: train loss 3.413 - train acc 0.103 - valid loss 3.506 - valid acc 0.074\nEpoch 10: train loss 3.411 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 11: train loss 3.412 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 12: train loss 3.412 - train acc 0.104 - valid loss 3.500 - valid acc 0.074\nEpoch 13: train loss 3.412 - train acc 0.100 - valid loss 3.505 - valid acc 0.074\nEpoch 14: train loss 3.412 - train acc 0.103 - valid loss 3.498 - valid acc 0.074\nEpoch 15: train loss 3.411 - train acc 0.105 - valid loss 3.503 - valid acc 0.074\nEpoch 16: train loss 3.412 - train acc 0.103 - valid loss 3.500 - valid acc 0.074\nEpoch 17: train loss 3.412 - train acc 0.103 - valid loss 3.502 - valid acc 0.074\nEpoch 18: train loss 3.411 - train acc 0.105 - valid loss 3.506 - valid acc 0.098\nEpoch 19: train loss 3.412 - train acc 0.102 - valid loss 3.505 - valid acc 0.074\nEpoch 20: train loss 3.412 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 21: train loss 3.412 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 22: train loss 3.411 - train acc 0.102 - valid loss 3.511 - valid acc 0.074\nEpoch 23: train loss 3.412 - train acc 0.102 - valid loss 3.507 - valid acc 0.074\nEpoch 24: train loss 3.412 - train acc 0.102 - valid loss 3.504 - valid acc 0.074\nEpoch 25: train loss 3.412 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 26: train loss 3.411 - train acc 0.101 - valid loss 3.505 - valid acc 0.074\nEpoch 27: train loss 3.411 - train acc 0.103 - valid loss 3.504 - valid acc 0.074\nEpoch 28: train loss 3.412 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 29: train loss 3.411 - train acc 0.103 - valid loss 3.501 - valid acc 0.074\nEpoch 30: train loss 3.412 - train acc 0.101 - valid loss 3.501 - valid acc 0.074\nEpoch 31: train loss 3.412 - train acc 0.102 - valid loss 3.503 - valid acc 0.074\nEpoch 32: train loss 3.412 - train acc 0.105 - valid loss 3.507 - valid acc 0.074\nEpoch 33: train loss 3.412 - train acc 0.105 - valid loss 3.509 - valid acc 0.074\nEpoch 34: train loss 3.412 - train acc 0.104 - valid loss 3.506 - valid acc 0.074\nEpoch 35: train loss 3.413 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 36: train loss 3.412 - train acc 0.105 - valid loss 3.502 - valid acc 0.074\nEpoch 37: train loss 3.411 - train acc 0.100 - valid loss 3.506 - valid acc 0.074\nEpoch 38: train loss 3.412 - train acc 0.105 - valid loss 3.502 - valid acc 0.074\nEpoch 39: train loss 3.412 - train acc 0.103 - valid loss 3.506 - valid acc 0.074\nBest epoch 2, best acc 0.19256756756756757\nTraining with: weight_decay=0.0, label_smoothing=0.01, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab2baa89ea04aad814d3a743ee36a24"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 2.939 - train acc 0.201 - valid loss 2.822 - valid acc 0.236\nEpoch 1: train loss 2.311 - train acc 0.324 - valid loss 2.579 - valid acc 0.277\nEpoch 2: train loss 1.955 - train acc 0.408 - valid loss 2.802 - valid acc 0.257\nEpoch 3: train loss 1.716 - train acc 0.473 - valid loss 2.343 - valid acc 0.301\nEpoch 4: train loss 1.555 - train acc 0.518 - valid loss 2.239 - valid acc 0.382\nEpoch 5: train loss 1.411 - train acc 0.577 - valid loss 2.098 - valid acc 0.358\nEpoch 6: train loss 1.323 - train acc 0.589 - valid loss 2.275 - valid acc 0.348\nEpoch 7: train loss 1.249 - train acc 0.617 - valid loss 2.097 - valid acc 0.422\nEpoch 8: train loss 1.181 - train acc 0.646 - valid loss 2.000 - valid acc 0.378\nEpoch 9: train loss 1.124 - train acc 0.662 - valid loss 2.131 - valid acc 0.429\nEpoch 10: train loss 1.064 - train acc 0.680 - valid loss 2.301 - valid acc 0.355\nEpoch 11: train loss 1.043 - train acc 0.696 - valid loss 2.251 - valid acc 0.432\nEpoch 12: train loss 0.976 - train acc 0.713 - valid loss 2.048 - valid acc 0.456\nEpoch 13: train loss 0.993 - train acc 0.702 - valid loss 2.180 - valid acc 0.426\nEpoch 14: train loss 0.960 - train acc 0.722 - valid loss 2.391 - valid acc 0.372\nEpoch 15: train loss 0.899 - train acc 0.750 - valid loss 2.207 - valid acc 0.426\nEpoch 16: train loss 0.879 - train acc 0.760 - valid loss 2.115 - valid acc 0.422\nEpoch 17: train loss 0.864 - train acc 0.747 - valid loss 2.390 - valid acc 0.436\nEpoch 18: train loss 0.842 - train acc 0.763 - valid loss 2.243 - valid acc 0.422\nEpoch 19: train loss 0.786 - train acc 0.784 - valid loss 2.365 - valid acc 0.419\nEpoch 20: train loss 0.831 - train acc 0.769 - valid loss 2.198 - valid acc 0.473\nEpoch 21: train loss 0.818 - train acc 0.778 - valid loss 2.220 - valid acc 0.500\nEpoch 22: train loss 0.740 - train acc 0.798 - valid loss 2.336 - valid acc 0.409\nEpoch 23: train loss 0.764 - train acc 0.802 - valid loss 2.210 - valid acc 0.426\nEpoch 24: train loss 0.734 - train acc 0.800 - valid loss 2.324 - valid acc 0.385\nEpoch 25: train loss 0.733 - train acc 0.806 - valid loss 2.091 - valid acc 0.439\nEpoch 26: train loss 0.733 - train acc 0.802 - valid loss 2.391 - valid acc 0.399\nEpoch 27: train loss 0.694 - train acc 0.821 - valid loss 2.215 - valid acc 0.476\nEpoch 28: train loss 0.749 - train acc 0.800 - valid loss 1.939 - valid acc 0.486\nEpoch 29: train loss 0.669 - train acc 0.828 - valid loss 2.574 - valid acc 0.432\nEpoch 30: train loss 0.697 - train acc 0.817 - valid loss 2.431 - valid acc 0.399\nEpoch 31: train loss 0.706 - train acc 0.817 - valid loss 1.876 - valid acc 0.514\nEpoch 32: train loss 0.643 - train acc 0.832 - valid loss 2.063 - valid acc 0.443\nEpoch 33: train loss 0.672 - train acc 0.824 - valid loss 2.358 - valid acc 0.392\nEpoch 34: train loss 0.642 - train acc 0.833 - valid loss 2.554 - valid acc 0.419\nEpoch 35: train loss 0.648 - train acc 0.831 - valid loss 2.302 - valid acc 0.416\nEpoch 36: train loss 0.649 - train acc 0.838 - valid loss 2.278 - valid acc 0.490\nEpoch 37: train loss 0.642 - train acc 0.834 - valid loss 2.436 - valid acc 0.409\nEpoch 38: train loss 0.606 - train acc 0.849 - valid loss 2.599 - valid acc 0.463\nEpoch 39: train loss 0.601 - train acc 0.841 - valid loss 2.139 - valid acc 0.497\nBest epoch 31, best acc 0.5135135135135135\nTraining with: weight_decay=0.0, label_smoothing=0.01, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2c040c97ea3448e9a6b8fa475b5dec3"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.603 - train acc 0.097 - valid loss 3.510 - valid acc 0.074\nEpoch 1: train loss 3.434 - train acc 0.105 - valid loss 3.498 - valid acc 0.098\nEpoch 2: train loss 3.430 - train acc 0.099 - valid loss 3.506 - valid acc 0.074\nEpoch 3: train loss 3.428 - train acc 0.103 - valid loss 3.496 - valid acc 0.074\nEpoch 4: train loss 3.423 - train acc 0.104 - valid loss 3.511 - valid acc 0.074\nEpoch 5: train loss 3.425 - train acc 0.103 - valid loss 3.521 - valid acc 0.074\nEpoch 6: train loss 3.424 - train acc 0.100 - valid loss 3.494 - valid acc 0.074\nEpoch 7: train loss 3.423 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 8: train loss 3.422 - train acc 0.103 - valid loss 3.505 - valid acc 0.074\nEpoch 9: train loss 3.423 - train acc 0.102 - valid loss 3.507 - valid acc 0.074\nEpoch 10: train loss 3.422 - train acc 0.102 - valid loss 3.507 - valid acc 0.074\nEpoch 11: train loss 3.423 - train acc 0.100 - valid loss 3.500 - valid acc 0.074\nEpoch 12: train loss 3.435 - train acc 0.102 - valid loss 3.497 - valid acc 0.074\nEpoch 13: train loss 3.423 - train acc 0.099 - valid loss 3.495 - valid acc 0.074\nEpoch 14: train loss 3.420 - train acc 0.105 - valid loss 3.507 - valid acc 0.074\nEpoch 15: train loss 3.420 - train acc 0.105 - valid loss 3.494 - valid acc 0.098\nEpoch 16: train loss 3.420 - train acc 0.103 - valid loss 3.503 - valid acc 0.074\nEpoch 17: train loss 3.420 - train acc 0.104 - valid loss 3.504 - valid acc 0.074\nEpoch 18: train loss 3.420 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 19: train loss 3.419 - train acc 0.105 - valid loss 3.505 - valid acc 0.074\nEpoch 20: train loss 3.420 - train acc 0.103 - valid loss 3.498 - valid acc 0.074\nEpoch 21: train loss 3.419 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 22: train loss 3.419 - train acc 0.103 - valid loss 3.504 - valid acc 0.074\nEpoch 23: train loss 3.419 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 24: train loss 3.418 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 25: train loss 3.419 - train acc 0.107 - valid loss 3.501 - valid acc 0.098\nEpoch 26: train loss 3.418 - train acc 0.100 - valid loss 3.501 - valid acc 0.074\nEpoch 27: train loss 3.418 - train acc 0.104 - valid loss 3.501 - valid acc 0.074\nEpoch 28: train loss 3.419 - train acc 0.105 - valid loss 3.502 - valid acc 0.098\nEpoch 29: train loss 3.418 - train acc 0.100 - valid loss 3.508 - valid acc 0.074\nEpoch 30: train loss 3.419 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 31: train loss 3.419 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 32: train loss 3.418 - train acc 0.103 - valid loss 3.501 - valid acc 0.098\nEpoch 33: train loss 3.418 - train acc 0.104 - valid loss 3.505 - valid acc 0.074\nEpoch 34: train loss 3.419 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 35: train loss 3.419 - train acc 0.105 - valid loss 3.499 - valid acc 0.074\nEpoch 36: train loss 3.419 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 37: train loss 3.418 - train acc 0.103 - valid loss 3.498 - valid acc 0.074\nEpoch 38: train loss 3.419 - train acc 0.096 - valid loss 3.500 - valid acc 0.074\nEpoch 39: train loss 3.418 - train acc 0.103 - valid loss 3.500 - valid acc 0.074\nBest epoch 1, best acc 0.09797297297297297\nTraining with: weight_decay=0.0, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"646097c8c7374134aeb7103dd378d97e"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.114 - train acc 0.193 - valid loss 2.888 - valid acc 0.182\nEpoch 1: train loss 2.582 - train acc 0.336 - valid loss 2.444 - valid acc 0.287\nEpoch 2: train loss 2.276 - train acc 0.420 - valid loss 2.371 - valid acc 0.314\nEpoch 3: train loss 2.093 - train acc 0.490 - valid loss 2.303 - valid acc 0.334\nEpoch 4: train loss 1.934 - train acc 0.540 - valid loss 2.206 - valid acc 0.351\nEpoch 5: train loss 1.846 - train acc 0.573 - valid loss 2.163 - valid acc 0.321\nEpoch 6: train loss 1.777 - train acc 0.609 - valid loss 2.004 - valid acc 0.416\nEpoch 7: train loss 1.726 - train acc 0.626 - valid loss 2.127 - valid acc 0.368\nEpoch 8: train loss 1.626 - train acc 0.667 - valid loss 2.038 - valid acc 0.375\nEpoch 9: train loss 1.612 - train acc 0.674 - valid loss 2.166 - valid acc 0.368\nEpoch 10: train loss 1.548 - train acc 0.701 - valid loss 2.120 - valid acc 0.399\nEpoch 11: train loss 1.522 - train acc 0.717 - valid loss 2.182 - valid acc 0.368\nEpoch 12: train loss 1.484 - train acc 0.729 - valid loss 1.989 - valid acc 0.392\nEpoch 13: train loss 1.489 - train acc 0.715 - valid loss 2.015 - valid acc 0.422\nEpoch 14: train loss 1.426 - train acc 0.753 - valid loss 2.242 - valid acc 0.405\nEpoch 15: train loss 1.435 - train acc 0.743 - valid loss 2.022 - valid acc 0.449\nEpoch 16: train loss 1.380 - train acc 0.774 - valid loss 2.003 - valid acc 0.422\nEpoch 17: train loss 1.362 - train acc 0.781 - valid loss 2.156 - valid acc 0.419\nEpoch 18: train loss 1.360 - train acc 0.791 - valid loss 2.190 - valid acc 0.426\nEpoch 19: train loss 1.315 - train acc 0.805 - valid loss 2.213 - valid acc 0.392\nEpoch 20: train loss 1.303 - train acc 0.809 - valid loss 2.106 - valid acc 0.426\nEpoch 21: train loss 1.279 - train acc 0.811 - valid loss 2.033 - valid acc 0.426\nEpoch 22: train loss 1.326 - train acc 0.801 - valid loss 2.058 - valid acc 0.409\nEpoch 23: train loss 1.293 - train acc 0.816 - valid loss 2.010 - valid acc 0.453\nEpoch 24: train loss 1.268 - train acc 0.818 - valid loss 2.157 - valid acc 0.426\nEpoch 25: train loss 1.242 - train acc 0.829 - valid loss 2.181 - valid acc 0.375\nEpoch 26: train loss 1.251 - train acc 0.832 - valid loss 1.968 - valid acc 0.456\nEpoch 27: train loss 1.229 - train acc 0.831 - valid loss 1.998 - valid acc 0.466\nEpoch 28: train loss 1.223 - train acc 0.837 - valid loss 2.000 - valid acc 0.483\nEpoch 29: train loss 1.196 - train acc 0.846 - valid loss 1.927 - valid acc 0.490\nEpoch 30: train loss 1.199 - train acc 0.844 - valid loss 1.927 - valid acc 0.459\nEpoch 31: train loss 1.207 - train acc 0.840 - valid loss 2.236 - valid acc 0.439\nEpoch 32: train loss 1.203 - train acc 0.847 - valid loss 1.993 - valid acc 0.432\nEpoch 33: train loss 1.200 - train acc 0.848 - valid loss 1.928 - valid acc 0.483\nEpoch 34: train loss 1.203 - train acc 0.842 - valid loss 1.981 - valid acc 0.486\nEpoch 35: train loss 1.161 - train acc 0.861 - valid loss 2.131 - valid acc 0.443\nEpoch 36: train loss 1.164 - train acc 0.866 - valid loss 1.919 - valid acc 0.480\nEpoch 37: train loss 1.146 - train acc 0.869 - valid loss 1.946 - valid acc 0.476\nEpoch 38: train loss 1.159 - train acc 0.867 - valid loss 1.898 - valid acc 0.480\nEpoch 39: train loss 1.180 - train acc 0.856 - valid loss 2.032 - valid acc 0.426\nBest epoch 29, best acc 0.48986486486486486\nTraining with: weight_decay=0.0, label_smoothing=0.1, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b67f3d9c4e7942f8a24671ff88a6ca41"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.707 - train acc 0.097 - valid loss 3.507 - valid acc 0.098\nEpoch 1: train loss 3.488 - train acc 0.101 - valid loss 3.511 - valid acc 0.074\nEpoch 2: train loss 3.485 - train acc 0.101 - valid loss 3.503 - valid acc 0.074\nEpoch 3: train loss 3.483 - train acc 0.102 - valid loss 3.490 - valid acc 0.074\nEpoch 4: train loss 3.482 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 5: train loss 3.482 - train acc 0.102 - valid loss 3.497 - valid acc 0.074\nEpoch 6: train loss 3.481 - train acc 0.104 - valid loss 3.497 - valid acc 0.098\nEpoch 7: train loss 3.481 - train acc 0.098 - valid loss 3.489 - valid acc 0.074\nEpoch 8: train loss 3.481 - train acc 0.105 - valid loss 3.502 - valid acc 0.074\nEpoch 9: train loss 3.479 - train acc 0.103 - valid loss 3.499 - valid acc 0.074\nEpoch 10: train loss 3.479 - train acc 0.098 - valid loss 3.501 - valid acc 0.074\nEpoch 11: train loss 3.478 - train acc 0.103 - valid loss 3.496 - valid acc 0.074\nEpoch 12: train loss 3.478 - train acc 0.106 - valid loss 3.496 - valid acc 0.098\nEpoch 13: train loss 3.478 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 14: train loss 3.477 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 15: train loss 3.477 - train acc 0.105 - valid loss 3.499 - valid acc 0.074\nEpoch 16: train loss 3.477 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 17: train loss 3.476 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 18: train loss 3.477 - train acc 0.105 - valid loss 3.492 - valid acc 0.098\nEpoch 19: train loss 3.476 - train acc 0.101 - valid loss 3.491 - valid acc 0.074\nEpoch 20: train loss 3.476 - train acc 0.103 - valid loss 3.492 - valid acc 0.074\nEpoch 21: train loss 3.475 - train acc 0.105 - valid loss 3.493 - valid acc 0.074\nEpoch 22: train loss 3.475 - train acc 0.103 - valid loss 3.497 - valid acc 0.074\nEpoch 23: train loss 3.475 - train acc 0.105 - valid loss 3.494 - valid acc 0.074\nEpoch 24: train loss 3.475 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 25: train loss 3.475 - train acc 0.105 - valid loss 3.492 - valid acc 0.074\nEpoch 26: train loss 3.476 - train acc 0.103 - valid loss 3.494 - valid acc 0.074\nEpoch 27: train loss 3.475 - train acc 0.104 - valid loss 3.495 - valid acc 0.074\nEpoch 28: train loss 3.475 - train acc 0.100 - valid loss 3.492 - valid acc 0.074\nEpoch 29: train loss 3.476 - train acc 0.102 - valid loss 3.498 - valid acc 0.074\nEpoch 30: train loss 3.475 - train acc 0.101 - valid loss 3.494 - valid acc 0.074\nEpoch 31: train loss 3.475 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 32: train loss 3.476 - train acc 0.103 - valid loss 3.493 - valid acc 0.074\nEpoch 33: train loss 3.476 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 34: train loss 3.476 - train acc 0.106 - valid loss 3.490 - valid acc 0.098\nEpoch 35: train loss 3.475 - train acc 0.098 - valid loss 3.492 - valid acc 0.074\nEpoch 36: train loss 3.475 - train acc 0.102 - valid loss 3.494 - valid acc 0.074\nEpoch 37: train loss 3.475 - train acc 0.102 - valid loss 3.494 - valid acc 0.074\nEpoch 38: train loss 3.475 - train acc 0.105 - valid loss 3.494 - valid acc 0.074\nEpoch 39: train loss 3.475 - train acc 0.105 - valid loss 3.496 - valid acc 0.074\nBest epoch 0, best acc 0.09797297297297297\nTraining with: weight_decay=0.01, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088457ef0a3749fbabcb8c5d0269a5ea"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.031 - train acc 0.170 - valid loss 2.947 - valid acc 0.216\nEpoch 1: train loss 2.683 - train acc 0.224 - valid loss 2.903 - valid acc 0.203\nEpoch 2: train loss 2.529 - train acc 0.248 - valid loss 2.693 - valid acc 0.206\nEpoch 3: train loss 2.341 - train acc 0.297 - valid loss 2.663 - valid acc 0.280\nEpoch 4: train loss 2.236 - train acc 0.320 - valid loss 2.452 - valid acc 0.274\nEpoch 5: train loss 2.061 - train acc 0.359 - valid loss 2.863 - valid acc 0.206\nEpoch 6: train loss 2.008 - train acc 0.368 - valid loss 2.433 - valid acc 0.260\nEpoch 7: train loss 1.901 - train acc 0.384 - valid loss 2.492 - valid acc 0.199\nEpoch 8: train loss 1.810 - train acc 0.408 - valid loss 2.656 - valid acc 0.253\nEpoch 9: train loss 1.776 - train acc 0.426 - valid loss 2.410 - valid acc 0.277\nEpoch 10: train loss 1.685 - train acc 0.444 - valid loss 2.421 - valid acc 0.297\nEpoch 11: train loss 1.642 - train acc 0.461 - valid loss 2.453 - valid acc 0.274\nEpoch 12: train loss 1.584 - train acc 0.478 - valid loss 2.409 - valid acc 0.274\nEpoch 13: train loss 1.558 - train acc 0.490 - valid loss 2.417 - valid acc 0.331\nEpoch 14: train loss 1.535 - train acc 0.483 - valid loss 2.422 - valid acc 0.345\nEpoch 15: train loss 1.532 - train acc 0.509 - valid loss 2.215 - valid acc 0.328\nEpoch 16: train loss 1.472 - train acc 0.515 - valid loss 2.410 - valid acc 0.351\nEpoch 17: train loss 1.464 - train acc 0.521 - valid loss 2.220 - valid acc 0.328\nEpoch 18: train loss 1.443 - train acc 0.522 - valid loss 2.193 - valid acc 0.385\nEpoch 19: train loss 1.413 - train acc 0.537 - valid loss 1.979 - valid acc 0.375\nEpoch 20: train loss 1.370 - train acc 0.545 - valid loss 2.305 - valid acc 0.304\nEpoch 21: train loss 1.379 - train acc 0.552 - valid loss 2.049 - valid acc 0.385\nEpoch 22: train loss 1.366 - train acc 0.549 - valid loss 1.927 - valid acc 0.385\nEpoch 23: train loss 1.321 - train acc 0.559 - valid loss 2.408 - valid acc 0.348\nEpoch 24: train loss 1.299 - train acc 0.560 - valid loss 2.245 - valid acc 0.385\nEpoch 25: train loss 1.338 - train acc 0.553 - valid loss 2.121 - valid acc 0.314\nEpoch 26: train loss 1.290 - train acc 0.570 - valid loss 1.929 - valid acc 0.409\nEpoch 27: train loss 1.283 - train acc 0.572 - valid loss 2.051 - valid acc 0.348\nEpoch 28: train loss 1.248 - train acc 0.577 - valid loss 2.150 - valid acc 0.419\nEpoch 29: train loss 1.280 - train acc 0.571 - valid loss 2.679 - valid acc 0.351\nEpoch 30: train loss 1.218 - train acc 0.589 - valid loss 2.312 - valid acc 0.338\nEpoch 31: train loss 1.265 - train acc 0.577 - valid loss 2.293 - valid acc 0.328\nEpoch 32: train loss 1.243 - train acc 0.584 - valid loss 2.593 - valid acc 0.368\nEpoch 33: train loss 1.226 - train acc 0.586 - valid loss 2.272 - valid acc 0.368\nEpoch 34: train loss 1.242 - train acc 0.590 - valid loss 2.241 - valid acc 0.382\nEpoch 35: train loss 1.220 - train acc 0.589 - valid loss 2.246 - valid acc 0.402\nEpoch 36: train loss 1.225 - train acc 0.585 - valid loss 2.398 - valid acc 0.361\nEpoch 37: train loss 1.213 - train acc 0.595 - valid loss 2.216 - valid acc 0.382\nEpoch 38: train loss 1.241 - train acc 0.585 - valid loss 2.137 - valid acc 0.399\nEpoch 39: train loss 1.215 - train acc 0.607 - valid loss 2.366 - valid acc 0.314\nBest epoch 28, best acc 0.4189189189189189\nTraining with: weight_decay=0.01, label_smoothing=0.0, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f60b32064ea4d01906b9d04f586b31c"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.555 - train acc 0.097 - valid loss 3.504 - valid acc 0.074\nEpoch 1: train loss 3.436 - train acc 0.095 - valid loss 3.494 - valid acc 0.074\nEpoch 2: train loss 3.431 - train acc 0.100 - valid loss 3.501 - valid acc 0.074\nEpoch 3: train loss 3.432 - train acc 0.097 - valid loss 3.503 - valid acc 0.074\nEpoch 4: train loss 3.433 - train acc 0.102 - valid loss 3.530 - valid acc 0.074\nEpoch 5: train loss 3.437 - train acc 0.095 - valid loss 3.499 - valid acc 0.074\nEpoch 6: train loss 3.433 - train acc 0.106 - valid loss 3.519 - valid acc 0.074\nEpoch 7: train loss 3.431 - train acc 0.102 - valid loss 3.514 - valid acc 0.074\nEpoch 8: train loss 3.436 - train acc 0.099 - valid loss 3.499 - valid acc 0.098\nEpoch 9: train loss 3.429 - train acc 0.097 - valid loss 3.480 - valid acc 0.074\nEpoch 10: train loss 3.429 - train acc 0.107 - valid loss 3.541 - valid acc 0.074\nEpoch 11: train loss 3.429 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 12: train loss 3.426 - train acc 0.105 - valid loss 3.489 - valid acc 0.074\nEpoch 13: train loss 3.434 - train acc 0.103 - valid loss 3.517 - valid acc 0.098\nEpoch 14: train loss 3.433 - train acc 0.102 - valid loss 3.484 - valid acc 0.074\nEpoch 15: train loss 3.428 - train acc 0.105 - valid loss 3.497 - valid acc 0.098\nEpoch 16: train loss 3.429 - train acc 0.099 - valid loss 3.495 - valid acc 0.074\nEpoch 17: train loss 3.437 - train acc 0.098 - valid loss 3.499 - valid acc 0.074\nEpoch 18: train loss 3.428 - train acc 0.100 - valid loss 3.499 - valid acc 0.074\nEpoch 19: train loss 3.426 - train acc 0.101 - valid loss 3.506 - valid acc 0.074\nEpoch 20: train loss 3.453 - train acc 0.103 - valid loss 3.507 - valid acc 0.074\nEpoch 21: train loss 3.425 - train acc 0.099 - valid loss 3.488 - valid acc 0.074\nEpoch 22: train loss 3.428 - train acc 0.105 - valid loss 3.489 - valid acc 0.074\nEpoch 23: train loss 3.445 - train acc 0.102 - valid loss 3.542 - valid acc 0.074\nEpoch 24: train loss 3.428 - train acc 0.098 - valid loss 3.502 - valid acc 0.074\nEpoch 25: train loss 3.425 - train acc 0.108 - valid loss 3.500 - valid acc 0.074\nEpoch 26: train loss 3.425 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 27: train loss 3.424 - train acc 0.107 - valid loss 3.509 - valid acc 0.074\nEpoch 28: train loss 3.424 - train acc 0.103 - valid loss 3.506 - valid acc 0.074\nEpoch 29: train loss 3.425 - train acc 0.108 - valid loss 3.492 - valid acc 0.098\nEpoch 30: train loss 3.425 - train acc 0.097 - valid loss 3.492 - valid acc 0.074\nEpoch 31: train loss 4.178 - train acc 0.094 - valid loss 3.505 - valid acc 0.074\nEpoch 32: train loss 3.427 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 33: train loss 3.424 - train acc 0.103 - valid loss 3.499 - valid acc 0.074\nEpoch 34: train loss 3.429 - train acc 0.103 - valid loss 3.502 - valid acc 0.074\nEpoch 35: train loss 3.444 - train acc 0.107 - valid loss 3.488 - valid acc 0.098\nEpoch 36: train loss 3.424 - train acc 0.099 - valid loss 3.501 - valid acc 0.074\nEpoch 37: train loss 3.424 - train acc 0.105 - valid loss 3.502 - valid acc 0.074\nEpoch 38: train loss 3.431 - train acc 0.103 - valid loss 3.492 - valid acc 0.074\nEpoch 39: train loss 3.424 - train acc 0.106 - valid loss 3.508 - valid acc 0.098\nBest epoch 8, best acc 0.09797297297297297\nTraining with: weight_decay=0.01, label_smoothing=0.01, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9873cf8df6314ca1980f11538a10927c"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.139 - train acc 0.163 - valid loss 3.090 - valid acc 0.162\nEpoch 1: train loss 2.734 - train acc 0.227 - valid loss 2.879 - valid acc 0.196\nEpoch 2: train loss 2.528 - train acc 0.254 - valid loss 2.712 - valid acc 0.236\nEpoch 3: train loss 2.344 - train acc 0.302 - valid loss 2.615 - valid acc 0.257\nEpoch 4: train loss 2.230 - train acc 0.334 - valid loss 2.510 - valid acc 0.277\nEpoch 5: train loss 2.152 - train acc 0.348 - valid loss 2.425 - valid acc 0.287\nEpoch 6: train loss 2.057 - train acc 0.383 - valid loss 2.461 - valid acc 0.291\nEpoch 7: train loss 1.993 - train acc 0.382 - valid loss 2.510 - valid acc 0.284\nEpoch 8: train loss 1.932 - train acc 0.399 - valid loss 2.340 - valid acc 0.314\nEpoch 9: train loss 1.897 - train acc 0.426 - valid loss 2.378 - valid acc 0.294\nEpoch 10: train loss 1.830 - train acc 0.443 - valid loss 2.284 - valid acc 0.331\nEpoch 11: train loss 1.849 - train acc 0.438 - valid loss 2.158 - valid acc 0.351\nEpoch 12: train loss 1.792 - train acc 0.452 - valid loss 2.265 - valid acc 0.328\nEpoch 13: train loss 1.778 - train acc 0.447 - valid loss 2.309 - valid acc 0.351\nEpoch 14: train loss 1.734 - train acc 0.466 - valid loss 2.252 - valid acc 0.338\nEpoch 15: train loss 1.748 - train acc 0.456 - valid loss 2.532 - valid acc 0.253\nEpoch 16: train loss 1.716 - train acc 0.463 - valid loss 2.131 - valid acc 0.321\nEpoch 17: train loss 1.683 - train acc 0.476 - valid loss 2.162 - valid acc 0.338\nEpoch 18: train loss 1.644 - train acc 0.484 - valid loss 2.135 - valid acc 0.351\nEpoch 19: train loss 1.672 - train acc 0.482 - valid loss 2.681 - valid acc 0.247\nEpoch 20: train loss 1.657 - train acc 0.488 - valid loss 2.515 - valid acc 0.301\nEpoch 21: train loss 1.638 - train acc 0.479 - valid loss 2.155 - valid acc 0.331\nEpoch 22: train loss 1.644 - train acc 0.486 - valid loss 2.475 - valid acc 0.301\nEpoch 23: train loss 1.627 - train acc 0.485 - valid loss 2.314 - valid acc 0.307\nEpoch 24: train loss 1.602 - train acc 0.501 - valid loss 2.324 - valid acc 0.324\nEpoch 25: train loss 1.587 - train acc 0.494 - valid loss 2.260 - valid acc 0.287\nEpoch 26: train loss 1.582 - train acc 0.491 - valid loss 2.120 - valid acc 0.361\nEpoch 27: train loss 1.561 - train acc 0.517 - valid loss 2.112 - valid acc 0.351\nEpoch 28: train loss 1.557 - train acc 0.515 - valid loss 2.150 - valid acc 0.341\nEpoch 29: train loss 1.555 - train acc 0.520 - valid loss 2.197 - valid acc 0.328\nEpoch 30: train loss 1.520 - train acc 0.527 - valid loss 2.073 - valid acc 0.345\nEpoch 31: train loss 1.539 - train acc 0.506 - valid loss 2.130 - valid acc 0.297\nEpoch 32: train loss 1.555 - train acc 0.514 - valid loss 2.217 - valid acc 0.314\nEpoch 33: train loss 1.542 - train acc 0.518 - valid loss 2.184 - valid acc 0.284\nEpoch 34: train loss 1.530 - train acc 0.522 - valid loss 2.205 - valid acc 0.294\nEpoch 35: train loss 1.507 - train acc 0.532 - valid loss 2.079 - valid acc 0.355\nEpoch 36: train loss 1.515 - train acc 0.526 - valid loss 2.008 - valid acc 0.358\nEpoch 37: train loss 1.456 - train acc 0.542 - valid loss 2.146 - valid acc 0.385\nEpoch 38: train loss 1.512 - train acc 0.533 - valid loss 2.287 - valid acc 0.314\nEpoch 39: train loss 1.445 - train acc 0.558 - valid loss 2.178 - valid acc 0.324\nBest epoch 37, best acc 0.38513513513513514\nTraining with: weight_decay=0.01, label_smoothing=0.01, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79eac82e956046eebc885610da25acdd"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.552 - train acc 0.091 - valid loss 3.512 - valid acc 0.074\nEpoch 1: train loss 3.445 - train acc 0.095 - valid loss 3.499 - valid acc 0.074\nEpoch 2: train loss 3.442 - train acc 0.103 - valid loss 3.482 - valid acc 0.074\nEpoch 3: train loss 3.441 - train acc 0.102 - valid loss 3.501 - valid acc 0.074\nEpoch 4: train loss 3.443 - train acc 0.099 - valid loss 3.493 - valid acc 0.098\nEpoch 5: train loss 3.440 - train acc 0.105 - valid loss 3.514 - valid acc 0.074\nEpoch 6: train loss 3.440 - train acc 0.103 - valid loss 3.496 - valid acc 0.074\nEpoch 7: train loss 3.439 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 8: train loss 3.440 - train acc 0.096 - valid loss 3.520 - valid acc 0.074\nEpoch 9: train loss 3.441 - train acc 0.106 - valid loss 3.495 - valid acc 0.098\nEpoch 10: train loss 3.452 - train acc 0.106 - valid loss 3.510 - valid acc 0.074\nEpoch 11: train loss 3.439 - train acc 0.095 - valid loss 3.502 - valid acc 0.098\nEpoch 12: train loss 3.436 - train acc 0.104 - valid loss 3.501 - valid acc 0.074\nEpoch 13: train loss 3.434 - train acc 0.102 - valid loss 3.508 - valid acc 0.074\nEpoch 14: train loss 3.432 - train acc 0.103 - valid loss 3.502 - valid acc 0.074\nEpoch 15: train loss 4.331 - train acc 0.097 - valid loss 3.513 - valid acc 0.074\nEpoch 16: train loss 3.555 - train acc 0.105 - valid loss 3.504 - valid acc 0.074\nEpoch 17: train loss 3.431 - train acc 0.105 - valid loss 3.489 - valid acc 0.074\nEpoch 18: train loss 3.431 - train acc 0.103 - valid loss 3.497 - valid acc 0.074\nEpoch 19: train loss 3.432 - train acc 0.099 - valid loss 3.489 - valid acc 0.074\nEpoch 20: train loss 3.474 - train acc 0.104 - valid loss 3.483 - valid acc 0.074\nEpoch 21: train loss 3.428 - train acc 0.104 - valid loss 3.506 - valid acc 0.074\nEpoch 22: train loss 3.439 - train acc 0.092 - valid loss 3.493 - valid acc 0.074\nEpoch 23: train loss 3.644 - train acc 0.102 - valid loss 3.538 - valid acc 0.074\nEpoch 24: train loss 3.447 - train acc 0.104 - valid loss 3.491 - valid acc 0.074\nEpoch 25: train loss 3.431 - train acc 0.098 - valid loss 3.491 - valid acc 0.074\nEpoch 26: train loss 3.433 - train acc 0.101 - valid loss 3.497 - valid acc 0.074\nEpoch 27: train loss 3.479 - train acc 0.101 - valid loss 3.494 - valid acc 0.098\nEpoch 28: train loss 3.430 - train acc 0.098 - valid loss 3.500 - valid acc 0.074\nEpoch 29: train loss 3.432 - train acc 0.100 - valid loss 3.498 - valid acc 0.074\nEpoch 30: train loss 3.433 - train acc 0.101 - valid loss 3.487 - valid acc 0.074\nEpoch 31: train loss 3.427 - train acc 0.105 - valid loss 3.505 - valid acc 0.074\nEpoch 32: train loss 3.489 - train acc 0.094 - valid loss 3.487 - valid acc 0.098\nEpoch 33: train loss 3.432 - train acc 0.097 - valid loss 3.486 - valid acc 0.074\nEpoch 34: train loss 3.428 - train acc 0.098 - valid loss 3.495 - valid acc 0.074\nEpoch 35: train loss 3.431 - train acc 0.102 - valid loss 3.494 - valid acc 0.074\nEpoch 36: train loss 3.431 - train acc 0.104 - valid loss 3.492 - valid acc 0.074\nEpoch 37: train loss 3.430 - train acc 0.098 - valid loss 3.508 - valid acc 0.074\nEpoch 38: train loss 3.428 - train acc 0.099 - valid loss 3.510 - valid acc 0.074\nEpoch 39: train loss 3.430 - train acc 0.102 - valid loss 3.514 - valid acc 0.074\nBest epoch 4, best acc 0.09797297297297297\nTraining with: weight_decay=0.01, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a36a3078c2c46d6a7b30749bd4c5cf7"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.144 - train acc 0.170 - valid loss 3.121 - valid acc 0.145\nEpoch 1: train loss 2.935 - train acc 0.211 - valid loss 2.937 - valid acc 0.179\nEpoch 2: train loss 2.796 - train acc 0.252 - valid loss 2.659 - valid acc 0.253\nEpoch 3: train loss 2.738 - train acc 0.263 - valid loss 2.788 - valid acc 0.226\nEpoch 4: train loss 2.670 - train acc 0.289 - valid loss 2.608 - valid acc 0.230\nEpoch 5: train loss 2.565 - train acc 0.336 - valid loss 2.528 - valid acc 0.307\nEpoch 6: train loss 2.476 - train acc 0.339 - valid loss 2.502 - valid acc 0.304\nEpoch 7: train loss 2.393 - train acc 0.373 - valid loss 2.707 - valid acc 0.240\nEpoch 8: train loss 2.323 - train acc 0.391 - valid loss 2.272 - valid acc 0.328\nEpoch 9: train loss 2.242 - train acc 0.414 - valid loss 2.383 - valid acc 0.280\nEpoch 10: train loss 2.210 - train acc 0.421 - valid loss 2.171 - valid acc 0.314\nEpoch 11: train loss 2.111 - train acc 0.455 - valid loss 2.407 - valid acc 0.294\nEpoch 12: train loss 2.117 - train acc 0.451 - valid loss 2.238 - valid acc 0.338\nEpoch 13: train loss 2.062 - train acc 0.480 - valid loss 2.172 - valid acc 0.358\nEpoch 14: train loss 2.048 - train acc 0.482 - valid loss 2.252 - valid acc 0.318\nEpoch 15: train loss 2.063 - train acc 0.476 - valid loss 2.331 - valid acc 0.311\nEpoch 16: train loss 2.017 - train acc 0.487 - valid loss 2.188 - valid acc 0.331\nEpoch 17: train loss 2.000 - train acc 0.507 - valid loss 2.385 - valid acc 0.324\nEpoch 18: train loss 1.972 - train acc 0.501 - valid loss 2.083 - valid acc 0.361\nEpoch 19: train loss 1.989 - train acc 0.502 - valid loss 2.114 - valid acc 0.368\nEpoch 20: train loss 1.980 - train acc 0.506 - valid loss 2.309 - valid acc 0.311\nEpoch 21: train loss 1.925 - train acc 0.522 - valid loss 2.296 - valid acc 0.324\nEpoch 22: train loss 1.980 - train acc 0.516 - valid loss 2.307 - valid acc 0.321\nEpoch 23: train loss 1.930 - train acc 0.534 - valid loss 2.089 - valid acc 0.382\nEpoch 24: train loss 1.941 - train acc 0.526 - valid loss 2.164 - valid acc 0.378\nEpoch 25: train loss 1.931 - train acc 0.531 - valid loss 2.138 - valid acc 0.348\nEpoch 26: train loss 1.902 - train acc 0.546 - valid loss 2.299 - valid acc 0.341\nEpoch 27: train loss 1.911 - train acc 0.523 - valid loss 2.141 - valid acc 0.382\nEpoch 28: train loss 1.901 - train acc 0.540 - valid loss 2.168 - valid acc 0.348\nEpoch 29: train loss 1.909 - train acc 0.538 - valid loss 2.231 - valid acc 0.324\nEpoch 30: train loss 1.930 - train acc 0.528 - valid loss 2.154 - valid acc 0.324\nEpoch 31: train loss 1.887 - train acc 0.549 - valid loss 2.075 - valid acc 0.328\nEpoch 32: train loss 1.893 - train acc 0.559 - valid loss 2.158 - valid acc 0.307\nEpoch 33: train loss 1.853 - train acc 0.563 - valid loss 2.052 - valid acc 0.382\nEpoch 34: train loss 1.880 - train acc 0.550 - valid loss 2.127 - valid acc 0.368\nEpoch 35: train loss 1.832 - train acc 0.567 - valid loss 2.122 - valid acc 0.361\nEpoch 36: train loss 1.877 - train acc 0.551 - valid loss 2.302 - valid acc 0.338\nEpoch 37: train loss 1.854 - train acc 0.573 - valid loss 2.264 - valid acc 0.338\nEpoch 38: train loss 1.838 - train acc 0.558 - valid loss 2.227 - valid acc 0.348\nEpoch 39: train loss 1.829 - train acc 0.559 - valid loss 2.164 - valid acc 0.331\nBest epoch 23, best acc 0.38175675675675674\nTraining with: weight_decay=0.01, label_smoothing=0.1, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9555d057c1954883b019045ae34bca8e"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.561 - train acc 0.103 - valid loss 3.500 - valid acc 0.074\nEpoch 1: train loss 3.498 - train acc 0.097 - valid loss 3.496 - valid acc 0.074\nEpoch 2: train loss 3.499 - train acc 0.103 - valid loss 3.502 - valid acc 0.098\nEpoch 3: train loss 3.489 - train acc 0.101 - valid loss 3.522 - valid acc 0.098\nEpoch 4: train loss 3.489 - train acc 0.105 - valid loss 3.487 - valid acc 0.074\nEpoch 5: train loss 3.492 - train acc 0.105 - valid loss 3.496 - valid acc 0.074\nEpoch 6: train loss 3.489 - train acc 0.102 - valid loss 3.494 - valid acc 0.098\nEpoch 7: train loss 3.550 - train acc 0.095 - valid loss 3.496 - valid acc 0.074\nEpoch 8: train loss 3.489 - train acc 0.099 - valid loss 3.504 - valid acc 0.074\nEpoch 9: train loss 3.491 - train acc 0.100 - valid loss 3.511 - valid acc 0.074\nEpoch 10: train loss 3.489 - train acc 0.101 - valid loss 3.494 - valid acc 0.074\nEpoch 11: train loss 3.486 - train acc 0.097 - valid loss 3.510 - valid acc 0.074\nEpoch 12: train loss 3.488 - train acc 0.099 - valid loss 3.506 - valid acc 0.074\nEpoch 13: train loss 3.493 - train acc 0.097 - valid loss 3.504 - valid acc 0.074\nEpoch 14: train loss 3.593 - train acc 0.105 - valid loss 3.492 - valid acc 0.098\nEpoch 15: train loss 3.550 - train acc 0.105 - valid loss 3.498 - valid acc 0.098\nEpoch 16: train loss 3.504 - train acc 0.105 - valid loss 3.494 - valid acc 0.098\nEpoch 17: train loss 3.508 - train acc 0.096 - valid loss 3.493 - valid acc 0.074\nEpoch 18: train loss 3.486 - train acc 0.101 - valid loss 3.501 - valid acc 0.098\nEpoch 19: train loss 3.490 - train acc 0.103 - valid loss 3.491 - valid acc 0.098\nEpoch 20: train loss 3.488 - train acc 0.100 - valid loss 3.496 - valid acc 0.098\nEpoch 21: train loss 3.489 - train acc 0.100 - valid loss 3.508 - valid acc 0.074\nEpoch 22: train loss 3.539 - train acc 0.102 - valid loss 3.496 - valid acc 0.074\nEpoch 23: train loss 3.487 - train acc 0.103 - valid loss 3.503 - valid acc 0.074\nEpoch 24: train loss 3.486 - train acc 0.108 - valid loss 3.503 - valid acc 0.098\nEpoch 25: train loss 3.486 - train acc 0.103 - valid loss 3.498 - valid acc 0.098\nEpoch 26: train loss 3.485 - train acc 0.097 - valid loss 3.484 - valid acc 0.074\nEpoch 27: train loss 3.485 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 28: train loss 3.487 - train acc 0.101 - valid loss 3.492 - valid acc 0.074\nEpoch 29: train loss 4.081 - train acc 0.102 - valid loss 3.488 - valid acc 0.074\nEpoch 30: train loss 3.501 - train acc 0.099 - valid loss 3.490 - valid acc 0.074\nEpoch 31: train loss 3.523 - train acc 0.101 - valid loss 3.516 - valid acc 0.074\nEpoch 32: train loss 3.486 - train acc 0.098 - valid loss 3.500 - valid acc 0.074\nEpoch 33: train loss 3.487 - train acc 0.103 - valid loss 3.489 - valid acc 0.074\nEpoch 34: train loss 3.711 - train acc 0.090 - valid loss 3.512 - valid acc 0.074\nEpoch 35: train loss 3.772 - train acc 0.101 - valid loss 3.489 - valid acc 0.098\nEpoch 36: train loss 3.484 - train acc 0.094 - valid loss 3.491 - valid acc 0.074\nEpoch 37: train loss 3.486 - train acc 0.100 - valid loss 3.502 - valid acc 0.098\nEpoch 38: train loss 3.746 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 39: train loss 3.485 - train acc 0.101 - valid loss 3.498 - valid acc 0.074\nBest epoch 2, best acc 0.09797297297297297\nTraining with: weight_decay=0.001, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1fab4046e44e388b6a56e828553567"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.024 - train acc 0.181 - valid loss 2.916 - valid acc 0.172\nEpoch 1: train loss 2.454 - train acc 0.275 - valid loss 2.659 - valid acc 0.203\nEpoch 2: train loss 2.091 - train acc 0.350 - valid loss 2.659 - valid acc 0.206\nEpoch 3: train loss 1.845 - train acc 0.406 - valid loss 2.342 - valid acc 0.287\nEpoch 4: train loss 1.715 - train acc 0.454 - valid loss 2.055 - valid acc 0.338\nEpoch 5: train loss 1.580 - train acc 0.481 - valid loss 2.004 - valid acc 0.368\nEpoch 6: train loss 1.515 - train acc 0.500 - valid loss 2.255 - valid acc 0.318\nEpoch 7: train loss 1.435 - train acc 0.531 - valid loss 2.280 - valid acc 0.297\nEpoch 8: train loss 1.383 - train acc 0.546 - valid loss 2.590 - valid acc 0.291\nEpoch 9: train loss 1.334 - train acc 0.567 - valid loss 2.224 - valid acc 0.294\nEpoch 10: train loss 1.252 - train acc 0.577 - valid loss 2.103 - valid acc 0.334\nEpoch 11: train loss 1.254 - train acc 0.582 - valid loss 2.451 - valid acc 0.334\nEpoch 12: train loss 1.217 - train acc 0.603 - valid loss 2.253 - valid acc 0.341\nEpoch 13: train loss 1.169 - train acc 0.614 - valid loss 1.892 - valid acc 0.422\nEpoch 14: train loss 1.145 - train acc 0.624 - valid loss 1.924 - valid acc 0.395\nEpoch 15: train loss 1.083 - train acc 0.633 - valid loss 1.936 - valid acc 0.402\nEpoch 16: train loss 1.041 - train acc 0.662 - valid loss 2.349 - valid acc 0.395\nEpoch 17: train loss 1.079 - train acc 0.642 - valid loss 2.071 - valid acc 0.378\nEpoch 18: train loss 1.054 - train acc 0.644 - valid loss 2.062 - valid acc 0.412\nEpoch 19: train loss 1.022 - train acc 0.658 - valid loss 2.080 - valid acc 0.419\nEpoch 20: train loss 0.979 - train acc 0.667 - valid loss 2.013 - valid acc 0.399\nEpoch 21: train loss 0.956 - train acc 0.676 - valid loss 2.052 - valid acc 0.385\nEpoch 22: train loss 0.946 - train acc 0.681 - valid loss 2.366 - valid acc 0.378\nEpoch 23: train loss 0.925 - train acc 0.689 - valid loss 2.208 - valid acc 0.402\nEpoch 24: train loss 0.939 - train acc 0.679 - valid loss 2.305 - valid acc 0.382\nEpoch 25: train loss 0.914 - train acc 0.695 - valid loss 2.140 - valid acc 0.375\nEpoch 26: train loss 0.885 - train acc 0.703 - valid loss 2.250 - valid acc 0.375\nEpoch 27: train loss 0.893 - train acc 0.698 - valid loss 2.377 - valid acc 0.348\nEpoch 28: train loss 0.857 - train acc 0.717 - valid loss 2.230 - valid acc 0.453\nEpoch 29: train loss 0.878 - train acc 0.711 - valid loss 2.076 - valid acc 0.470\nEpoch 30: train loss 0.849 - train acc 0.711 - valid loss 2.495 - valid acc 0.412\nEpoch 31: train loss 0.825 - train acc 0.723 - valid loss 2.254 - valid acc 0.443\nEpoch 32: train loss 0.875 - train acc 0.714 - valid loss 2.337 - valid acc 0.348\nEpoch 33: train loss 0.829 - train acc 0.731 - valid loss 1.906 - valid acc 0.439\nEpoch 34: train loss 0.784 - train acc 0.739 - valid loss 2.159 - valid acc 0.449\nEpoch 35: train loss 0.810 - train acc 0.734 - valid loss 2.427 - valid acc 0.389\nEpoch 36: train loss 0.820 - train acc 0.737 - valid loss 2.566 - valid acc 0.436\nEpoch 37: train loss 0.766 - train acc 0.746 - valid loss 2.270 - valid acc 0.412\nEpoch 38: train loss 0.797 - train acc 0.746 - valid loss 2.263 - valid acc 0.416\nEpoch 39: train loss 0.758 - train acc 0.754 - valid loss 2.357 - valid acc 0.368\nBest epoch 29, best acc 0.46959459459459457\nTraining with: weight_decay=0.001, label_smoothing=0.0, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d8becf18bc4a849a0f5887739f2145"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.558 - train acc 0.101 - valid loss 3.505 - valid acc 0.074\nEpoch 1: train loss 3.431 - train acc 0.103 - valid loss 3.521 - valid acc 0.074\nEpoch 2: train loss 3.429 - train acc 0.102 - valid loss 3.497 - valid acc 0.098\nEpoch 3: train loss 3.427 - train acc 0.102 - valid loss 3.498 - valid acc 0.074\nEpoch 4: train loss 3.430 - train acc 0.102 - valid loss 3.501 - valid acc 0.074\nEpoch 5: train loss 3.423 - train acc 0.102 - valid loss 3.512 - valid acc 0.074\nEpoch 6: train loss 3.423 - train acc 0.105 - valid loss 3.516 - valid acc 0.074\nEpoch 7: train loss 3.421 - train acc 0.107 - valid loss 3.505 - valid acc 0.098\nEpoch 8: train loss 3.421 - train acc 0.100 - valid loss 3.496 - valid acc 0.074\nEpoch 9: train loss 3.425 - train acc 0.099 - valid loss 3.496 - valid acc 0.074\nEpoch 10: train loss 3.415 - train acc 0.100 - valid loss 3.501 - valid acc 0.074\nEpoch 11: train loss 3.415 - train acc 0.100 - valid loss 3.494 - valid acc 0.074\nEpoch 12: train loss 3.417 - train acc 0.104 - valid loss 3.491 - valid acc 0.074\nEpoch 13: train loss 3.414 - train acc 0.103 - valid loss 3.495 - valid acc 0.074\nEpoch 14: train loss 3.412 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 15: train loss 3.412 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 16: train loss 3.413 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 17: train loss 3.412 - train acc 0.102 - valid loss 3.499 - valid acc 0.074\nEpoch 18: train loss 3.412 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 19: train loss 3.412 - train acc 0.104 - valid loss 3.495 - valid acc 0.074\nEpoch 20: train loss 3.412 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 21: train loss 3.413 - train acc 0.102 - valid loss 3.494 - valid acc 0.074\nEpoch 22: train loss 3.412 - train acc 0.100 - valid loss 3.501 - valid acc 0.074\nEpoch 23: train loss 3.413 - train acc 0.105 - valid loss 3.487 - valid acc 0.074\nEpoch 24: train loss 3.412 - train acc 0.105 - valid loss 3.499 - valid acc 0.074\nEpoch 25: train loss 3.412 - train acc 0.103 - valid loss 3.495 - valid acc 0.074\nEpoch 26: train loss 3.413 - train acc 0.102 - valid loss 3.497 - valid acc 0.074\nEpoch 27: train loss 3.634 - train acc 0.103 - valid loss 3.498 - valid acc 0.074\nEpoch 28: train loss 3.452 - train acc 0.104 - valid loss 3.497 - valid acc 0.074\nEpoch 29: train loss 3.479 - train acc 0.102 - valid loss 3.497 - valid acc 0.074\nEpoch 30: train loss 3.413 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 31: train loss 3.412 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 32: train loss 3.412 - train acc 0.105 - valid loss 3.494 - valid acc 0.074\nEpoch 33: train loss 3.413 - train acc 0.102 - valid loss 3.492 - valid acc 0.074\nEpoch 34: train loss 3.586 - train acc 0.096 - valid loss 3.497 - valid acc 0.074\nEpoch 35: train loss 3.412 - train acc 0.105 - valid loss 3.493 - valid acc 0.074\nEpoch 36: train loss 3.413 - train acc 0.104 - valid loss 3.498 - valid acc 0.074\nEpoch 37: train loss 3.413 - train acc 0.105 - valid loss 3.500 - valid acc 0.074\nEpoch 38: train loss 3.593 - train acc 0.106 - valid loss 3.491 - valid acc 0.074\nEpoch 39: train loss 3.414 - train acc 0.104 - valid loss 3.516 - valid acc 0.098\nBest epoch 2, best acc 0.09797297297297297\nTraining with: weight_decay=0.001, label_smoothing=0.01, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8ad2dbf5dc4ca780b0623f7c607b84"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 2.988 - train acc 0.183 - valid loss 2.851 - valid acc 0.186\nEpoch 1: train loss 2.423 - train acc 0.275 - valid loss 2.459 - valid acc 0.284\nEpoch 2: train loss 2.082 - train acc 0.372 - valid loss 2.480 - valid acc 0.301\nEpoch 3: train loss 1.816 - train acc 0.438 - valid loss 2.526 - valid acc 0.264\nEpoch 4: train loss 1.682 - train acc 0.483 - valid loss 2.286 - valid acc 0.341\nEpoch 5: train loss 1.569 - train acc 0.508 - valid loss 2.509 - valid acc 0.311\nEpoch 6: train loss 1.463 - train acc 0.541 - valid loss 2.214 - valid acc 0.355\nEpoch 7: train loss 1.460 - train acc 0.534 - valid loss 2.127 - valid acc 0.385\nEpoch 8: train loss 1.381 - train acc 0.559 - valid loss 2.216 - valid acc 0.375\nEpoch 9: train loss 1.322 - train acc 0.589 - valid loss 2.541 - valid acc 0.345\nEpoch 10: train loss 1.312 - train acc 0.597 - valid loss 2.209 - valid acc 0.331\nEpoch 11: train loss 1.285 - train acc 0.603 - valid loss 2.417 - valid acc 0.328\nEpoch 12: train loss 1.252 - train acc 0.613 - valid loss 2.197 - valid acc 0.389\nEpoch 13: train loss 1.261 - train acc 0.609 - valid loss 2.127 - valid acc 0.324\nEpoch 14: train loss 1.184 - train acc 0.636 - valid loss 2.205 - valid acc 0.385\nEpoch 15: train loss 1.198 - train acc 0.643 - valid loss 2.114 - valid acc 0.368\nEpoch 16: train loss 1.154 - train acc 0.647 - valid loss 2.239 - valid acc 0.378\nEpoch 17: train loss 1.128 - train acc 0.658 - valid loss 2.156 - valid acc 0.361\nEpoch 18: train loss 1.126 - train acc 0.667 - valid loss 2.166 - valid acc 0.409\nEpoch 19: train loss 1.078 - train acc 0.675 - valid loss 2.332 - valid acc 0.365\nEpoch 20: train loss 1.084 - train acc 0.672 - valid loss 2.194 - valid acc 0.416\nEpoch 21: train loss 1.110 - train acc 0.671 - valid loss 2.094 - valid acc 0.429\nEpoch 22: train loss 1.028 - train acc 0.698 - valid loss 1.985 - valid acc 0.426\nEpoch 23: train loss 1.058 - train acc 0.689 - valid loss 2.182 - valid acc 0.378\nEpoch 24: train loss 1.014 - train acc 0.699 - valid loss 2.152 - valid acc 0.365\nEpoch 25: train loss 1.030 - train acc 0.684 - valid loss 2.112 - valid acc 0.402\nEpoch 26: train loss 1.029 - train acc 0.702 - valid loss 2.073 - valid acc 0.368\nEpoch 27: train loss 0.981 - train acc 0.704 - valid loss 2.387 - valid acc 0.405\nEpoch 28: train loss 0.959 - train acc 0.710 - valid loss 2.283 - valid acc 0.395\nEpoch 29: train loss 0.981 - train acc 0.710 - valid loss 2.332 - valid acc 0.395\nEpoch 30: train loss 0.957 - train acc 0.703 - valid loss 2.121 - valid acc 0.375\nEpoch 31: train loss 0.921 - train acc 0.720 - valid loss 2.250 - valid acc 0.399\nEpoch 32: train loss 0.915 - train acc 0.733 - valid loss 2.091 - valid acc 0.514\nEpoch 33: train loss 0.945 - train acc 0.719 - valid loss 2.274 - valid acc 0.382\nEpoch 34: train loss 0.943 - train acc 0.726 - valid loss 2.091 - valid acc 0.432\nEpoch 35: train loss 0.940 - train acc 0.722 - valid loss 2.584 - valid acc 0.422\nEpoch 36: train loss 0.910 - train acc 0.736 - valid loss 2.427 - valid acc 0.382\nEpoch 37: train loss 0.859 - train acc 0.745 - valid loss 2.432 - valid acc 0.382\nEpoch 38: train loss 0.874 - train acc 0.738 - valid loss 2.153 - valid acc 0.392\nEpoch 39: train loss 0.901 - train acc 0.742 - valid loss 2.190 - valid acc 0.426\nBest epoch 32, best acc 0.5135135135135135\nTraining with: weight_decay=0.001, label_smoothing=0.01, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ee467cf7d6c446fbe39947a0989b076"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.696 - train acc 0.124 - valid loss 3.309 - valid acc 0.095\nEpoch 1: train loss 3.123 - train acc 0.159 - valid loss 3.248 - valid acc 0.152\nEpoch 2: train loss 2.995 - train acc 0.172 - valid loss 3.181 - valid acc 0.118\nEpoch 3: train loss 2.962 - train acc 0.185 - valid loss 3.197 - valid acc 0.176\nEpoch 4: train loss 2.956 - train acc 0.175 - valid loss 3.143 - valid acc 0.125\nEpoch 5: train loss 2.936 - train acc 0.185 - valid loss 3.226 - valid acc 0.145\nEpoch 6: train loss 2.930 - train acc 0.195 - valid loss 3.355 - valid acc 0.098\nEpoch 7: train loss 2.931 - train acc 0.195 - valid loss 3.216 - valid acc 0.095\nEpoch 8: train loss 2.924 - train acc 0.198 - valid loss 3.179 - valid acc 0.145\nEpoch 9: train loss 4.750 - train acc 0.165 - valid loss 3.529 - valid acc 0.098\nEpoch 10: train loss 3.447 - train acc 0.102 - valid loss 3.488 - valid acc 0.074\nEpoch 11: train loss 3.445 - train acc 0.105 - valid loss 3.491 - valid acc 0.074\nEpoch 12: train loss 3.419 - train acc 0.102 - valid loss 3.496 - valid acc 0.074\nEpoch 13: train loss 3.421 - train acc 0.106 - valid loss 3.491 - valid acc 0.074\nEpoch 14: train loss 3.419 - train acc 0.102 - valid loss 3.498 - valid acc 0.074\nEpoch 15: train loss 3.478 - train acc 0.100 - valid loss 3.493 - valid acc 0.074\nEpoch 16: train loss 3.423 - train acc 0.102 - valid loss 3.496 - valid acc 0.074\nEpoch 17: train loss 3.432 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 18: train loss 3.420 - train acc 0.104 - valid loss 3.506 - valid acc 0.074\nEpoch 19: train loss 3.441 - train acc 0.105 - valid loss 3.491 - valid acc 0.074\nEpoch 20: train loss 3.419 - train acc 0.103 - valid loss 3.496 - valid acc 0.074\nEpoch 21: train loss 3.623 - train acc 0.102 - valid loss 3.494 - valid acc 0.074\nEpoch 22: train loss 3.419 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 23: train loss 3.418 - train acc 0.103 - valid loss 3.501 - valid acc 0.074\nEpoch 24: train loss 3.419 - train acc 0.105 - valid loss 3.501 - valid acc 0.074\nEpoch 25: train loss 3.418 - train acc 0.105 - valid loss 3.498 - valid acc 0.074\nEpoch 26: train loss 3.676 - train acc 0.098 - valid loss 3.500 - valid acc 0.074\nEpoch 27: train loss 3.419 - train acc 0.100 - valid loss 3.502 - valid acc 0.074\nEpoch 28: train loss 3.418 - train acc 0.105 - valid loss 3.499 - valid acc 0.074\nEpoch 29: train loss 3.418 - train acc 0.108 - valid loss 3.498 - valid acc 0.074\nEpoch 30: train loss 3.419 - train acc 0.105 - valid loss 3.498 - valid acc 0.074\nEpoch 31: train loss 3.476 - train acc 0.105 - valid loss 3.496 - valid acc 0.074\nEpoch 32: train loss 3.419 - train acc 0.101 - valid loss 3.500 - valid acc 0.074\nEpoch 33: train loss 3.420 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 34: train loss 3.419 - train acc 0.103 - valid loss 3.497 - valid acc 0.074\nEpoch 35: train loss 3.419 - train acc 0.105 - valid loss 3.497 - valid acc 0.074\nEpoch 36: train loss 4.147 - train acc 0.103 - valid loss 3.503 - valid acc 0.074\nEpoch 37: train loss 3.420 - train acc 0.101 - valid loss 3.497 - valid acc 0.074\nEpoch 38: train loss 3.419 - train acc 0.101 - valid loss 3.505 - valid acc 0.074\nEpoch 39: train loss 3.419 - train acc 0.105 - valid loss 3.499 - valid acc 0.074\nBest epoch 3, best acc 0.17567567567567569\nTraining with: weight_decay=0.001, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bff2b31ace4703b7d1ccbaf46865cf"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.130 - train acc 0.203 - valid loss 2.834 - valid acc 0.274\nEpoch 1: train loss 2.599 - train acc 0.333 - valid loss 2.499 - valid acc 0.301\nEpoch 2: train loss 2.366 - train acc 0.392 - valid loss 2.462 - valid acc 0.280\nEpoch 3: train loss 2.211 - train acc 0.445 - valid loss 2.338 - valid acc 0.331\nEpoch 4: train loss 2.126 - train acc 0.461 - valid loss 2.352 - valid acc 0.277\nEpoch 5: train loss 2.021 - train acc 0.504 - valid loss 2.088 - valid acc 0.392\nEpoch 6: train loss 1.934 - train acc 0.539 - valid loss 2.109 - valid acc 0.358\nEpoch 7: train loss 1.917 - train acc 0.542 - valid loss 1.973 - valid acc 0.419\nEpoch 8: train loss 1.831 - train acc 0.579 - valid loss 2.247 - valid acc 0.307\nEpoch 9: train loss 1.802 - train acc 0.591 - valid loss 2.450 - valid acc 0.311\nEpoch 10: train loss 1.776 - train acc 0.587 - valid loss 2.137 - valid acc 0.358\nEpoch 11: train loss 1.728 - train acc 0.619 - valid loss 2.249 - valid acc 0.331\nEpoch 12: train loss 1.694 - train acc 0.634 - valid loss 2.023 - valid acc 0.409\nEpoch 13: train loss 1.671 - train acc 0.649 - valid loss 2.200 - valid acc 0.361\nEpoch 14: train loss 1.656 - train acc 0.650 - valid loss 2.043 - valid acc 0.392\nEpoch 15: train loss 1.628 - train acc 0.652 - valid loss 2.151 - valid acc 0.412\nEpoch 16: train loss 1.620 - train acc 0.674 - valid loss 2.403 - valid acc 0.314\nEpoch 17: train loss 1.559 - train acc 0.683 - valid loss 2.185 - valid acc 0.436\nEpoch 18: train loss 1.579 - train acc 0.682 - valid loss 2.358 - valid acc 0.338\nEpoch 19: train loss 1.553 - train acc 0.693 - valid loss 2.074 - valid acc 0.361\nEpoch 20: train loss 1.556 - train acc 0.693 - valid loss 1.983 - valid acc 0.429\nEpoch 21: train loss 1.524 - train acc 0.698 - valid loss 1.895 - valid acc 0.449\nEpoch 22: train loss 1.487 - train acc 0.719 - valid loss 2.231 - valid acc 0.331\nEpoch 23: train loss 1.500 - train acc 0.709 - valid loss 2.025 - valid acc 0.463\nEpoch 24: train loss 1.479 - train acc 0.724 - valid loss 1.977 - valid acc 0.426\nEpoch 25: train loss 1.490 - train acc 0.713 - valid loss 2.087 - valid acc 0.412\nEpoch 26: train loss 1.494 - train acc 0.712 - valid loss 2.142 - valid acc 0.392\nEpoch 27: train loss 1.455 - train acc 0.726 - valid loss 1.834 - valid acc 0.514\nEpoch 28: train loss 1.439 - train acc 0.734 - valid loss 2.081 - valid acc 0.412\nEpoch 29: train loss 1.449 - train acc 0.728 - valid loss 2.070 - valid acc 0.432\nEpoch 30: train loss 1.462 - train acc 0.737 - valid loss 2.094 - valid acc 0.419\nEpoch 31: train loss 1.445 - train acc 0.739 - valid loss 1.879 - valid acc 0.439\nEpoch 32: train loss 1.410 - train acc 0.758 - valid loss 2.026 - valid acc 0.470\nEpoch 33: train loss 1.430 - train acc 0.746 - valid loss 2.110 - valid acc 0.358\nEpoch 34: train loss 1.430 - train acc 0.750 - valid loss 2.015 - valid acc 0.436\nEpoch 35: train loss 1.415 - train acc 0.756 - valid loss 1.957 - valid acc 0.456\nEpoch 36: train loss 1.421 - train acc 0.742 - valid loss 2.024 - valid acc 0.470\nEpoch 37: train loss 1.385 - train acc 0.755 - valid loss 1.957 - valid acc 0.409\nEpoch 38: train loss 1.396 - train acc 0.758 - valid loss 1.959 - valid acc 0.470\nEpoch 39: train loss 1.386 - train acc 0.750 - valid loss 2.083 - valid acc 0.409\nBest epoch 27, best acc 0.5135135135135135\nTraining with: weight_decay=0.001, label_smoothing=0.1, lr=0.01, channels=16, batch_size=8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1073acca30a04deca21bb86ecb848fb9"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: train loss 3.407 - train acc 0.143 - valid loss 3.371 - valid acc 0.182\nEpoch 1: train loss 3.177 - train acc 0.176 - valid loss 3.223 - valid acc 0.155\nEpoch 2: train loss 3.143 - train acc 0.178 - valid loss 3.188 - valid acc 0.139\nEpoch 3: train loss 3.377 - train acc 0.152 - valid loss 3.523 - valid acc 0.074\nEpoch 4: train loss 3.494 - train acc 0.104 - valid loss 3.485 - valid acc 0.074\nEpoch 5: train loss 3.477 - train acc 0.102 - valid loss 3.493 - valid acc 0.074\nEpoch 6: train loss 3.476 - train acc 0.102 - valid loss 3.495 - valid acc 0.074\nEpoch 7: train loss 3.476 - train acc 0.101 - valid loss 3.492 - valid acc 0.074\nEpoch 8: train loss 3.477 - train acc 0.105 - valid loss 3.491 - valid acc 0.074\nEpoch 9: train loss 3.660 - train acc 0.109 - valid loss 3.493 - valid acc 0.074\nEpoch 10: train loss 3.476 - train acc 0.102 - valid loss 3.496 - valid acc 0.074\nEpoch 11: train loss 3.477 - train acc 0.105 - valid loss 3.494 - valid acc 0.074\nEpoch 12: train loss 3.475 - train acc 0.103 - valid loss 3.501 - valid acc 0.074\nEpoch 13: train loss 3.476 - train acc 0.105 - valid loss 3.498 - valid acc 0.074\nEpoch 14: train loss 3.480 - train acc 0.104 - valid loss 3.489 - valid acc 0.074\nEpoch 15: train loss 3.476 - train acc 0.105 - valid loss 3.489 - valid acc 0.074\nEpoch 16: train loss 3.475 - train acc 0.103 - valid loss 3.498 - valid acc 0.074\nEpoch 17: train loss 3.475 - train acc 0.105 - valid loss 3.495 - valid acc 0.074\nEpoch 18: train loss 3.475 - train acc 0.105 - valid loss 3.491 - valid acc 0.074\nEpoch 19: train loss 3.476 - train acc 0.105 - valid loss 3.492 - valid acc 0.074\nEpoch 20: train loss 3.550 - train acc 0.102 - valid loss 3.491 - valid acc 0.074\nEpoch 21: train loss 3.475 - train acc 0.103 - valid loss 3.493 - valid acc 0.074\nEpoch 22: train loss 3.475 - train acc 0.105 - valid loss 3.491 - valid acc 0.074\nEpoch 23: train loss 3.590 - train acc 0.106 - valid loss 3.490 - valid acc 0.074\nEpoch 24: train loss 3.477 - train acc 0.105 - valid loss 3.490 - valid acc 0.074\nEpoch 25: train loss 3.475 - train acc 0.098 - valid loss 3.489 - valid acc 0.074\nEpoch 26: train loss 3.476 - train acc 0.096 - valid loss 3.494 - valid acc 0.074\nEpoch 27: train loss 3.476 - train acc 0.103 - valid loss 3.496 - valid acc 0.074\nEpoch 28: train loss 3.540 - train acc 0.105 - valid loss 3.494 - valid acc 0.074\nEpoch 29: train loss 3.475 - train acc 0.104 - valid loss 3.492 - valid acc 0.074\nEpoch 30: train loss 3.475 - train acc 0.102 - valid loss 3.493 - valid acc 0.074\nEpoch 31: train loss 3.476 - train acc 0.105 - valid loss 3.498 - valid acc 0.074\nEpoch 32: train loss 3.483 - train acc 0.106 - valid loss 3.498 - valid acc 0.074\nEpoch 33: train loss 3.749 - train acc 0.105 - valid loss 3.487 - valid acc 0.074\nEpoch 34: train loss 3.478 - train acc 0.105 - valid loss 3.493 - valid acc 0.074\nEpoch 35: train loss 3.475 - train acc 0.103 - valid loss 3.487 - valid acc 0.074\nEpoch 36: train loss 3.476 - train acc 0.105 - valid loss 3.488 - valid acc 0.074\nEpoch 37: train loss 3.475 - train acc 0.103 - valid loss 3.497 - valid acc 0.074\nEpoch 38: train loss 3.506 - train acc 0.102 - valid loss 3.489 - valid acc 0.074\nEpoch 39: train loss 3.476 - train acc 0.102 - valid loss 3.490 - valid acc 0.074\nBest epoch 0, best acc 0.18243243243243243\n","output_type":"stream"}]}]}