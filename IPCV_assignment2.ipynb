{"cells":[{"cell_type":"markdown","metadata":{"id":"MNBgGYg_lpVN"},"source":["# Assignment Module 2: Product Classification\n","\n","The goal of this assignment is to implement a neural network that classifies smartphone pictures of products found in grocery stores. The assignment will be divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch.\n"]},{"cell_type":"markdown","metadata":{"id":"dVTQUJ4uYH1w"},"source":["## Preliminaries: the dataset\n","\n","The dataset you will be using contains natural images of products taken with a smartphone camera in different grocery stores:\n","\n","<p align=\"center\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Granny-Smith.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Pink-Lady.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Lemon.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Banana.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Vine-Tomato.jpg\" width=\"150\">\n","</p>\n","<p align=\"center\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Yellow-Onion.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Green-Bell-Pepper.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Arla-Standard-Milk.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Oatly-Natural-Oatghurt.jpg\" width=\"150\">\n","  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Alpro-Fresh-Soy-Milk.jpg\" width=\"150\">\n","</p>\n","\n","The products belong to the following 43 classes:\n","```\n","0.  Apple\n","1.  Avocado\n","2.  Banana\n","3.  Kiwi\n","4.  Lemon\n","5.  Lime\n","6.  Mango\n","7.  Melon\n","8.  Nectarine\n","9.  Orange\n","10. Papaya\n","11. Passion-Fruit\n","12. Peach\n","13. Pear\n","14. Pineapple\n","15. Plum\n","16. Pomegranate\n","17. Red-Grapefruit\n","18. Satsumas\n","19. Juice\n","20. Milk\n","21. Oatghurt\n","22. Oat-Milk\n","23. Sour-Cream\n","24. Sour-Milk\n","25. Soyghurt\n","26. Soy-Milk\n","27. Yoghurt\n","28. Asparagus\n","29. Aubergine\n","30. Cabbage\n","31. Carrots\n","32. Cucumber\n","33. Garlic\n","34. Ginger\n","35. Leek\n","36. Mushroom\n","37. Onion\n","38. Pepper\n","39. Potato\n","40. Red-Beet\n","41. Tomato\n","42. Zucchini\n","```\n","\n","The dataset is split into training (`train`), validation (`val`), and test (`test`) set."]},{"cell_type":"markdown","metadata":{"id":"1pdrmJRnJPd8"},"source":["The following code cells download the dataset and define a `torch.utils.data.Dataset` class to access it. This `Dataset` class will be the starting point of your assignment: use it in your own code and build everything else around it."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-06T07:17:01.404011Z","iopub.status.busy":"2024-07-06T07:17:01.403009Z","iopub.status.idle":"2024-07-06T07:17:12.053264Z","shell.execute_reply":"2024-07-06T07:17:12.052332Z","shell.execute_reply.started":"2024-07-06T07:17:01.403976Z"},"id":"POMX_3x-_bZI","outputId":"fca1c913-e28d-4d56-8973-197218d7cd04","trusted":true},"outputs":[],"source":["#!git clone https://github.com/marcusklasson/GroceryStoreDataset.git"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-06T07:17:12.056104Z","iopub.status.busy":"2024-07-06T07:17:12.055639Z","iopub.status.idle":"2024-07-06T07:17:16.806954Z","shell.execute_reply":"2024-07-06T07:17:16.806008Z","shell.execute_reply.started":"2024-07-06T07:17:12.056066Z"},"id":"Q4bU2LAr_LPh","outputId":"367bc232-77af-470b-9bf6-73864b6d9201","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]}],"source":["from pathlib import Path\n","from PIL import Image\n","from typing import List, Tuple\n","\n","import torch\n","from torch import Tensor,device\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import Adam, SGD, AdamW\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torchvision\n","\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import random\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(f\"Device: {device}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:17:16.808755Z","iopub.status.busy":"2024-07-06T07:17:16.808253Z","iopub.status.idle":"2024-07-06T07:17:16.818672Z","shell.execute_reply":"2024-07-06T07:17:16.817790Z","shell.execute_reply.started":"2024-07-06T07:17:16.808723Z"},"id":"yWGsm5z5qos9","trusted":true},"outputs":[],"source":["def fix_random(seed: int) -> None:\n","    \"\"\"Fix all the possible sources of randomness.\n","\n","    Args:\n","        seed: the seed to use.\n","    \"\"\"\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","fix_random(45)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:17:16.821881Z","iopub.status.busy":"2024-07-06T07:17:16.821126Z","iopub.status.idle":"2024-07-06T07:17:16.831074Z","shell.execute_reply":"2024-07-06T07:17:16.830071Z","shell.execute_reply.started":"2024-07-06T07:17:16.821856Z"},"id":"jROSO2qVDxdD","trusted":true},"outputs":[],"source":["class GroceryStoreDataset(Dataset):\n","\n","    def __init__(self, split: str, transform=None) -> None:\n","        super().__init__()\n","\n","        self.root = Path(\"GroceryStoreDataset/dataset\")\n","        self.split = split\n","        self.paths, self.labels = self.read_file()\n","\n","        self.transform = transform\n","\n","    def __len__(self) -> int:\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n","        img = Image.open(self.root / self.paths[idx])\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","    def read_file(self) -> Tuple[List[str], List[int]]:\n","        paths = []\n","        labels = []\n","\n","        with open(self.root / f\"{self.split}.txt\") as f:\n","            for line in f:\n","                # path, fine-grained class, coarse-grained class\n","                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n","                paths.append(path), labels.append(int(label))\n","\n","        return paths, labels\n","\n","    def get_num_classes(self) -> int:\n","        return max(self.labels) + 1"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-06T07:17:16.832446Z","iopub.status.busy":"2024-07-06T07:17:16.832177Z","iopub.status.idle":"2024-07-06T07:17:16.854453Z","shell.execute_reply":"2024-07-06T07:17:16.853375Z","shell.execute_reply.started":"2024-07-06T07:17:16.832424Z"},"id":"pNnuPzhOzj0s","outputId":"cea2b931-e4d8-4b3b-ba87-674d7df3ab3d","trusted":true},"outputs":[{"data":{"text/plain":["(2640, 296, 2485)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["transform = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor()\n","])\n","train_dataset = GroceryStoreDataset(split='train',transform=transform)\n","val_dataset = GroceryStoreDataset(split='val',transform=transform)\n","test_dataset = GroceryStoreDataset(split='test',transform=transform)\n","train_dataset.__len__(),val_dataset.__len__(),test_dataset.__len__()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-06T07:17:16.856173Z","iopub.status.busy":"2024-07-06T07:17:16.855579Z","iopub.status.idle":"2024-07-06T07:17:20.962102Z","shell.execute_reply":"2024-07-06T07:17:20.961147Z","shell.execute_reply.started":"2024-07-06T07:17:16.856125Z"},"id":"ASJ8mG9Q074x","outputId":"8db8a7a5-a87c-4beb-cefc-e3b3ba58d491","trusted":true},"outputs":[{"data":{"text/plain":["(464, 348)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["def check_image_shapes(dataset):\n","    for i in range(dataset.__len__()):\n","        img, label = dataset[i]\n","        w, h = 0,0\n","        #print(f\"Image {i} shape: {img.shape} (width, height)\")\n","        if img.shape[1] > w:\n","          w = img.shape[1]\n","        if img.shape[2] > h:\n","          h = img.shape[2]\n","    return w,h\n","# Check shapes of the first few images\n","w_t,h_t = check_image_shapes(train_dataset)\n","w_t,h_t\n","#w_v,h_v = check_image_shapes(val_dataset)\n","#w_T,h_T = check_image_shapes(test_dataset)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:17:20.964029Z","iopub.status.busy":"2024-07-06T07:17:20.963686Z","iopub.status.idle":"2024-07-06T07:17:29.869670Z","shell.execute_reply":"2024-07-06T07:17:29.868755Z","shell.execute_reply.started":"2024-07-06T07:17:20.963998Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean: tensor([0.5306, 0.3964, 0.2564])\n","Std: tensor([0.2329, 0.2094, 0.1785])\n"]}],"source":["from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","image_height, image_width, image_channels = 348,348,3\n","# Define the transform to resize images\n","resize_transform = transforms.Compose([\n","    transforms.Resize((image_height, image_width)),\n","    transforms.ToTensor()\n","])\n","\n","# Load the training dataset with the resizing transform\n","train_dataset = GroceryStoreDataset(split='train',transform=resize_transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n","\n","# Initialize variables to store the mean and std\n","mean = torch.zeros(3)\n","std = torch.zeros(3)\n","nb_samples = 0\n","\n","# Compute mean and standard deviation\n","for images, _ in train_loader:\n","    batch_samples = images.size(0)\n","    images = images.view(batch_samples, images.size(1), -1)\n","    mean += images.mean(2).sum(0)\n","    std += images.std(2).sum(0)\n","    nb_samples += batch_samples\n","\n","mean /= nb_samples\n","std /= nb_samples\n","\n","print(f'Mean: {mean}')\n","print(f'Std: {std}')\n"]},{"cell_type":"markdown","metadata":{"id":"yBch3dpwNSsW"},"source":["## Part 1: design your own network\n","\n","Your goal is to implement a convolutional neural network for image classification and train it on `GroceryStoreDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split of **around 60%**. You are free to achieve that however you want, except for a few rules you must follow:\n","\n","- You **cannot** simply instantiate an off-the-self PyTorch network. Instead, you must construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you **cannot** use e.g. `torchvision.models.alexnet`.\n","\n","- Justify every *design choice* you make. Design choices include network architecture, training hyperparameters, and, possibly, dataset preprocessing steps. You can either (i) start from the simplest convolutional network you can think of and add complexity one step at a time, while showing how each step gets you closer to the target ~60%, or (ii) start from a model that is already able to achieve the desired accuracy and show how, by removing some of its components, its performance drops (i.e. an *ablation study*). You can *show* your results/improvements however you want: training plots, console-printed values or tables, or whatever else your heart desires: the clearer, the better.\n","\n","Don't be too concerned with your network performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded **more** points than a poorly experimentally validated model with higher accuracy."]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:17:39.940424Z","iopub.status.busy":"2024-07-06T07:17:39.940032Z","iopub.status.idle":"2024-07-06T07:17:39.955426Z","shell.execute_reply":"2024-07-06T07:17:39.954483Z","shell.execute_reply.started":"2024-07-06T07:17:39.940389Z"},"id":"SFKZXhGDAqto","trusted":true},"outputs":[],"source":["def ncorrect(scores, y):\n","    y_hat = torch.argmax(scores, -1)\n","    return (y_hat == y).sum()\n","\n","def accuracy(scores, y):\n","    correct = ncorrect(scores, y)\n","    return correct.true_divide(y.shape[0])\n","\n","def train_loop(model, train_dl, epochs, opt, val_dl=None, verbose=False, label_smoothing=0):\n","    best_val_acc = 0\n","    best_params = []\n","    best_epoch = -1\n","    found = False\n","    for e in tqdm(range(epochs)):\n","        model.train()\n","        # Train\n","        train_loss = 0\n","        train_samples = 0\n","        train_acc = 0\n","        for train_data in train_dl:\n","            imgs = train_data[0].to(device)\n","            labels = train_data[1].to(device)\n","            scores = model(imgs)\n","            loss = F.cross_entropy(scores, labels,label_smoothing=label_smoothing)\n","            train_loss += loss.item() * imgs.shape[0]\n","            train_samples += imgs.shape[0]\n","            train_acc += ncorrect(scores, labels).item()\n","\n","            opt.zero_grad()  # clear\n","            loss.backward()  # fill\n","            opt.step()       # use\n","\n","        train_acc /= train_samples\n","        train_loss /= train_samples\n","\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            val_loss = 0\n","            val_samples = 0\n","            val_acc = 0\n","            if val_dl is not None:\n","                for val_data in val_dl:\n","                    imgs = val_data[0].to(device)\n","                    labels = val_data[1].to(device)\n","                    val_scores = model(imgs)\n","                    val_loss += F.cross_entropy(val_scores, labels).item() * imgs.shape[0]\n","                    val_samples += imgs.shape[0]\n","                    val_acc += ncorrect(val_scores, labels).item()\n","                val_acc /= val_samples\n","                val_loss /= val_samples\n","\n","            if val_dl is None or val_acc > best_val_acc:\n","                best_val_acc = val_acc if val_dl is not None else 0\n","                best_params = model.state_dict()\n","                torch.save(best_params, \"best_model.pth\")\n","                best_epoch = e\n","\n","        if verbose: #and e % 5 == 0:\n","            print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if val_dl is None else f\" - valid loss {val_loss:.3f} - valid acc {val_acc:.3f}\"))\n","            if val_acc >= 0.60:\n","                best_params = model.state_dict()\n","                torch.save(best_params, \"A2.pth\")\n","                best_epoch = e\n","                break\n","\n","    if verbose and val_dl is not None:\n","        print(f\"Best epoch {best_epoch}, best acc {best_val_acc}\")\n","\n","    return (best_val_acc, best_params, best_epoch)"]},{"cell_type":"markdown","metadata":{"id":"8RNVD7TQoy1r"},"source":["# CNN"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T09:29:23.191008Z","iopub.status.busy":"2024-07-06T09:29:23.190418Z","iopub.status.idle":"2024-07-06T09:29:23.205355Z","shell.execute_reply":"2024-07-06T09:29:23.204494Z","shell.execute_reply.started":"2024-07-06T09:29:23.190980Z"},"id":"kVYlsNGkbuqb","trusted":true},"outputs":[],"source":["image_height, image_width, image_channels = 348,348,3 #224, 224, 3\n","num_classes = train_dataset.get_num_classes()\n","\n","transform_2 = torchvision.transforms.Compose([\n","    torchvision.transforms.RandomResizedCrop(size=(image_height, image_width),antialias=True),\n","    #torchvision.transforms.Resize((image_height, image_width)),\n","    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean, std)\n","    #torchvision.transforms.Normalize((0.5, 0.4, 0.25), (0.23, 0.2, 0.17))\n","])\n","\n","val_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((image_height, image_width)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean, std)\n","    #torchvision.transforms.transforms.Normalize((0.5, 0.4, 0.25), (0.23, 0.2, 0.17))\n","])\n","train_dataset = GroceryStoreDataset(split='train',transform=transform_2)\n","val_dataset = GroceryStoreDataset(split='val',transform=val_transforms)\n","#test_dataset = GroceryStoreDataset(split='test',transform=transform_2)\n","\n","batch = 8\n","train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:17:39.977526Z","iopub.status.busy":"2024-07-06T07:17:39.977269Z","iopub.status.idle":"2024-07-06T07:17:39.992090Z","shell.execute_reply":"2024-07-06T07:17:39.991319Z","shell.execute_reply.started":"2024-07-06T07:17:39.977504Z"},"id":"CZNxdSS2o3oT","trusted":true},"outputs":[],"source":["class ExtendedCNN(nn.Module):\n","    def __init__(self,channels=16, num_classes=num_classes,p_dropout=0):\n","        super(ExtendedCNN, self).__init__()\n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(in_channels=image_channels, out_channels=channels, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=channels, out_channels=channels*2, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=channels*2, out_channels=channels*4, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(in_channels=channels*4, out_channels=channels*8, kernel_size=3, stride=1, padding=1)\n","\n","        # Calculate the size of the feature map after the convolutional layers\n","        def conv2d_size_out(size, kernel_size=3, stride=1, padding=1):\n","            return (size - kernel_size + 2 * padding) // stride + 1\n","        def conv2d_compute_size(conv_number,kernels,max_poolings):  #max pooling ex. [1,0,1] if 1 them there is a max_pool\n","          image_w = image_width\n","          for i in range(conv_number):\n","            image_w = conv2d_size_out(image_w, kernel_size=kernels[i])\n","            if max_poolings[i] == 1:\n","              image_w = image_w//2\n","          return image_w\n","\n","        #convh = conv2d_size_out(conv2d_size_out(image_height, kernel_size=5, padding=1) // 2, kernel_size=3, padding=1) // 2\n","        image_w = conv2d_compute_size(4,[3,3,3,3],[1,1,1,1])\n","\n","        linear_input_size = image_w * image_w * channels*8  # Adjusted based on the output channels of conv2\n","\n","        # Define fully connected layers\n","        self.fc1 = nn.Linear(linear_input_size, 128)\n","        #self.drop1 = nn.Dropout(p_dropout)\n","        self.fc2 = nn.Linear(128, 64)\n","        #self.drop2 = nn.Dropout(p_dropout)\n","        self.fc3 = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        # Apply convolutional layers with ReLU activation and max pooling\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, kernel_size=2, stride=2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, kernel_size=2, stride=2)\n","        x = F.relu(self.conv3(x))\n","        x = F.max_pool2d(x, kernel_size=2, stride=2)\n","        x = F.relu(self.conv4(x))\n","        x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","        # Flatten the tensor\n","        x = x.view(x.size(0), -1)\n","\n","        # Apply fully connected layers\n","        x = F.relu(self.fc1(x))\n","        #x = self.drop1(x)\n","        x = F.relu(self.fc2(x))\n","        #x = self.drop2(x)\n","        x = self.fc3(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761,"referenced_widgets":["521788e7ab614c4bb1ec45d9853678db","d18c07c8179043df9447c93111a31dd0","4733ff38e6f54f72a8dca7b6d1d6e1f5","71a09f42d1f34c5faf7c012fbfe5fc1e","f7ded3abfb644ed3aaa967d1bc313eb6","febae8e0d3764652bbf57351fbfb5041","7b39c4ee962d4b019efe256eb5bc4b42","7cd9473ac34347508ec6f23534b463b2","0d21484dba744589823686ea95ce27f8","6a5d0a75de624cc5a80388acd0cafad1","84f66999ecb34dd284cbb5b1961e009c"]},"execution":{"iopub.execute_input":"2024-07-06T09:29:30.155863Z","iopub.status.busy":"2024-07-06T09:29:30.155521Z"},"id":"TpE8SRf5ptIM","outputId":"53c4d936-42b1-4d1e-eccd-3435a1820580","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fdc9c5e3ca74bb7ad60541db17b41d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.243 - train acc 0.162 - valid loss 3.005 - valid acc 0.186\n","Epoch 1: train loss 2.826 - train acc 0.243 - valid loss 2.623 - valid acc 0.277\n","Epoch 2: train loss 2.589 - train acc 0.311 - valid loss 2.867 - valid acc 0.209\n","Epoch 3: train loss 2.363 - train acc 0.385 - valid loss 2.228 - valid acc 0.294\n","Epoch 4: train loss 2.179 - train acc 0.447 - valid loss 2.199 - valid acc 0.304\n","Epoch 5: train loss 2.089 - train acc 0.482 - valid loss 1.878 - valid acc 0.453\n","Epoch 6: train loss 1.953 - train acc 0.520 - valid loss 2.026 - valid acc 0.389\n","Epoch 7: train loss 1.878 - train acc 0.556 - valid loss 2.066 - valid acc 0.382\n","Epoch 8: train loss 1.832 - train acc 0.569 - valid loss 1.845 - valid acc 0.432\n","Epoch 9: train loss 1.753 - train acc 0.599 - valid loss 1.900 - valid acc 0.429\n","Epoch 10: train loss 1.714 - train acc 0.616 - valid loss 1.720 - valid acc 0.439\n","Epoch 11: train loss 1.665 - train acc 0.639 - valid loss 2.097 - valid acc 0.446\n","Epoch 12: train loss 1.628 - train acc 0.660 - valid loss 1.860 - valid acc 0.459\n","Epoch 13: train loss 1.585 - train acc 0.669 - valid loss 1.751 - valid acc 0.483\n","Epoch 14: train loss 1.582 - train acc 0.674 - valid loss 1.931 - valid acc 0.443\n","Epoch 15: train loss 1.558 - train acc 0.683 - valid loss 1.677 - valid acc 0.503\n","Epoch 16: train loss 1.461 - train acc 0.726 - valid loss 1.889 - valid acc 0.493\n","Epoch 17: train loss 1.469 - train acc 0.716 - valid loss 1.880 - valid acc 0.493\n","Epoch 18: train loss 1.469 - train acc 0.727 - valid loss 1.833 - valid acc 0.493\n","Epoch 19: train loss 1.411 - train acc 0.751 - valid loss 1.969 - valid acc 0.490\n","Epoch 20: train loss 1.388 - train acc 0.767 - valid loss 1.869 - valid acc 0.490\n","Epoch 21: train loss 1.406 - train acc 0.762 - valid loss 1.882 - valid acc 0.466\n","Epoch 22: train loss 1.363 - train acc 0.770 - valid loss 1.826 - valid acc 0.490\n","Epoch 23: train loss 1.329 - train acc 0.786 - valid loss 1.740 - valid acc 0.520\n","Epoch 24: train loss 1.317 - train acc 0.787 - valid loss 1.987 - valid acc 0.456\n","Epoch 25: train loss 1.301 - train acc 0.801 - valid loss 1.658 - valid acc 0.537\n","Epoch 26: train loss 1.272 - train acc 0.813 - valid loss 1.845 - valid acc 0.503\n","Epoch 27: train loss 1.273 - train acc 0.819 - valid loss 2.028 - valid acc 0.443\n","Epoch 28: train loss 1.244 - train acc 0.826 - valid loss 1.838 - valid acc 0.541\n","Epoch 29: train loss 1.283 - train acc 0.810 - valid loss 1.820 - valid acc 0.507\n","Epoch 30: train loss 1.264 - train acc 0.816 - valid loss 1.963 - valid acc 0.483\n","Epoch 31: train loss 1.249 - train acc 0.822 - valid loss 1.863 - valid acc 0.480\n","Epoch 32: train loss 1.198 - train acc 0.836 - valid loss 1.681 - valid acc 0.544\n","Epoch 33: train loss 1.232 - train acc 0.826 - valid loss 1.534 - valid acc 0.581\n","Epoch 34: train loss 1.210 - train acc 0.835 - valid loss 1.874 - valid acc 0.497\n","Epoch 35: train loss 1.192 - train acc 0.839 - valid loss 1.754 - valid acc 0.541\n","Epoch 36: train loss 1.198 - train acc 0.840 - valid loss 1.916 - valid acc 0.446\n","Epoch 37: train loss 1.175 - train acc 0.845 - valid loss 1.720 - valid acc 0.507\n","Epoch 38: train loss 1.189 - train acc 0.842 - valid loss 1.702 - valid acc 0.473\n","Epoch 39: train loss 1.155 - train acc 0.858 - valid loss 1.763 - valid acc 0.510\n","Epoch 40: train loss 1.129 - train acc 0.870 - valid loss 2.118 - valid acc 0.432\n","Epoch 41: train loss 1.138 - train acc 0.868 - valid loss 1.753 - valid acc 0.517\n","Epoch 42: train loss 1.133 - train acc 0.873 - valid loss 1.736 - valid acc 0.544\n","Epoch 43: train loss 1.120 - train acc 0.875 - valid loss 1.799 - valid acc 0.517\n","Epoch 44: train loss 1.147 - train acc 0.858 - valid loss 1.890 - valid acc 0.503\n","Epoch 45: train loss 1.192 - train acc 0.839 - valid loss 1.556 - valid acc 0.574\n","Epoch 46: train loss 1.119 - train acc 0.867 - valid loss 1.873 - valid acc 0.514\n","Epoch 47: train loss 1.133 - train acc 0.877 - valid loss 1.694 - valid acc 0.507\n","Epoch 48: train loss 1.140 - train acc 0.863 - valid loss 1.551 - valid acc 0.598\n","Epoch 49: train loss 1.126 - train acc 0.864 - valid loss 1.610 - valid acc 0.520\n","Epoch 50: train loss 1.128 - train acc 0.865 - valid loss 1.741 - valid acc 0.517\n","Epoch 51: train loss 1.135 - train acc 0.863 - valid loss 1.773 - valid acc 0.520\n","Epoch 52: train loss 1.097 - train acc 0.884 - valid loss 1.637 - valid acc 0.551\n","Epoch 53: train loss 1.097 - train acc 0.879 - valid loss 1.641 - valid acc 0.507\n","Epoch 54: train loss 1.123 - train acc 0.870 - valid loss 1.727 - valid acc 0.561\n","Epoch 55: train loss 1.115 - train acc 0.873 - valid loss 1.640 - valid acc 0.581\n","Epoch 56: train loss 1.096 - train acc 0.883 - valid loss 1.919 - valid acc 0.507\n","Epoch 57: train loss 1.103 - train acc 0.880 - valid loss 1.982 - valid acc 0.476\n","Epoch 58: train loss 1.070 - train acc 0.891 - valid loss 1.771 - valid acc 0.551\n","Epoch 59: train loss 1.104 - train acc 0.874 - valid loss 1.737 - valid acc 0.554\n","Epoch 60: train loss 1.090 - train acc 0.881 - valid loss 1.748 - valid acc 0.534\n","Epoch 61: train loss 1.112 - train acc 0.874 - valid loss 1.683 - valid acc 0.541\n","Epoch 62: train loss 1.091 - train acc 0.889 - valid loss 1.780 - valid acc 0.551\n","Epoch 63: train loss 1.082 - train acc 0.884 - valid loss 1.608 - valid acc 0.578\n","Epoch 64: train loss 1.084 - train acc 0.880 - valid loss 1.831 - valid acc 0.507\n","Epoch 65: train loss 1.070 - train acc 0.891 - valid loss 1.756 - valid acc 0.534\n","Epoch 66: train loss 1.071 - train acc 0.889 - valid loss 1.637 - valid acc 0.557\n","Epoch 67: train loss 1.080 - train acc 0.886 - valid loss 1.443 - valid acc 0.588\n","Epoch 68: train loss 1.046 - train acc 0.898 - valid loss 1.667 - valid acc 0.571\n","Epoch 69: train loss 1.049 - train acc 0.900 - valid loss 1.531 - valid acc 0.598\n","Epoch 70: train loss 1.066 - train acc 0.890 - valid loss 1.805 - valid acc 0.517\n","Epoch 71: train loss 1.076 - train acc 0.886 - valid loss 1.737 - valid acc 0.534\n","Epoch 72: train loss 1.068 - train acc 0.892 - valid loss 1.524 - valid acc 0.615\n","Best epoch 72, best acc 0.6148648648648649\n"]}],"source":["new_model = ExtendedCNN(\n","    num_classes = num_classes,\n",")\n","new_model.to(device)\n","\n","#Training with: weight_decay=0.0, label_smoothing=0.5, lr=0.001, channels=16, batch_size=8\n","    \n","#optimizer = torch.optim.AdamW(new_model.parameters(), lr=0.001,weight_decay=0.01)\n","optimizer = torch.optim.Adam(new_model.parameters(), lr=0.001)\n","\n","epochs = 80\n","label_smoothing = 0.1\n","best_val_acc, best_params, best_epoch = train_loop(\n","    new_model,\n","    train_loader,\n","    epochs,\n","    optimizer,\n","    val_loader,\n","    verbose=True,\n","    label_smoothing = label_smoothing,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Gridsearch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-06T07:21:09.118432Z","iopub.status.busy":"2024-07-06T07:21:09.117902Z","iopub.status.idle":"2024-07-06T09:16:30.231721Z","shell.execute_reply":"2024-07-06T09:16:30.230348Z","shell.execute_reply.started":"2024-07-06T07:21:09.118402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training with: weight_decay=0.0, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8,test=1/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cda7e701cdc647ec862a3066dbd5218b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.075 - train acc 0.169 - valid loss 3.038 - valid acc 0.226\n","Epoch 1: train loss 2.540 - train acc 0.265 - valid loss 2.808 - valid acc 0.233\n","Epoch 2: train loss 2.232 - train acc 0.309 - valid loss 2.427 - valid acc 0.307\n","Epoch 3: train loss 2.011 - train acc 0.379 - valid loss 2.641 - valid acc 0.304\n","Epoch 4: train loss 1.806 - train acc 0.431 - valid loss 2.472 - valid acc 0.291\n","Epoch 5: train loss 1.666 - train acc 0.482 - valid loss 2.491 - valid acc 0.331\n","Epoch 6: train loss 1.485 - train acc 0.521 - valid loss 1.926 - valid acc 0.426\n","Epoch 7: train loss 1.409 - train acc 0.548 - valid loss 2.087 - valid acc 0.409\n","Epoch 8: train loss 1.315 - train acc 0.575 - valid loss 2.044 - valid acc 0.402\n","Epoch 9: train loss 1.234 - train acc 0.600 - valid loss 2.141 - valid acc 0.412\n","Epoch 10: train loss 1.166 - train acc 0.627 - valid loss 2.490 - valid acc 0.382\n","Epoch 11: train loss 1.075 - train acc 0.644 - valid loss 2.291 - valid acc 0.395\n","Epoch 12: train loss 1.022 - train acc 0.669 - valid loss 1.946 - valid acc 0.416\n","Epoch 13: train loss 1.030 - train acc 0.670 - valid loss 1.985 - valid acc 0.443\n","Epoch 14: train loss 1.002 - train acc 0.680 - valid loss 2.221 - valid acc 0.429\n","Epoch 15: train loss 0.896 - train acc 0.711 - valid loss 1.838 - valid acc 0.493\n","Epoch 16: train loss 0.898 - train acc 0.705 - valid loss 2.172 - valid acc 0.429\n","Epoch 17: train loss 0.890 - train acc 0.710 - valid loss 2.099 - valid acc 0.500\n","Epoch 18: train loss 0.889 - train acc 0.712 - valid loss 2.099 - valid acc 0.456\n","Epoch 19: train loss 0.815 - train acc 0.742 - valid loss 2.828 - valid acc 0.402\n","Epoch 20: train loss 0.817 - train acc 0.744 - valid loss 2.384 - valid acc 0.459\n","Epoch 21: train loss 0.828 - train acc 0.745 - valid loss 1.909 - valid acc 0.520\n","Epoch 22: train loss 0.753 - train acc 0.769 - valid loss 2.132 - valid acc 0.493\n","Epoch 23: train loss 0.790 - train acc 0.767 - valid loss 2.032 - valid acc 0.517\n","Epoch 24: train loss 0.764 - train acc 0.762 - valid loss 2.178 - valid acc 0.463\n","Epoch 25: train loss 0.721 - train acc 0.772 - valid loss 2.525 - valid acc 0.405\n","Epoch 26: train loss 0.730 - train acc 0.759 - valid loss 2.020 - valid acc 0.530\n","Epoch 27: train loss 0.705 - train acc 0.778 - valid loss 2.361 - valid acc 0.470\n","Epoch 28: train loss 0.652 - train acc 0.794 - valid loss 2.250 - valid acc 0.524\n","Epoch 29: train loss 0.638 - train acc 0.795 - valid loss 2.394 - valid acc 0.412\n","Epoch 30: train loss 0.694 - train acc 0.779 - valid loss 2.624 - valid acc 0.436\n","Epoch 31: train loss 0.616 - train acc 0.809 - valid loss 2.035 - valid acc 0.530\n","Epoch 32: train loss 0.663 - train acc 0.784 - valid loss 2.607 - valid acc 0.456\n","Epoch 33: train loss 0.654 - train acc 0.796 - valid loss 2.249 - valid acc 0.497\n","Epoch 34: train loss 0.641 - train acc 0.805 - valid loss 2.435 - valid acc 0.486\n","Epoch 35: train loss 0.598 - train acc 0.806 - valid loss 2.585 - valid acc 0.453\n","Epoch 36: train loss 0.571 - train acc 0.817 - valid loss 2.871 - valid acc 0.459\n","Epoch 37: train loss 0.613 - train acc 0.808 - valid loss 2.602 - valid acc 0.456\n","Epoch 38: train loss 0.584 - train acc 0.823 - valid loss 2.252 - valid acc 0.483\n","Epoch 39: train loss 0.541 - train acc 0.829 - valid loss 3.002 - valid acc 0.480\n","Epoch 40: train loss 0.617 - train acc 0.809 - valid loss 2.718 - valid acc 0.449\n","Epoch 41: train loss 0.561 - train acc 0.825 - valid loss 2.742 - valid acc 0.473\n","Epoch 42: train loss 0.526 - train acc 0.843 - valid loss 2.636 - valid acc 0.490\n","Epoch 43: train loss 0.523 - train acc 0.839 - valid loss 2.799 - valid acc 0.466\n","Epoch 44: train loss 0.527 - train acc 0.830 - valid loss 2.525 - valid acc 0.493\n","Epoch 45: train loss 0.520 - train acc 0.842 - valid loss 3.326 - valid acc 0.443\n","Epoch 46: train loss 0.571 - train acc 0.829 - valid loss 2.112 - valid acc 0.544\n","Epoch 47: train loss 0.492 - train acc 0.852 - valid loss 2.861 - valid acc 0.503\n","Epoch 48: train loss 0.552 - train acc 0.839 - valid loss 2.573 - valid acc 0.503\n","Epoch 49: train loss 0.469 - train acc 0.852 - valid loss 2.699 - valid acc 0.480\n","Epoch 50: train loss 0.497 - train acc 0.855 - valid loss 2.839 - valid acc 0.483\n","Epoch 51: train loss 0.490 - train acc 0.849 - valid loss 2.462 - valid acc 0.517\n","Epoch 52: train loss 0.500 - train acc 0.852 - valid loss 2.727 - valid acc 0.490\n","Epoch 53: train loss 0.522 - train acc 0.846 - valid loss 3.102 - valid acc 0.449\n","Epoch 54: train loss 0.538 - train acc 0.833 - valid loss 3.545 - valid acc 0.439\n","Epoch 55: train loss 0.522 - train acc 0.847 - valid loss 2.603 - valid acc 0.524\n","Epoch 56: train loss 0.469 - train acc 0.855 - valid loss 3.224 - valid acc 0.443\n","Epoch 57: train loss 0.497 - train acc 0.844 - valid loss 2.850 - valid acc 0.453\n","Epoch 58: train loss 0.461 - train acc 0.860 - valid loss 3.055 - valid acc 0.490\n","Epoch 59: train loss 0.508 - train acc 0.858 - valid loss 2.725 - valid acc 0.500\n","Epoch 60: train loss 0.507 - train acc 0.848 - valid loss 2.658 - valid acc 0.527\n","Epoch 61: train loss 0.508 - train acc 0.845 - valid loss 2.889 - valid acc 0.500\n","Epoch 62: train loss 0.437 - train acc 0.869 - valid loss 3.269 - valid acc 0.459\n","Epoch 63: train loss 0.462 - train acc 0.859 - valid loss 2.816 - valid acc 0.446\n","Epoch 64: train loss 0.463 - train acc 0.853 - valid loss 2.903 - valid acc 0.470\n","Epoch 65: train loss 0.465 - train acc 0.860 - valid loss 2.944 - valid acc 0.524\n","Epoch 66: train loss 0.484 - train acc 0.859 - valid loss 2.707 - valid acc 0.507\n","Epoch 67: train loss 0.396 - train acc 0.883 - valid loss 3.225 - valid acc 0.480\n","Epoch 68: train loss 0.446 - train acc 0.873 - valid loss 3.039 - valid acc 0.486\n","Epoch 69: train loss 0.470 - train acc 0.861 - valid loss 2.610 - valid acc 0.541\n","Epoch 70: train loss 0.468 - train acc 0.859 - valid loss 2.761 - valid acc 0.507\n","Epoch 71: train loss 0.422 - train acc 0.868 - valid loss 3.808 - valid acc 0.486\n","Epoch 72: train loss 0.438 - train acc 0.868 - valid loss 2.627 - valid acc 0.493\n","Epoch 73: train loss 0.407 - train acc 0.877 - valid loss 3.480 - valid acc 0.456\n","Epoch 74: train loss 0.420 - train acc 0.869 - valid loss 2.691 - valid acc 0.537\n","Epoch 75: train loss 0.439 - train acc 0.861 - valid loss 2.773 - valid acc 0.524\n","Epoch 76: train loss 0.402 - train acc 0.879 - valid loss 3.022 - valid acc 0.541\n","Epoch 77: train loss 0.423 - train acc 0.867 - valid loss 3.269 - valid acc 0.483\n","Epoch 78: train loss 0.422 - train acc 0.870 - valid loss 2.952 - valid acc 0.510\n","Epoch 79: train loss 0.443 - train acc 0.861 - valid loss 2.374 - valid acc 0.561\n","Best epoch 79, best acc 0.5608108108108109\n","Training with: weight_decay=0.0, label_smoothing=0.05, lr=0.001, channels=16, batch_size=8,test=2/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26e18acadbb64fa396c2db168051cba3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.067 - train acc 0.192 - valid loss 2.784 - valid acc 0.226\n","Epoch 1: train loss 2.547 - train acc 0.300 - valid loss 2.722 - valid acc 0.291\n","Epoch 2: train loss 2.211 - train acc 0.386 - valid loss 2.564 - valid acc 0.277\n","Epoch 3: train loss 1.971 - train acc 0.459 - valid loss 2.137 - valid acc 0.341\n","Epoch 4: train loss 1.800 - train acc 0.509 - valid loss 1.999 - valid acc 0.395\n","Epoch 5: train loss 1.682 - train acc 0.550 - valid loss 2.110 - valid acc 0.382\n","Epoch 6: train loss 1.620 - train acc 0.564 - valid loss 2.032 - valid acc 0.429\n","Epoch 7: train loss 1.488 - train acc 0.618 - valid loss 1.979 - valid acc 0.382\n","Epoch 8: train loss 1.455 - train acc 0.631 - valid loss 2.042 - valid acc 0.426\n","Epoch 9: train loss 1.375 - train acc 0.660 - valid loss 1.821 - valid acc 0.432\n","Epoch 10: train loss 1.356 - train acc 0.659 - valid loss 1.926 - valid acc 0.412\n","Epoch 11: train loss 1.304 - train acc 0.698 - valid loss 1.837 - valid acc 0.483\n","Epoch 12: train loss 1.280 - train acc 0.703 - valid loss 1.839 - valid acc 0.459\n","Epoch 13: train loss 1.210 - train acc 0.724 - valid loss 1.922 - valid acc 0.416\n","Epoch 14: train loss 1.181 - train acc 0.739 - valid loss 1.770 - valid acc 0.436\n","Epoch 15: train loss 1.161 - train acc 0.745 - valid loss 1.785 - valid acc 0.463\n","Epoch 16: train loss 1.134 - train acc 0.759 - valid loss 1.713 - valid acc 0.486\n","Epoch 17: train loss 1.116 - train acc 0.761 - valid loss 1.804 - valid acc 0.426\n","Epoch 18: train loss 1.081 - train acc 0.787 - valid loss 1.914 - valid acc 0.449\n","Epoch 19: train loss 1.066 - train acc 0.782 - valid loss 1.849 - valid acc 0.470\n","Epoch 20: train loss 1.024 - train acc 0.802 - valid loss 1.864 - valid acc 0.480\n","Epoch 21: train loss 1.038 - train acc 0.802 - valid loss 1.961 - valid acc 0.449\n","Epoch 22: train loss 1.020 - train acc 0.795 - valid loss 1.897 - valid acc 0.470\n","Epoch 23: train loss 1.015 - train acc 0.797 - valid loss 2.110 - valid acc 0.412\n","Epoch 24: train loss 1.030 - train acc 0.807 - valid loss 1.991 - valid acc 0.470\n","Epoch 25: train loss 0.969 - train acc 0.812 - valid loss 1.957 - valid acc 0.476\n","Epoch 26: train loss 0.973 - train acc 0.817 - valid loss 2.049 - valid acc 0.456\n","Epoch 27: train loss 0.930 - train acc 0.833 - valid loss 1.779 - valid acc 0.527\n","Epoch 28: train loss 0.969 - train acc 0.829 - valid loss 1.789 - valid acc 0.493\n","Epoch 29: train loss 0.932 - train acc 0.833 - valid loss 1.783 - valid acc 0.503\n","Epoch 30: train loss 0.928 - train acc 0.836 - valid loss 1.783 - valid acc 0.520\n","Epoch 31: train loss 0.936 - train acc 0.831 - valid loss 1.901 - valid acc 0.466\n","Epoch 32: train loss 0.908 - train acc 0.838 - valid loss 1.964 - valid acc 0.463\n","Epoch 33: train loss 0.902 - train acc 0.848 - valid loss 2.044 - valid acc 0.476\n","Epoch 34: train loss 0.937 - train acc 0.838 - valid loss 1.806 - valid acc 0.517\n","Epoch 35: train loss 0.867 - train acc 0.858 - valid loss 1.857 - valid acc 0.490\n","Epoch 36: train loss 0.863 - train acc 0.857 - valid loss 1.873 - valid acc 0.527\n","Epoch 37: train loss 0.868 - train acc 0.855 - valid loss 1.728 - valid acc 0.524\n","Epoch 38: train loss 0.861 - train acc 0.861 - valid loss 1.836 - valid acc 0.517\n","Epoch 39: train loss 0.860 - train acc 0.856 - valid loss 1.634 - valid acc 0.571\n","Epoch 40: train loss 0.824 - train acc 0.878 - valid loss 1.716 - valid acc 0.520\n","Epoch 41: train loss 0.830 - train acc 0.873 - valid loss 1.767 - valid acc 0.551\n","Epoch 42: train loss 0.827 - train acc 0.873 - valid loss 1.715 - valid acc 0.510\n","Epoch 43: train loss 0.809 - train acc 0.880 - valid loss 1.864 - valid acc 0.493\n","Epoch 44: train loss 0.817 - train acc 0.877 - valid loss 1.901 - valid acc 0.510\n","Epoch 45: train loss 0.833 - train acc 0.874 - valid loss 1.878 - valid acc 0.497\n","Epoch 46: train loss 0.816 - train acc 0.874 - valid loss 1.791 - valid acc 0.510\n","Epoch 47: train loss 0.823 - train acc 0.873 - valid loss 1.642 - valid acc 0.578\n","Epoch 48: train loss 0.812 - train acc 0.880 - valid loss 1.878 - valid acc 0.486\n","Epoch 49: train loss 0.840 - train acc 0.865 - valid loss 1.809 - valid acc 0.534\n","Epoch 50: train loss 0.798 - train acc 0.884 - valid loss 1.761 - valid acc 0.578\n","Epoch 51: train loss 0.786 - train acc 0.890 - valid loss 2.055 - valid acc 0.490\n","Epoch 52: train loss 0.807 - train acc 0.877 - valid loss 1.874 - valid acc 0.493\n","Epoch 53: train loss 0.823 - train acc 0.871 - valid loss 1.996 - valid acc 0.507\n","Epoch 54: train loss 0.824 - train acc 0.880 - valid loss 2.054 - valid acc 0.476\n","Epoch 55: train loss 0.808 - train acc 0.886 - valid loss 1.803 - valid acc 0.517\n","Epoch 56: train loss 0.791 - train acc 0.897 - valid loss 1.669 - valid acc 0.574\n","Epoch 57: train loss 0.766 - train acc 0.896 - valid loss 1.726 - valid acc 0.557\n","Epoch 58: train loss 0.783 - train acc 0.889 - valid loss 1.876 - valid acc 0.524\n","Epoch 59: train loss 0.788 - train acc 0.885 - valid loss 1.891 - valid acc 0.503\n","Epoch 60: train loss 0.773 - train acc 0.894 - valid loss 1.973 - valid acc 0.490\n","Epoch 61: train loss 0.758 - train acc 0.900 - valid loss 2.149 - valid acc 0.493\n","Epoch 62: train loss 0.789 - train acc 0.889 - valid loss 1.753 - valid acc 0.554\n","Epoch 63: train loss 0.767 - train acc 0.893 - valid loss 1.930 - valid acc 0.530\n","Epoch 64: train loss 0.787 - train acc 0.885 - valid loss 1.770 - valid acc 0.541\n","Epoch 65: train loss 0.745 - train acc 0.905 - valid loss 1.880 - valid acc 0.527\n","Epoch 66: train loss 0.783 - train acc 0.889 - valid loss 1.836 - valid acc 0.510\n","Epoch 67: train loss 0.747 - train acc 0.902 - valid loss 1.724 - valid acc 0.524\n","Epoch 68: train loss 0.728 - train acc 0.906 - valid loss 1.890 - valid acc 0.483\n","Epoch 69: train loss 0.723 - train acc 0.909 - valid loss 1.763 - valid acc 0.541\n","Epoch 70: train loss 0.778 - train acc 0.893 - valid loss 1.766 - valid acc 0.534\n","Epoch 71: train loss 0.713 - train acc 0.911 - valid loss 1.961 - valid acc 0.490\n","Epoch 72: train loss 0.769 - train acc 0.896 - valid loss 2.065 - valid acc 0.486\n","Epoch 73: train loss 0.733 - train acc 0.906 - valid loss 2.022 - valid acc 0.500\n","Epoch 74: train loss 0.729 - train acc 0.912 - valid loss 1.875 - valid acc 0.514\n","Epoch 75: train loss 0.745 - train acc 0.908 - valid loss 1.831 - valid acc 0.547\n","Epoch 76: train loss 0.718 - train acc 0.916 - valid loss 1.788 - valid acc 0.551\n","Epoch 77: train loss 0.750 - train acc 0.898 - valid loss 1.788 - valid acc 0.527\n","Epoch 78: train loss 0.765 - train acc 0.894 - valid loss 1.845 - valid acc 0.510\n","Epoch 79: train loss 0.703 - train acc 0.913 - valid loss 1.731 - valid acc 0.551\n","Best epoch 47, best acc 0.5777027027027027\n","Training with: weight_decay=0.0, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8,test=3/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98dda8045dd541cbb98863da6afb4a71","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.097 - train acc 0.192 - valid loss 2.867 - valid acc 0.240\n","Epoch 1: train loss 2.628 - train acc 0.309 - valid loss 2.556 - valid acc 0.291\n","Epoch 2: train loss 2.316 - train acc 0.397 - valid loss 2.363 - valid acc 0.389\n","Epoch 3: train loss 2.126 - train acc 0.470 - valid loss 2.221 - valid acc 0.355\n","Epoch 4: train loss 2.019 - train acc 0.514 - valid loss 2.350 - valid acc 0.382\n","Epoch 5: train loss 1.908 - train acc 0.560 - valid loss 2.175 - valid acc 0.338\n","Epoch 6: train loss 1.821 - train acc 0.586 - valid loss 2.060 - valid acc 0.375\n","Epoch 7: train loss 1.791 - train acc 0.606 - valid loss 1.869 - valid acc 0.470\n","Epoch 8: train loss 1.722 - train acc 0.620 - valid loss 2.063 - valid acc 0.378\n","Epoch 9: train loss 1.649 - train acc 0.657 - valid loss 1.954 - valid acc 0.443\n","Epoch 10: train loss 1.606 - train acc 0.673 - valid loss 2.012 - valid acc 0.395\n","Epoch 11: train loss 1.577 - train acc 0.689 - valid loss 1.817 - valid acc 0.480\n","Epoch 12: train loss 1.527 - train acc 0.707 - valid loss 1.886 - valid acc 0.443\n","Epoch 13: train loss 1.501 - train acc 0.717 - valid loss 1.729 - valid acc 0.514\n","Epoch 14: train loss 1.487 - train acc 0.725 - valid loss 1.972 - valid acc 0.449\n","Epoch 15: train loss 1.411 - train acc 0.756 - valid loss 1.864 - valid acc 0.476\n","Epoch 16: train loss 1.415 - train acc 0.749 - valid loss 1.878 - valid acc 0.480\n","Epoch 17: train loss 1.416 - train acc 0.756 - valid loss 1.712 - valid acc 0.503\n","Epoch 18: train loss 1.346 - train acc 0.778 - valid loss 1.888 - valid acc 0.486\n","Epoch 19: train loss 1.374 - train acc 0.779 - valid loss 1.823 - valid acc 0.507\n","Epoch 20: train loss 1.301 - train acc 0.803 - valid loss 1.890 - valid acc 0.470\n","Epoch 21: train loss 1.280 - train acc 0.808 - valid loss 1.960 - valid acc 0.473\n","Epoch 22: train loss 1.313 - train acc 0.793 - valid loss 2.094 - valid acc 0.426\n","Epoch 23: train loss 1.307 - train acc 0.805 - valid loss 1.888 - valid acc 0.446\n","Epoch 24: train loss 1.222 - train acc 0.836 - valid loss 1.838 - valid acc 0.497\n","Epoch 25: train loss 1.247 - train acc 0.829 - valid loss 2.030 - valid acc 0.470\n","Epoch 26: train loss 1.225 - train acc 0.833 - valid loss 1.787 - valid acc 0.503\n","Epoch 27: train loss 1.206 - train acc 0.842 - valid loss 2.148 - valid acc 0.439\n","Epoch 28: train loss 1.198 - train acc 0.842 - valid loss 1.893 - valid acc 0.497\n","Epoch 29: train loss 1.225 - train acc 0.838 - valid loss 1.883 - valid acc 0.493\n","Epoch 30: train loss 1.170 - train acc 0.856 - valid loss 2.057 - valid acc 0.473\n","Epoch 31: train loss 1.233 - train acc 0.836 - valid loss 2.064 - valid acc 0.416\n","Epoch 32: train loss 1.148 - train acc 0.862 - valid loss 1.662 - valid acc 0.581\n","Epoch 33: train loss 1.157 - train acc 0.864 - valid loss 1.892 - valid acc 0.500\n","Epoch 34: train loss 1.154 - train acc 0.864 - valid loss 1.887 - valid acc 0.480\n","Epoch 35: train loss 1.172 - train acc 0.853 - valid loss 1.788 - valid acc 0.537\n","Epoch 36: train loss 1.151 - train acc 0.870 - valid loss 1.932 - valid acc 0.530\n","Epoch 37: train loss 1.123 - train acc 0.874 - valid loss 2.263 - valid acc 0.399\n","Epoch 38: train loss 1.146 - train acc 0.870 - valid loss 1.944 - valid acc 0.490\n","Epoch 39: train loss 1.143 - train acc 0.872 - valid loss 2.024 - valid acc 0.459\n","Epoch 40: train loss 1.124 - train acc 0.869 - valid loss 1.899 - valid acc 0.493\n","Epoch 41: train loss 1.109 - train acc 0.877 - valid loss 1.709 - valid acc 0.554\n","Epoch 42: train loss 1.098 - train acc 0.883 - valid loss 1.810 - valid acc 0.541\n","Epoch 43: train loss 1.105 - train acc 0.881 - valid loss 1.908 - valid acc 0.486\n","Epoch 44: train loss 1.123 - train acc 0.876 - valid loss 1.873 - valid acc 0.510\n","Epoch 45: train loss 1.094 - train acc 0.887 - valid loss 2.009 - valid acc 0.476\n","Epoch 46: train loss 1.097 - train acc 0.883 - valid loss 1.934 - valid acc 0.490\n","Epoch 47: train loss 1.087 - train acc 0.889 - valid loss 1.954 - valid acc 0.486\n","Epoch 48: train loss 1.081 - train acc 0.890 - valid loss 1.991 - valid acc 0.514\n","Epoch 49: train loss 1.088 - train acc 0.891 - valid loss 1.859 - valid acc 0.530\n","Epoch 50: train loss 1.081 - train acc 0.885 - valid loss 2.212 - valid acc 0.446\n","Epoch 51: train loss 1.053 - train acc 0.901 - valid loss 1.730 - valid acc 0.564\n","Epoch 52: train loss 1.095 - train acc 0.884 - valid loss 1.991 - valid acc 0.490\n","Epoch 53: train loss 1.099 - train acc 0.883 - valid loss 2.137 - valid acc 0.456\n","Epoch 54: train loss 1.066 - train acc 0.892 - valid loss 1.919 - valid acc 0.500\n","Epoch 55: train loss 1.033 - train acc 0.903 - valid loss 2.092 - valid acc 0.483\n","Epoch 56: train loss 1.086 - train acc 0.887 - valid loss 1.830 - valid acc 0.534\n","Epoch 57: train loss 1.037 - train acc 0.908 - valid loss 1.880 - valid acc 0.507\n","Epoch 58: train loss 1.064 - train acc 0.894 - valid loss 2.058 - valid acc 0.473\n","Epoch 59: train loss 1.041 - train acc 0.902 - valid loss 1.765 - valid acc 0.551\n","Epoch 60: train loss 1.057 - train acc 0.898 - valid loss 1.913 - valid acc 0.524\n","Epoch 61: train loss 1.058 - train acc 0.904 - valid loss 2.051 - valid acc 0.497\n","Epoch 62: train loss 1.056 - train acc 0.901 - valid loss 2.028 - valid acc 0.503\n","Epoch 63: train loss 1.059 - train acc 0.896 - valid loss 1.883 - valid acc 0.507\n","Epoch 64: train loss 1.023 - train acc 0.907 - valid loss 1.860 - valid acc 0.574\n","Epoch 65: train loss 1.058 - train acc 0.895 - valid loss 2.059 - valid acc 0.503\n","Epoch 66: train loss 1.038 - train acc 0.905 - valid loss 2.126 - valid acc 0.476\n","Epoch 67: train loss 1.001 - train acc 0.919 - valid loss 1.916 - valid acc 0.541\n","Epoch 68: train loss 1.051 - train acc 0.893 - valid loss 1.848 - valid acc 0.537\n","Epoch 69: train loss 1.031 - train acc 0.909 - valid loss 1.810 - valid acc 0.534\n","Epoch 70: train loss 1.031 - train acc 0.903 - valid loss 2.115 - valid acc 0.493\n","Epoch 71: train loss 1.021 - train acc 0.904 - valid loss 1.991 - valid acc 0.507\n","Epoch 72: train loss 1.032 - train acc 0.906 - valid loss 1.795 - valid acc 0.551\n","Epoch 73: train loss 1.016 - train acc 0.907 - valid loss 1.934 - valid acc 0.510\n","Epoch 74: train loss 1.048 - train acc 0.896 - valid loss 1.649 - valid acc 0.591\n","Epoch 75: train loss 1.036 - train acc 0.903 - valid loss 2.060 - valid acc 0.476\n","Epoch 76: train loss 1.026 - train acc 0.907 - valid loss 2.070 - valid acc 0.490\n","Epoch 77: train loss 1.033 - train acc 0.902 - valid loss 2.152 - valid acc 0.473\n","Epoch 78: train loss 1.012 - train acc 0.909 - valid loss 2.025 - valid acc 0.480\n","Epoch 79: train loss 1.021 - train acc 0.907 - valid loss 1.929 - valid acc 0.497\n","Best epoch 74, best acc 0.5912162162162162\n","Training with: weight_decay=0.0, label_smoothing=0.15, lr=0.001, channels=16, batch_size=8,test=4/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e510fca56d14b7889c6d0b51053bd5e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.316 - train acc 0.169 - valid loss 2.967 - valid acc 0.169\n","Epoch 1: train loss 2.879 - train acc 0.271 - valid loss 2.667 - valid acc 0.236\n","Epoch 2: train loss 2.649 - train acc 0.344 - valid loss 2.569 - valid acc 0.277\n","Epoch 3: train loss 2.491 - train acc 0.405 - valid loss 2.331 - valid acc 0.368\n","Epoch 4: train loss 2.335 - train acc 0.451 - valid loss 2.280 - valid acc 0.331\n","Epoch 5: train loss 2.223 - train acc 0.487 - valid loss 2.291 - valid acc 0.348\n","Epoch 6: train loss 2.119 - train acc 0.528 - valid loss 2.168 - valid acc 0.348\n","Epoch 7: train loss 2.026 - train acc 0.593 - valid loss 2.167 - valid acc 0.318\n","Epoch 8: train loss 1.980 - train acc 0.599 - valid loss 1.920 - valid acc 0.409\n","Epoch 9: train loss 1.924 - train acc 0.628 - valid loss 2.298 - valid acc 0.341\n","Epoch 10: train loss 1.874 - train acc 0.661 - valid loss 2.143 - valid acc 0.351\n","Epoch 11: train loss 1.850 - train acc 0.666 - valid loss 2.144 - valid acc 0.412\n","Epoch 12: train loss 1.792 - train acc 0.684 - valid loss 2.122 - valid acc 0.439\n","Epoch 13: train loss 1.789 - train acc 0.693 - valid loss 2.383 - valid acc 0.341\n","Epoch 14: train loss 1.668 - train acc 0.741 - valid loss 1.826 - valid acc 0.500\n","Epoch 15: train loss 1.710 - train acc 0.728 - valid loss 1.840 - valid acc 0.486\n","Epoch 16: train loss 1.698 - train acc 0.726 - valid loss 2.125 - valid acc 0.443\n","Epoch 17: train loss 1.655 - train acc 0.748 - valid loss 1.866 - valid acc 0.486\n","Epoch 18: train loss 1.640 - train acc 0.760 - valid loss 1.903 - valid acc 0.470\n","Epoch 19: train loss 1.604 - train acc 0.777 - valid loss 1.984 - valid acc 0.463\n","Epoch 20: train loss 1.614 - train acc 0.777 - valid loss 1.922 - valid acc 0.446\n","Epoch 21: train loss 1.572 - train acc 0.795 - valid loss 1.982 - valid acc 0.429\n","Epoch 22: train loss 1.558 - train acc 0.797 - valid loss 1.986 - valid acc 0.476\n","Epoch 23: train loss 1.549 - train acc 0.801 - valid loss 1.972 - valid acc 0.510\n","Epoch 24: train loss 1.519 - train acc 0.817 - valid loss 1.898 - valid acc 0.483\n","Epoch 25: train loss 1.502 - train acc 0.824 - valid loss 2.026 - valid acc 0.449\n","Epoch 26: train loss 1.516 - train acc 0.816 - valid loss 1.893 - valid acc 0.480\n","Epoch 27: train loss 1.482 - train acc 0.836 - valid loss 1.842 - valid acc 0.510\n","Epoch 28: train loss 1.490 - train acc 0.829 - valid loss 1.800 - valid acc 0.524\n","Epoch 29: train loss 1.491 - train acc 0.823 - valid loss 1.902 - valid acc 0.507\n","Epoch 30: train loss 1.465 - train acc 0.838 - valid loss 1.859 - valid acc 0.537\n","Epoch 31: train loss 1.477 - train acc 0.838 - valid loss 1.835 - valid acc 0.470\n","Epoch 32: train loss 1.443 - train acc 0.847 - valid loss 2.023 - valid acc 0.466\n","Epoch 33: train loss 1.451 - train acc 0.842 - valid loss 1.954 - valid acc 0.527\n","Epoch 34: train loss 1.437 - train acc 0.845 - valid loss 1.926 - valid acc 0.500\n","Epoch 35: train loss 1.426 - train acc 0.849 - valid loss 1.800 - valid acc 0.507\n","Epoch 36: train loss 1.423 - train acc 0.858 - valid loss 1.925 - valid acc 0.503\n","Epoch 37: train loss 1.400 - train acc 0.859 - valid loss 1.954 - valid acc 0.490\n","Epoch 38: train loss 1.445 - train acc 0.848 - valid loss 1.871 - valid acc 0.500\n","Epoch 39: train loss 1.420 - train acc 0.855 - valid loss 1.821 - valid acc 0.510\n","Epoch 40: train loss 1.399 - train acc 0.870 - valid loss 2.081 - valid acc 0.426\n","Epoch 41: train loss 1.403 - train acc 0.856 - valid loss 1.893 - valid acc 0.497\n","Epoch 42: train loss 1.373 - train acc 0.878 - valid loss 2.022 - valid acc 0.453\n","Epoch 43: train loss 1.380 - train acc 0.878 - valid loss 1.854 - valid acc 0.503\n","Epoch 44: train loss 1.404 - train acc 0.858 - valid loss 1.851 - valid acc 0.517\n","Epoch 45: train loss 1.369 - train acc 0.873 - valid loss 1.945 - valid acc 0.470\n","Epoch 46: train loss 1.411 - train acc 0.853 - valid loss 1.754 - valid acc 0.541\n","Epoch 47: train loss 1.375 - train acc 0.873 - valid loss 1.955 - valid acc 0.527\n","Epoch 48: train loss 1.360 - train acc 0.877 - valid loss 1.697 - valid acc 0.588\n","Epoch 49: train loss 1.380 - train acc 0.873 - valid loss 1.960 - valid acc 0.470\n","Epoch 50: train loss 1.380 - train acc 0.873 - valid loss 1.778 - valid acc 0.554\n","Epoch 51: train loss 1.363 - train acc 0.883 - valid loss 1.840 - valid acc 0.547\n","Epoch 52: train loss 1.331 - train acc 0.897 - valid loss 1.978 - valid acc 0.490\n","Epoch 53: train loss 1.375 - train acc 0.872 - valid loss 2.137 - valid acc 0.443\n","Epoch 54: train loss 1.348 - train acc 0.881 - valid loss 1.904 - valid acc 0.480\n","Epoch 55: train loss 1.354 - train acc 0.880 - valid loss 1.774 - valid acc 0.544\n","Epoch 56: train loss 1.339 - train acc 0.890 - valid loss 1.980 - valid acc 0.507\n","Epoch 57: train loss 1.336 - train acc 0.889 - valid loss 1.906 - valid acc 0.517\n","Epoch 58: train loss 1.344 - train acc 0.885 - valid loss 1.822 - valid acc 0.514\n","Epoch 59: train loss 1.339 - train acc 0.887 - valid loss 1.898 - valid acc 0.527\n","Epoch 60: train loss 1.332 - train acc 0.891 - valid loss 1.846 - valid acc 0.524\n","Epoch 61: train loss 1.322 - train acc 0.890 - valid loss 1.925 - valid acc 0.537\n","Epoch 62: train loss 1.347 - train acc 0.886 - valid loss 1.983 - valid acc 0.493\n","Epoch 63: train loss 1.320 - train acc 0.894 - valid loss 1.896 - valid acc 0.537\n","Epoch 64: train loss 1.302 - train acc 0.900 - valid loss 2.056 - valid acc 0.473\n","Epoch 65: train loss 1.342 - train acc 0.889 - valid loss 1.808 - valid acc 0.537\n","Epoch 66: train loss 1.320 - train acc 0.900 - valid loss 1.896 - valid acc 0.517\n","Epoch 67: train loss 1.333 - train acc 0.892 - valid loss 1.841 - valid acc 0.514\n","Epoch 68: train loss 1.299 - train acc 0.903 - valid loss 2.015 - valid acc 0.497\n","Epoch 69: train loss 1.325 - train acc 0.894 - valid loss 1.782 - valid acc 0.537\n","Epoch 70: train loss 1.307 - train acc 0.897 - valid loss 1.903 - valid acc 0.524\n","Epoch 71: train loss 1.314 - train acc 0.897 - valid loss 1.864 - valid acc 0.571\n","Epoch 72: train loss 1.320 - train acc 0.898 - valid loss 1.908 - valid acc 0.541\n","Epoch 73: train loss 1.295 - train acc 0.901 - valid loss 2.036 - valid acc 0.497\n","Epoch 74: train loss 1.295 - train acc 0.906 - valid loss 2.008 - valid acc 0.514\n","Epoch 75: train loss 1.299 - train acc 0.903 - valid loss 1.871 - valid acc 0.561\n","Epoch 76: train loss 1.275 - train acc 0.911 - valid loss 1.680 - valid acc 0.557\n","Epoch 77: train loss 1.311 - train acc 0.894 - valid loss 1.713 - valid acc 0.568\n","Epoch 78: train loss 1.337 - train acc 0.886 - valid loss 1.957 - valid acc 0.534\n","Epoch 79: train loss 1.308 - train acc 0.901 - valid loss 1.809 - valid acc 0.510\n","Best epoch 48, best acc 0.5878378378378378\n","Training with: weight_decay=0.0, label_smoothing=0.2, lr=0.001, channels=16, batch_size=8,test=5/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2d0a3ef6eaa4e89a0d8d430aadaa6bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.386 - train acc 0.150 - valid loss 3.107 - valid acc 0.176\n","Epoch 1: train loss 2.943 - train acc 0.285 - valid loss 2.734 - valid acc 0.291\n","Epoch 2: train loss 2.702 - train acc 0.373 - valid loss 2.289 - valid acc 0.361\n","Epoch 3: train loss 2.524 - train acc 0.439 - valid loss 2.292 - valid acc 0.385\n","Epoch 4: train loss 2.410 - train acc 0.489 - valid loss 2.366 - valid acc 0.355\n","Epoch 5: train loss 2.309 - train acc 0.530 - valid loss 2.038 - valid acc 0.436\n","Epoch 6: train loss 2.209 - train acc 0.564 - valid loss 2.026 - valid acc 0.446\n","Epoch 7: train loss 2.165 - train acc 0.592 - valid loss 1.941 - valid acc 0.463\n","Epoch 8: train loss 2.139 - train acc 0.610 - valid loss 2.133 - valid acc 0.412\n","Epoch 9: train loss 2.084 - train acc 0.646 - valid loss 2.064 - valid acc 0.432\n","Epoch 10: train loss 2.042 - train acc 0.651 - valid loss 2.024 - valid acc 0.409\n","Epoch 11: train loss 2.006 - train acc 0.682 - valid loss 2.014 - valid acc 0.453\n","Epoch 12: train loss 2.004 - train acc 0.681 - valid loss 2.198 - valid acc 0.419\n","Epoch 13: train loss 1.943 - train acc 0.720 - valid loss 2.049 - valid acc 0.436\n","Epoch 14: train loss 1.910 - train acc 0.720 - valid loss 2.143 - valid acc 0.459\n","Epoch 15: train loss 1.908 - train acc 0.730 - valid loss 2.137 - valid acc 0.389\n","Epoch 16: train loss 1.880 - train acc 0.746 - valid loss 1.991 - valid acc 0.429\n","Epoch 17: train loss 1.850 - train acc 0.752 - valid loss 2.005 - valid acc 0.429\n","Epoch 18: train loss 1.836 - train acc 0.760 - valid loss 2.158 - valid acc 0.392\n","Epoch 19: train loss 1.816 - train acc 0.774 - valid loss 2.021 - valid acc 0.449\n","Epoch 20: train loss 1.792 - train acc 0.791 - valid loss 2.148 - valid acc 0.446\n","Epoch 21: train loss 1.785 - train acc 0.794 - valid loss 1.877 - valid acc 0.486\n","Epoch 22: train loss 1.778 - train acc 0.796 - valid loss 1.980 - valid acc 0.449\n","Epoch 23: train loss 1.752 - train acc 0.814 - valid loss 2.128 - valid acc 0.463\n","Epoch 24: train loss 1.735 - train acc 0.819 - valid loss 2.047 - valid acc 0.426\n","Epoch 25: train loss 1.745 - train acc 0.815 - valid loss 1.949 - valid acc 0.493\n","Epoch 26: train loss 1.743 - train acc 0.818 - valid loss 1.995 - valid acc 0.463\n","Epoch 27: train loss 1.716 - train acc 0.830 - valid loss 1.964 - valid acc 0.480\n","Epoch 28: train loss 1.705 - train acc 0.833 - valid loss 2.073 - valid acc 0.432\n","Epoch 29: train loss 1.711 - train acc 0.826 - valid loss 2.056 - valid acc 0.480\n","Epoch 30: train loss 1.684 - train acc 0.843 - valid loss 1.793 - valid acc 0.524\n","Epoch 31: train loss 1.689 - train acc 0.838 - valid loss 1.926 - valid acc 0.483\n","Epoch 32: train loss 1.669 - train acc 0.853 - valid loss 2.123 - valid acc 0.480\n","Epoch 33: train loss 1.650 - train acc 0.860 - valid loss 1.886 - valid acc 0.520\n","Epoch 34: train loss 1.684 - train acc 0.844 - valid loss 2.161 - valid acc 0.486\n","Epoch 35: train loss 1.629 - train acc 0.869 - valid loss 1.978 - valid acc 0.486\n","Epoch 36: train loss 1.647 - train acc 0.862 - valid loss 2.041 - valid acc 0.476\n","Epoch 37: train loss 1.653 - train acc 0.860 - valid loss 1.871 - valid acc 0.507\n","Epoch 38: train loss 1.667 - train acc 0.849 - valid loss 2.138 - valid acc 0.443\n","Epoch 39: train loss 1.629 - train acc 0.869 - valid loss 2.025 - valid acc 0.527\n","Epoch 40: train loss 1.633 - train acc 0.867 - valid loss 2.035 - valid acc 0.480\n","Epoch 41: train loss 1.631 - train acc 0.865 - valid loss 1.911 - valid acc 0.497\n","Epoch 42: train loss 1.635 - train acc 0.859 - valid loss 2.088 - valid acc 0.456\n","Epoch 43: train loss 1.616 - train acc 0.869 - valid loss 1.835 - valid acc 0.503\n","Epoch 44: train loss 1.624 - train acc 0.874 - valid loss 2.037 - valid acc 0.470\n","Epoch 45: train loss 1.609 - train acc 0.878 - valid loss 1.866 - valid acc 0.544\n","Epoch 46: train loss 1.602 - train acc 0.877 - valid loss 2.089 - valid acc 0.514\n","Epoch 47: train loss 1.620 - train acc 0.872 - valid loss 1.925 - valid acc 0.534\n","Epoch 48: train loss 1.594 - train acc 0.884 - valid loss 2.089 - valid acc 0.449\n","Epoch 49: train loss 1.612 - train acc 0.881 - valid loss 1.872 - valid acc 0.510\n","Epoch 50: train loss 1.600 - train acc 0.877 - valid loss 1.897 - valid acc 0.500\n","Epoch 51: train loss 1.566 - train acc 0.894 - valid loss 2.072 - valid acc 0.507\n","Epoch 52: train loss 1.588 - train acc 0.887 - valid loss 1.982 - valid acc 0.483\n","Epoch 53: train loss 1.584 - train acc 0.886 - valid loss 2.010 - valid acc 0.486\n","Epoch 54: train loss 1.587 - train acc 0.883 - valid loss 1.941 - valid acc 0.520\n","Epoch 55: train loss 1.603 - train acc 0.877 - valid loss 1.930 - valid acc 0.534\n","Epoch 56: train loss 1.593 - train acc 0.886 - valid loss 1.891 - valid acc 0.527\n","Epoch 57: train loss 1.557 - train acc 0.898 - valid loss 2.190 - valid acc 0.456\n","Epoch 58: train loss 1.560 - train acc 0.898 - valid loss 1.898 - valid acc 0.537\n","Epoch 59: train loss 1.565 - train acc 0.898 - valid loss 2.078 - valid acc 0.517\n","Epoch 60: train loss 1.566 - train acc 0.895 - valid loss 1.934 - valid acc 0.520\n","Epoch 61: train loss 1.540 - train acc 0.902 - valid loss 1.941 - valid acc 0.466\n","Epoch 62: train loss 1.550 - train acc 0.900 - valid loss 1.878 - valid acc 0.527\n","Epoch 63: train loss 1.571 - train acc 0.891 - valid loss 2.052 - valid acc 0.510\n","Epoch 64: train loss 1.572 - train acc 0.890 - valid loss 2.247 - valid acc 0.426\n","Epoch 65: train loss 1.551 - train acc 0.894 - valid loss 2.070 - valid acc 0.483\n","Epoch 66: train loss 1.529 - train acc 0.907 - valid loss 1.921 - valid acc 0.507\n","Epoch 67: train loss 1.538 - train acc 0.906 - valid loss 1.951 - valid acc 0.524\n","Epoch 68: train loss 1.538 - train acc 0.908 - valid loss 1.862 - valid acc 0.537\n","Epoch 69: train loss 1.556 - train acc 0.895 - valid loss 1.868 - valid acc 0.534\n","Epoch 70: train loss 1.515 - train acc 0.914 - valid loss 1.821 - valid acc 0.557\n","Epoch 71: train loss 1.536 - train acc 0.902 - valid loss 2.011 - valid acc 0.537\n","Epoch 72: train loss 1.553 - train acc 0.903 - valid loss 1.811 - valid acc 0.571\n","Epoch 73: train loss 1.547 - train acc 0.900 - valid loss 1.914 - valid acc 0.527\n","Epoch 74: train loss 1.495 - train acc 0.922 - valid loss 1.878 - valid acc 0.571\n","Epoch 75: train loss 1.543 - train acc 0.900 - valid loss 1.906 - valid acc 0.507\n","Epoch 76: train loss 1.517 - train acc 0.913 - valid loss 1.887 - valid acc 0.547\n","Epoch 77: train loss 1.568 - train acc 0.892 - valid loss 2.007 - valid acc 0.493\n","Epoch 78: train loss 1.522 - train acc 0.916 - valid loss 2.008 - valid acc 0.490\n","Epoch 79: train loss 1.525 - train acc 0.910 - valid loss 1.978 - valid acc 0.493\n","Best epoch 72, best acc 0.5709459459459459\n","Training with: weight_decay=0.01, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8,test=6/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce740acc37b64f8aa8c4548bc1a5c5a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.259 - train acc 0.143 - valid loss 3.086 - valid acc 0.159\n","Epoch 1: train loss 2.923 - train acc 0.178 - valid loss 3.010 - valid acc 0.122\n","Epoch 2: train loss 2.833 - train acc 0.206 - valid loss 2.986 - valid acc 0.135\n","Epoch 3: train loss 2.683 - train acc 0.227 - valid loss 3.096 - valid acc 0.172\n","Epoch 4: train loss 2.518 - train acc 0.255 - valid loss 2.710 - valid acc 0.199\n","Epoch 5: train loss 2.400 - train acc 0.280 - valid loss 2.936 - valid acc 0.216\n","Epoch 6: train loss 2.334 - train acc 0.286 - valid loss 2.488 - valid acc 0.291\n","Epoch 7: train loss 2.220 - train acc 0.322 - valid loss 2.653 - valid acc 0.250\n","Epoch 8: train loss 2.210 - train acc 0.332 - valid loss 2.504 - valid acc 0.284\n","Epoch 9: train loss 2.187 - train acc 0.333 - valid loss 2.616 - valid acc 0.294\n","Epoch 10: train loss 2.104 - train acc 0.348 - valid loss 2.660 - valid acc 0.331\n","Epoch 11: train loss 2.104 - train acc 0.351 - valid loss 2.589 - valid acc 0.270\n","Epoch 12: train loss 2.030 - train acc 0.371 - valid loss 2.649 - valid acc 0.280\n","Epoch 13: train loss 2.006 - train acc 0.381 - valid loss 2.611 - valid acc 0.230\n","Epoch 14: train loss 1.977 - train acc 0.385 - valid loss 2.326 - valid acc 0.321\n","Epoch 15: train loss 1.907 - train acc 0.381 - valid loss 2.284 - valid acc 0.358\n","Epoch 16: train loss 1.890 - train acc 0.400 - valid loss 2.505 - valid acc 0.324\n","Epoch 17: train loss 1.887 - train acc 0.406 - valid loss 2.315 - valid acc 0.314\n","Epoch 18: train loss 1.839 - train acc 0.409 - valid loss 2.485 - valid acc 0.277\n","Epoch 19: train loss 1.779 - train acc 0.417 - valid loss 2.476 - valid acc 0.284\n","Epoch 20: train loss 1.788 - train acc 0.428 - valid loss 2.404 - valid acc 0.297\n","Epoch 21: train loss 1.753 - train acc 0.439 - valid loss 2.330 - valid acc 0.331\n","Epoch 22: train loss 1.755 - train acc 0.423 - valid loss 2.209 - valid acc 0.338\n","Epoch 23: train loss 1.687 - train acc 0.442 - valid loss 2.166 - valid acc 0.355\n","Epoch 24: train loss 1.699 - train acc 0.453 - valid loss 2.237 - valid acc 0.338\n","Epoch 25: train loss 1.691 - train acc 0.450 - valid loss 2.481 - valid acc 0.314\n","Epoch 26: train loss 1.625 - train acc 0.469 - valid loss 2.160 - valid acc 0.348\n","Epoch 27: train loss 1.619 - train acc 0.467 - valid loss 2.120 - valid acc 0.351\n","Epoch 28: train loss 1.613 - train acc 0.466 - valid loss 2.289 - valid acc 0.291\n","Epoch 29: train loss 1.575 - train acc 0.477 - valid loss 2.119 - valid acc 0.375\n","Epoch 30: train loss 1.554 - train acc 0.482 - valid loss 2.135 - valid acc 0.348\n","Epoch 31: train loss 1.565 - train acc 0.483 - valid loss 2.152 - valid acc 0.372\n","Epoch 32: train loss 1.535 - train acc 0.475 - valid loss 2.246 - valid acc 0.294\n","Epoch 33: train loss 1.527 - train acc 0.497 - valid loss 2.197 - valid acc 0.385\n","Epoch 34: train loss 1.488 - train acc 0.516 - valid loss 2.145 - valid acc 0.372\n","Epoch 35: train loss 1.504 - train acc 0.497 - valid loss 2.167 - valid acc 0.301\n","Epoch 36: train loss 1.503 - train acc 0.503 - valid loss 2.081 - valid acc 0.372\n","Epoch 37: train loss 1.459 - train acc 0.524 - valid loss 2.026 - valid acc 0.389\n","Epoch 38: train loss 1.456 - train acc 0.520 - valid loss 2.029 - valid acc 0.378\n","Epoch 39: train loss 1.418 - train acc 0.529 - valid loss 2.110 - valid acc 0.365\n","Epoch 40: train loss 1.413 - train acc 0.528 - valid loss 1.965 - valid acc 0.409\n","Epoch 41: train loss 1.401 - train acc 0.533 - valid loss 2.195 - valid acc 0.358\n","Epoch 42: train loss 1.408 - train acc 0.533 - valid loss 2.016 - valid acc 0.378\n","Epoch 43: train loss 1.391 - train acc 0.538 - valid loss 2.294 - valid acc 0.338\n","Epoch 44: train loss 1.354 - train acc 0.545 - valid loss 2.159 - valid acc 0.351\n","Epoch 45: train loss 1.380 - train acc 0.547 - valid loss 2.092 - valid acc 0.341\n","Epoch 46: train loss 1.387 - train acc 0.524 - valid loss 2.125 - valid acc 0.338\n","Epoch 47: train loss 1.375 - train acc 0.543 - valid loss 2.118 - valid acc 0.297\n","Epoch 48: train loss 1.368 - train acc 0.531 - valid loss 2.401 - valid acc 0.338\n","Epoch 49: train loss 1.354 - train acc 0.550 - valid loss 2.083 - valid acc 0.345\n","Epoch 50: train loss 1.379 - train acc 0.539 - valid loss 2.019 - valid acc 0.345\n","Epoch 51: train loss 1.385 - train acc 0.546 - valid loss 2.067 - valid acc 0.372\n","Epoch 52: train loss 1.356 - train acc 0.543 - valid loss 2.047 - valid acc 0.334\n","Epoch 53: train loss 1.302 - train acc 0.576 - valid loss 2.068 - valid acc 0.378\n","Epoch 54: train loss 1.346 - train acc 0.562 - valid loss 2.205 - valid acc 0.351\n","Epoch 55: train loss 1.323 - train acc 0.556 - valid loss 2.198 - valid acc 0.358\n","Epoch 56: train loss 1.363 - train acc 0.544 - valid loss 2.094 - valid acc 0.334\n","Epoch 57: train loss 1.308 - train acc 0.565 - valid loss 2.675 - valid acc 0.297\n","Epoch 58: train loss 1.313 - train acc 0.561 - valid loss 2.076 - valid acc 0.389\n","Epoch 59: train loss 1.317 - train acc 0.561 - valid loss 2.175 - valid acc 0.361\n","Epoch 60: train loss 1.334 - train acc 0.562 - valid loss 2.116 - valid acc 0.382\n","Epoch 61: train loss 1.276 - train acc 0.567 - valid loss 1.953 - valid acc 0.429\n","Epoch 62: train loss 1.338 - train acc 0.559 - valid loss 2.025 - valid acc 0.372\n","Epoch 63: train loss 1.273 - train acc 0.570 - valid loss 2.268 - valid acc 0.382\n","Epoch 64: train loss 1.278 - train acc 0.572 - valid loss 2.114 - valid acc 0.385\n","Epoch 65: train loss 1.286 - train acc 0.574 - valid loss 2.282 - valid acc 0.375\n","Epoch 66: train loss 1.266 - train acc 0.586 - valid loss 2.055 - valid acc 0.351\n","Epoch 67: train loss 1.305 - train acc 0.561 - valid loss 2.460 - valid acc 0.314\n","Epoch 68: train loss 1.291 - train acc 0.566 - valid loss 2.128 - valid acc 0.405\n","Epoch 69: train loss 1.285 - train acc 0.572 - valid loss 2.233 - valid acc 0.324\n","Epoch 70: train loss 1.276 - train acc 0.568 - valid loss 2.043 - valid acc 0.389\n","Epoch 71: train loss 1.265 - train acc 0.576 - valid loss 2.148 - valid acc 0.345\n","Epoch 72: train loss 1.258 - train acc 0.590 - valid loss 2.091 - valid acc 0.358\n","Epoch 73: train loss 1.283 - train acc 0.572 - valid loss 2.247 - valid acc 0.392\n","Epoch 74: train loss 1.296 - train acc 0.567 - valid loss 1.942 - valid acc 0.422\n","Epoch 75: train loss 1.295 - train acc 0.575 - valid loss 1.934 - valid acc 0.402\n","Epoch 76: train loss 1.234 - train acc 0.575 - valid loss 2.292 - valid acc 0.355\n","Epoch 77: train loss 1.268 - train acc 0.584 - valid loss 2.011 - valid acc 0.399\n","Epoch 78: train loss 1.269 - train acc 0.581 - valid loss 2.151 - valid acc 0.365\n","Epoch 79: train loss 1.217 - train acc 0.601 - valid loss 2.190 - valid acc 0.392\n","Best epoch 61, best acc 0.42905405405405406\n","Training with: weight_decay=0.01, label_smoothing=0.05, lr=0.001, channels=16, batch_size=8,test=7/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"162d0673db51470cb04c92954398b05a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.178 - train acc 0.152 - valid loss 3.031 - valid acc 0.213\n","Epoch 1: train loss 2.857 - train acc 0.209 - valid loss 2.986 - valid acc 0.179\n","Epoch 2: train loss 2.774 - train acc 0.227 - valid loss 2.744 - valid acc 0.233\n","Epoch 3: train loss 2.708 - train acc 0.238 - valid loss 2.860 - valid acc 0.216\n","Epoch 4: train loss 2.647 - train acc 0.254 - valid loss 2.769 - valid acc 0.247\n","Epoch 5: train loss 2.590 - train acc 0.267 - valid loss 2.695 - valid acc 0.247\n","Epoch 6: train loss 2.543 - train acc 0.284 - valid loss 2.632 - valid acc 0.247\n","Epoch 7: train loss 2.479 - train acc 0.304 - valid loss 2.881 - valid acc 0.274\n","Epoch 8: train loss 2.442 - train acc 0.308 - valid loss 2.589 - valid acc 0.277\n","Epoch 9: train loss 2.348 - train acc 0.338 - valid loss 2.560 - valid acc 0.307\n","Epoch 10: train loss 2.321 - train acc 0.347 - valid loss 2.402 - valid acc 0.321\n","Epoch 11: train loss 2.296 - train acc 0.355 - valid loss 2.521 - valid acc 0.253\n","Epoch 12: train loss 2.279 - train acc 0.358 - valid loss 2.398 - valid acc 0.297\n","Epoch 13: train loss 2.227 - train acc 0.370 - valid loss 2.618 - valid acc 0.331\n","Epoch 14: train loss 2.154 - train acc 0.387 - valid loss 2.274 - valid acc 0.382\n","Epoch 15: train loss 2.124 - train acc 0.384 - valid loss 2.372 - valid acc 0.314\n","Epoch 16: train loss 2.062 - train acc 0.412 - valid loss 2.273 - valid acc 0.291\n","Epoch 17: train loss 2.031 - train acc 0.430 - valid loss 2.211 - valid acc 0.361\n","Epoch 18: train loss 1.955 - train acc 0.450 - valid loss 2.115 - valid acc 0.372\n","Epoch 19: train loss 1.949 - train acc 0.444 - valid loss 2.105 - valid acc 0.345\n","Epoch 20: train loss 1.929 - train acc 0.458 - valid loss 2.330 - valid acc 0.311\n","Epoch 21: train loss 1.879 - train acc 0.468 - valid loss 2.220 - valid acc 0.355\n","Epoch 22: train loss 1.881 - train acc 0.470 - valid loss 2.161 - valid acc 0.368\n","Epoch 23: train loss 1.858 - train acc 0.484 - valid loss 2.356 - valid acc 0.307\n","Epoch 24: train loss 1.850 - train acc 0.480 - valid loss 2.077 - valid acc 0.341\n","Epoch 25: train loss 1.833 - train acc 0.481 - valid loss 2.113 - valid acc 0.328\n","Epoch 26: train loss 1.802 - train acc 0.502 - valid loss 2.192 - valid acc 0.358\n","Epoch 27: train loss 1.817 - train acc 0.498 - valid loss 2.065 - valid acc 0.361\n","Epoch 28: train loss 1.806 - train acc 0.493 - valid loss 2.088 - valid acc 0.382\n","Epoch 29: train loss 1.781 - train acc 0.501 - valid loss 2.019 - valid acc 0.399\n","Epoch 30: train loss 1.754 - train acc 0.524 - valid loss 2.144 - valid acc 0.341\n","Epoch 31: train loss 1.759 - train acc 0.516 - valid loss 2.137 - valid acc 0.338\n","Epoch 32: train loss 1.744 - train acc 0.522 - valid loss 2.063 - valid acc 0.361\n","Epoch 33: train loss 1.720 - train acc 0.520 - valid loss 2.093 - valid acc 0.368\n","Epoch 34: train loss 1.733 - train acc 0.518 - valid loss 2.227 - valid acc 0.348\n","Epoch 35: train loss 1.707 - train acc 0.543 - valid loss 2.383 - valid acc 0.314\n","Epoch 36: train loss 1.677 - train acc 0.528 - valid loss 2.135 - valid acc 0.358\n","Epoch 37: train loss 1.669 - train acc 0.550 - valid loss 2.174 - valid acc 0.338\n","Epoch 38: train loss 1.684 - train acc 0.539 - valid loss 2.253 - valid acc 0.321\n","Epoch 39: train loss 1.701 - train acc 0.537 - valid loss 2.113 - valid acc 0.399\n","Epoch 40: train loss 1.652 - train acc 0.556 - valid loss 2.149 - valid acc 0.341\n","Epoch 41: train loss 1.651 - train acc 0.553 - valid loss 2.100 - valid acc 0.392\n","Epoch 42: train loss 1.633 - train acc 0.564 - valid loss 1.996 - valid acc 0.429\n","Epoch 43: train loss 1.657 - train acc 0.560 - valid loss 2.213 - valid acc 0.334\n","Epoch 44: train loss 1.655 - train acc 0.544 - valid loss 2.176 - valid acc 0.358\n","Epoch 45: train loss 1.646 - train acc 0.541 - valid loss 2.166 - valid acc 0.382\n","Epoch 46: train loss 1.639 - train acc 0.553 - valid loss 2.178 - valid acc 0.399\n","Epoch 47: train loss 1.616 - train acc 0.565 - valid loss 2.310 - valid acc 0.389\n","Epoch 48: train loss 1.623 - train acc 0.555 - valid loss 2.187 - valid acc 0.334\n","Epoch 49: train loss 1.630 - train acc 0.556 - valid loss 1.982 - valid acc 0.432\n","Epoch 50: train loss 1.573 - train acc 0.586 - valid loss 2.392 - valid acc 0.311\n","Epoch 51: train loss 1.603 - train acc 0.565 - valid loss 2.042 - valid acc 0.402\n","Epoch 52: train loss 1.569 - train acc 0.584 - valid loss 2.133 - valid acc 0.402\n","Epoch 53: train loss 1.580 - train acc 0.567 - valid loss 2.345 - valid acc 0.348\n","Epoch 54: train loss 1.572 - train acc 0.577 - valid loss 1.964 - valid acc 0.395\n","Epoch 55: train loss 1.580 - train acc 0.584 - valid loss 2.069 - valid acc 0.385\n","Epoch 56: train loss 1.573 - train acc 0.584 - valid loss 2.035 - valid acc 0.392\n","Epoch 57: train loss 1.562 - train acc 0.572 - valid loss 2.018 - valid acc 0.389\n","Epoch 58: train loss 1.551 - train acc 0.581 - valid loss 1.932 - valid acc 0.419\n","Epoch 59: train loss 1.542 - train acc 0.575 - valid loss 2.182 - valid acc 0.348\n","Epoch 60: train loss 1.586 - train acc 0.567 - valid loss 2.122 - valid acc 0.345\n","Epoch 61: train loss 1.549 - train acc 0.585 - valid loss 2.068 - valid acc 0.419\n","Epoch 62: train loss 1.537 - train acc 0.595 - valid loss 2.274 - valid acc 0.389\n","Epoch 63: train loss 1.584 - train acc 0.581 - valid loss 2.242 - valid acc 0.382\n","Epoch 64: train loss 1.509 - train acc 0.618 - valid loss 2.352 - valid acc 0.361\n","Epoch 65: train loss 1.518 - train acc 0.604 - valid loss 2.336 - valid acc 0.334\n","Epoch 66: train loss 1.548 - train acc 0.594 - valid loss 2.142 - valid acc 0.345\n","Epoch 67: train loss 1.544 - train acc 0.594 - valid loss 2.016 - valid acc 0.399\n","Epoch 68: train loss 1.543 - train acc 0.595 - valid loss 2.248 - valid acc 0.382\n","Epoch 69: train loss 1.536 - train acc 0.609 - valid loss 2.098 - valid acc 0.361\n","Epoch 70: train loss 1.527 - train acc 0.595 - valid loss 2.247 - valid acc 0.358\n","Epoch 71: train loss 1.517 - train acc 0.607 - valid loss 2.037 - valid acc 0.375\n","Epoch 72: train loss 1.527 - train acc 0.589 - valid loss 2.084 - valid acc 0.341\n","Epoch 73: train loss 1.523 - train acc 0.600 - valid loss 2.239 - valid acc 0.361\n","Epoch 74: train loss 1.528 - train acc 0.605 - valid loss 2.118 - valid acc 0.355\n","Epoch 75: train loss 1.529 - train acc 0.599 - valid loss 2.082 - valid acc 0.368\n","Epoch 76: train loss 1.481 - train acc 0.622 - valid loss 2.117 - valid acc 0.395\n","Epoch 77: train loss 1.494 - train acc 0.625 - valid loss 2.072 - valid acc 0.389\n","Epoch 78: train loss 1.484 - train acc 0.617 - valid loss 2.023 - valid acc 0.419\n","Epoch 79: train loss 1.489 - train acc 0.625 - valid loss 2.095 - valid acc 0.361\n","Best epoch 49, best acc 0.43243243243243246\n","Training with: weight_decay=0.01, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8,test=8/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dff8034e077249279ad4fdedb91754be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.266 - train acc 0.156 - valid loss 3.084 - valid acc 0.182\n","Epoch 1: train loss 3.109 - train acc 0.195 - valid loss 3.006 - valid acc 0.203\n","Epoch 2: train loss 2.990 - train acc 0.211 - valid loss 2.871 - valid acc 0.233\n","Epoch 3: train loss 2.884 - train acc 0.233 - valid loss 3.084 - valid acc 0.145\n","Epoch 4: train loss 2.791 - train acc 0.263 - valid loss 2.735 - valid acc 0.277\n","Epoch 5: train loss 2.700 - train acc 0.294 - valid loss 2.805 - valid acc 0.233\n","Epoch 6: train loss 2.612 - train acc 0.323 - valid loss 2.565 - valid acc 0.297\n","Epoch 7: train loss 2.560 - train acc 0.331 - valid loss 2.727 - valid acc 0.247\n","Epoch 8: train loss 2.514 - train acc 0.342 - valid loss 2.624 - valid acc 0.240\n","Epoch 9: train loss 2.453 - train acc 0.358 - valid loss 2.468 - valid acc 0.287\n","Epoch 10: train loss 2.406 - train acc 0.366 - valid loss 2.532 - valid acc 0.318\n","Epoch 11: train loss 2.348 - train acc 0.388 - valid loss 2.379 - valid acc 0.304\n","Epoch 12: train loss 2.303 - train acc 0.400 - valid loss 2.481 - valid acc 0.294\n","Epoch 13: train loss 2.246 - train acc 0.429 - valid loss 2.281 - valid acc 0.361\n","Epoch 14: train loss 2.175 - train acc 0.463 - valid loss 2.233 - valid acc 0.348\n","Epoch 15: train loss 2.172 - train acc 0.460 - valid loss 2.229 - valid acc 0.321\n","Epoch 16: train loss 2.119 - train acc 0.465 - valid loss 2.258 - valid acc 0.334\n","Epoch 17: train loss 2.100 - train acc 0.470 - valid loss 2.224 - valid acc 0.345\n","Epoch 18: train loss 2.087 - train acc 0.478 - valid loss 2.264 - valid acc 0.348\n","Epoch 19: train loss 2.064 - train acc 0.481 - valid loss 2.184 - valid acc 0.331\n","Epoch 20: train loss 2.044 - train acc 0.487 - valid loss 2.120 - valid acc 0.341\n","Epoch 21: train loss 2.049 - train acc 0.500 - valid loss 2.018 - valid acc 0.392\n","Epoch 22: train loss 2.005 - train acc 0.495 - valid loss 2.330 - valid acc 0.331\n","Epoch 23: train loss 1.997 - train acc 0.504 - valid loss 2.224 - valid acc 0.341\n","Epoch 24: train loss 1.990 - train acc 0.501 - valid loss 2.049 - valid acc 0.382\n","Epoch 25: train loss 1.968 - train acc 0.527 - valid loss 2.107 - valid acc 0.412\n","Epoch 26: train loss 1.970 - train acc 0.513 - valid loss 2.146 - valid acc 0.351\n","Epoch 27: train loss 1.983 - train acc 0.499 - valid loss 2.095 - valid acc 0.368\n","Epoch 28: train loss 1.965 - train acc 0.511 - valid loss 2.050 - valid acc 0.412\n","Epoch 29: train loss 1.933 - train acc 0.541 - valid loss 2.002 - valid acc 0.389\n","Epoch 30: train loss 1.971 - train acc 0.511 - valid loss 2.151 - valid acc 0.358\n","Epoch 31: train loss 1.927 - train acc 0.534 - valid loss 2.063 - valid acc 0.355\n","Epoch 32: train loss 1.949 - train acc 0.516 - valid loss 1.974 - valid acc 0.419\n","Epoch 33: train loss 1.923 - train acc 0.525 - valid loss 2.125 - valid acc 0.375\n","Epoch 34: train loss 1.929 - train acc 0.536 - valid loss 2.163 - valid acc 0.378\n","Epoch 35: train loss 1.910 - train acc 0.544 - valid loss 1.949 - valid acc 0.409\n","Epoch 36: train loss 1.885 - train acc 0.546 - valid loss 2.032 - valid acc 0.412\n","Epoch 37: train loss 1.885 - train acc 0.545 - valid loss 2.196 - valid acc 0.368\n","Epoch 38: train loss 1.903 - train acc 0.544 - valid loss 2.026 - valid acc 0.355\n","Epoch 39: train loss 1.882 - train acc 0.545 - valid loss 2.112 - valid acc 0.395\n","Epoch 40: train loss 1.894 - train acc 0.533 - valid loss 2.218 - valid acc 0.372\n","Epoch 41: train loss 1.891 - train acc 0.545 - valid loss 2.000 - valid acc 0.345\n","Epoch 42: train loss 1.876 - train acc 0.540 - valid loss 2.161 - valid acc 0.375\n","Epoch 43: train loss 1.824 - train acc 0.566 - valid loss 1.971 - valid acc 0.419\n","Epoch 44: train loss 1.877 - train acc 0.565 - valid loss 2.055 - valid acc 0.422\n","Epoch 45: train loss 1.863 - train acc 0.550 - valid loss 2.157 - valid acc 0.341\n","Epoch 46: train loss 1.861 - train acc 0.552 - valid loss 2.193 - valid acc 0.358\n","Epoch 47: train loss 1.849 - train acc 0.562 - valid loss 1.994 - valid acc 0.419\n","Epoch 48: train loss 1.851 - train acc 0.559 - valid loss 1.969 - valid acc 0.368\n","Epoch 49: train loss 1.860 - train acc 0.557 - valid loss 2.028 - valid acc 0.402\n","Epoch 50: train loss 1.844 - train acc 0.568 - valid loss 2.203 - valid acc 0.389\n","Epoch 51: train loss 1.825 - train acc 0.567 - valid loss 2.115 - valid acc 0.389\n","Epoch 52: train loss 1.832 - train acc 0.568 - valid loss 2.217 - valid acc 0.345\n","Epoch 53: train loss 1.828 - train acc 0.572 - valid loss 2.073 - valid acc 0.385\n","Epoch 54: train loss 1.813 - train acc 0.567 - valid loss 1.867 - valid acc 0.409\n","Epoch 55: train loss 1.821 - train acc 0.573 - valid loss 2.077 - valid acc 0.345\n","Epoch 56: train loss 1.838 - train acc 0.569 - valid loss 1.903 - valid acc 0.412\n","Epoch 57: train loss 1.845 - train acc 0.565 - valid loss 2.017 - valid acc 0.412\n","Epoch 58: train loss 1.813 - train acc 0.580 - valid loss 1.992 - valid acc 0.409\n","Epoch 59: train loss 1.818 - train acc 0.573 - valid loss 2.058 - valid acc 0.368\n","Epoch 60: train loss 1.807 - train acc 0.578 - valid loss 2.131 - valid acc 0.402\n","Epoch 61: train loss 1.825 - train acc 0.564 - valid loss 2.061 - valid acc 0.375\n","Epoch 62: train loss 1.808 - train acc 0.586 - valid loss 1.942 - valid acc 0.405\n","Epoch 63: train loss 1.823 - train acc 0.573 - valid loss 2.113 - valid acc 0.361\n","Epoch 64: train loss 1.804 - train acc 0.581 - valid loss 1.984 - valid acc 0.389\n","Epoch 65: train loss 1.836 - train acc 0.571 - valid loss 2.307 - valid acc 0.307\n","Epoch 66: train loss 1.802 - train acc 0.591 - valid loss 1.951 - valid acc 0.405\n","Epoch 67: train loss 1.810 - train acc 0.583 - valid loss 1.964 - valid acc 0.385\n","Epoch 68: train loss 1.821 - train acc 0.574 - valid loss 2.037 - valid acc 0.361\n","Epoch 69: train loss 1.804 - train acc 0.577 - valid loss 1.917 - valid acc 0.416\n","Epoch 70: train loss 1.842 - train acc 0.574 - valid loss 1.986 - valid acc 0.426\n","Epoch 71: train loss 1.800 - train acc 0.579 - valid loss 2.058 - valid acc 0.409\n","Epoch 72: train loss 1.795 - train acc 0.586 - valid loss 2.096 - valid acc 0.365\n","Epoch 73: train loss 1.807 - train acc 0.583 - valid loss 2.176 - valid acc 0.385\n","Epoch 74: train loss 1.813 - train acc 0.578 - valid loss 2.293 - valid acc 0.345\n","Epoch 75: train loss 1.793 - train acc 0.594 - valid loss 2.044 - valid acc 0.358\n","Epoch 76: train loss 1.815 - train acc 0.577 - valid loss 2.075 - valid acc 0.405\n","Epoch 77: train loss 1.796 - train acc 0.584 - valid loss 1.845 - valid acc 0.436\n","Epoch 78: train loss 1.779 - train acc 0.593 - valid loss 2.040 - valid acc 0.392\n","Epoch 79: train loss 1.818 - train acc 0.578 - valid loss 2.020 - valid acc 0.382\n","Best epoch 77, best acc 0.4358108108108108\n","Training with: weight_decay=0.01, label_smoothing=0.15, lr=0.001, channels=16, batch_size=8,test=9/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"884180098b874fddbbc46762f5d276eb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.343 - train acc 0.144 - valid loss 3.040 - valid acc 0.189\n","Epoch 1: train loss 3.080 - train acc 0.206 - valid loss 2.962 - valid acc 0.236\n","Epoch 2: train loss 3.015 - train acc 0.209 - valid loss 2.830 - valid acc 0.236\n","Epoch 3: train loss 2.942 - train acc 0.228 - valid loss 2.810 - valid acc 0.220\n","Epoch 4: train loss 2.874 - train acc 0.249 - valid loss 2.765 - valid acc 0.209\n","Epoch 5: train loss 2.816 - train acc 0.273 - valid loss 2.747 - valid acc 0.199\n","Epoch 6: train loss 2.750 - train acc 0.286 - valid loss 2.697 - valid acc 0.250\n","Epoch 7: train loss 2.728 - train acc 0.302 - valid loss 2.726 - valid acc 0.236\n","Epoch 8: train loss 2.679 - train acc 0.320 - valid loss 2.525 - valid acc 0.321\n","Epoch 9: train loss 2.620 - train acc 0.355 - valid loss 2.506 - valid acc 0.287\n","Epoch 10: train loss 2.557 - train acc 0.367 - valid loss 2.562 - valid acc 0.270\n","Epoch 11: train loss 2.554 - train acc 0.375 - valid loss 2.455 - valid acc 0.284\n","Epoch 12: train loss 2.529 - train acc 0.381 - valid loss 2.360 - valid acc 0.321\n","Epoch 13: train loss 2.493 - train acc 0.392 - valid loss 2.483 - valid acc 0.284\n","Epoch 14: train loss 2.464 - train acc 0.408 - valid loss 2.475 - valid acc 0.260\n","Epoch 15: train loss 2.447 - train acc 0.402 - valid loss 2.555 - valid acc 0.233\n","Epoch 16: train loss 2.413 - train acc 0.419 - valid loss 2.475 - valid acc 0.297\n","Epoch 17: train loss 2.396 - train acc 0.422 - valid loss 2.631 - valid acc 0.260\n","Epoch 18: train loss 2.384 - train acc 0.428 - valid loss 2.416 - valid acc 0.270\n","Epoch 19: train loss 2.368 - train acc 0.438 - valid loss 2.365 - valid acc 0.301\n","Epoch 20: train loss 2.368 - train acc 0.441 - valid loss 2.475 - valid acc 0.260\n","Epoch 21: train loss 2.347 - train acc 0.453 - valid loss 2.213 - valid acc 0.328\n","Epoch 22: train loss 2.326 - train acc 0.447 - valid loss 2.282 - valid acc 0.314\n","Epoch 23: train loss 2.342 - train acc 0.437 - valid loss 2.304 - valid acc 0.257\n","Epoch 24: train loss 2.297 - train acc 0.462 - valid loss 2.374 - valid acc 0.287\n","Epoch 25: train loss 2.299 - train acc 0.457 - valid loss 2.311 - valid acc 0.341\n","Epoch 26: train loss 2.289 - train acc 0.479 - valid loss 2.429 - valid acc 0.277\n","Epoch 27: train loss 2.302 - train acc 0.452 - valid loss 2.252 - valid acc 0.311\n","Epoch 28: train loss 2.285 - train acc 0.466 - valid loss 2.330 - valid acc 0.301\n","Epoch 29: train loss 2.277 - train acc 0.461 - valid loss 2.378 - valid acc 0.314\n","Epoch 30: train loss 2.259 - train acc 0.480 - valid loss 2.273 - valid acc 0.321\n","Epoch 31: train loss 2.261 - train acc 0.473 - valid loss 2.248 - valid acc 0.297\n","Epoch 32: train loss 2.268 - train acc 0.471 - valid loss 2.156 - valid acc 0.355\n","Epoch 33: train loss 2.238 - train acc 0.486 - valid loss 2.189 - valid acc 0.378\n","Epoch 34: train loss 2.234 - train acc 0.480 - valid loss 2.255 - valid acc 0.321\n","Epoch 35: train loss 2.229 - train acc 0.492 - valid loss 2.238 - valid acc 0.348\n","Epoch 36: train loss 2.219 - train acc 0.492 - valid loss 2.136 - valid acc 0.378\n","Epoch 37: train loss 2.239 - train acc 0.494 - valid loss 2.089 - valid acc 0.375\n","Epoch 38: train loss 2.217 - train acc 0.495 - valid loss 2.280 - valid acc 0.331\n","Epoch 39: train loss 2.193 - train acc 0.510 - valid loss 2.133 - valid acc 0.348\n","Epoch 40: train loss 2.233 - train acc 0.485 - valid loss 2.139 - valid acc 0.368\n","Epoch 41: train loss 2.207 - train acc 0.503 - valid loss 2.393 - valid acc 0.284\n","Epoch 42: train loss 2.212 - train acc 0.498 - valid loss 2.180 - valid acc 0.331\n","Epoch 43: train loss 2.186 - train acc 0.504 - valid loss 2.194 - valid acc 0.348\n","Epoch 44: train loss 2.184 - train acc 0.514 - valid loss 2.339 - valid acc 0.257\n","Epoch 45: train loss 2.194 - train acc 0.506 - valid loss 2.256 - valid acc 0.311\n","Epoch 46: train loss 2.175 - train acc 0.505 - valid loss 2.110 - valid acc 0.351\n","Epoch 47: train loss 2.179 - train acc 0.502 - valid loss 2.173 - valid acc 0.314\n","Epoch 48: train loss 2.165 - train acc 0.517 - valid loss 2.233 - valid acc 0.307\n","Epoch 49: train loss 2.176 - train acc 0.518 - valid loss 2.106 - valid acc 0.345\n","Epoch 50: train loss 2.171 - train acc 0.515 - valid loss 2.210 - valid acc 0.334\n","Epoch 51: train loss 2.160 - train acc 0.512 - valid loss 2.332 - valid acc 0.307\n","Epoch 52: train loss 2.155 - train acc 0.514 - valid loss 2.226 - valid acc 0.341\n","Epoch 53: train loss 2.180 - train acc 0.506 - valid loss 2.167 - valid acc 0.341\n","Epoch 54: train loss 2.154 - train acc 0.512 - valid loss 2.236 - valid acc 0.280\n","Epoch 55: train loss 2.169 - train acc 0.514 - valid loss 2.202 - valid acc 0.338\n","Epoch 56: train loss 2.136 - train acc 0.531 - valid loss 2.172 - valid acc 0.314\n","Epoch 57: train loss 2.154 - train acc 0.531 - valid loss 2.245 - valid acc 0.294\n","Epoch 58: train loss 2.146 - train acc 0.515 - valid loss 2.090 - valid acc 0.341\n","Epoch 59: train loss 2.142 - train acc 0.536 - valid loss 2.264 - valid acc 0.328\n","Epoch 60: train loss 2.136 - train acc 0.523 - valid loss 2.340 - valid acc 0.307\n","Epoch 61: train loss 2.158 - train acc 0.523 - valid loss 2.293 - valid acc 0.314\n","Epoch 62: train loss 2.132 - train acc 0.525 - valid loss 2.310 - valid acc 0.280\n","Epoch 63: train loss 2.113 - train acc 0.539 - valid loss 2.213 - valid acc 0.348\n","Epoch 64: train loss 2.117 - train acc 0.539 - valid loss 2.218 - valid acc 0.318\n","Epoch 65: train loss 2.106 - train acc 0.544 - valid loss 2.127 - valid acc 0.378\n","Epoch 66: train loss 2.115 - train acc 0.536 - valid loss 2.186 - valid acc 0.311\n","Epoch 67: train loss 2.136 - train acc 0.515 - valid loss 2.085 - valid acc 0.355\n","Epoch 68: train loss 2.129 - train acc 0.528 - valid loss 2.341 - valid acc 0.321\n","Epoch 69: train loss 2.115 - train acc 0.537 - valid loss 2.105 - valid acc 0.375\n","Epoch 70: train loss 2.121 - train acc 0.526 - valid loss 2.290 - valid acc 0.291\n","Epoch 71: train loss 2.113 - train acc 0.541 - valid loss 2.227 - valid acc 0.314\n","Epoch 72: train loss 2.136 - train acc 0.527 - valid loss 2.155 - valid acc 0.348\n","Epoch 73: train loss 2.098 - train acc 0.552 - valid loss 2.165 - valid acc 0.378\n","Epoch 74: train loss 2.119 - train acc 0.538 - valid loss 2.238 - valid acc 0.311\n","Epoch 75: train loss 2.119 - train acc 0.545 - valid loss 2.195 - valid acc 0.328\n","Epoch 76: train loss 2.123 - train acc 0.533 - valid loss 2.460 - valid acc 0.274\n","Epoch 77: train loss 2.109 - train acc 0.543 - valid loss 2.296 - valid acc 0.314\n","Epoch 78: train loss 2.104 - train acc 0.550 - valid loss 2.206 - valid acc 0.392\n","Epoch 79: train loss 2.095 - train acc 0.548 - valid loss 2.152 - valid acc 0.351\n","Best epoch 78, best acc 0.3918918918918919\n","Training with: weight_decay=0.01, label_smoothing=0.2, lr=0.001, channels=16, batch_size=8,test=10/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3395211cf71b49aa83333dc62eb3b72c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.339 - train acc 0.157 - valid loss 3.088 - valid acc 0.155\n","Epoch 1: train loss 3.126 - train acc 0.208 - valid loss 2.948 - valid acc 0.176\n","Epoch 2: train loss 3.073 - train acc 0.217 - valid loss 2.836 - valid acc 0.206\n","Epoch 3: train loss 3.013 - train acc 0.233 - valid loss 2.810 - valid acc 0.257\n","Epoch 4: train loss 2.959 - train acc 0.250 - valid loss 2.771 - valid acc 0.236\n","Epoch 5: train loss 2.929 - train acc 0.271 - valid loss 2.691 - valid acc 0.307\n","Epoch 6: train loss 2.893 - train acc 0.291 - valid loss 2.674 - valid acc 0.270\n","Epoch 7: train loss 2.863 - train acc 0.291 - valid loss 2.743 - valid acc 0.267\n","Epoch 8: train loss 2.835 - train acc 0.302 - valid loss 2.706 - valid acc 0.284\n","Epoch 9: train loss 2.806 - train acc 0.312 - valid loss 2.622 - valid acc 0.267\n","Epoch 10: train loss 2.783 - train acc 0.312 - valid loss 2.479 - valid acc 0.324\n","Epoch 11: train loss 2.722 - train acc 0.340 - valid loss 2.369 - valid acc 0.307\n","Epoch 12: train loss 2.697 - train acc 0.353 - valid loss 2.483 - valid acc 0.301\n","Epoch 13: train loss 2.697 - train acc 0.368 - valid loss 2.364 - valid acc 0.345\n","Epoch 14: train loss 2.671 - train acc 0.358 - valid loss 2.460 - valid acc 0.324\n","Epoch 15: train loss 2.630 - train acc 0.381 - valid loss 2.479 - valid acc 0.375\n","Epoch 16: train loss 2.611 - train acc 0.388 - valid loss 2.331 - valid acc 0.348\n","Epoch 17: train loss 2.546 - train acc 0.419 - valid loss 2.488 - valid acc 0.267\n","Epoch 18: train loss 2.535 - train acc 0.421 - valid loss 2.380 - valid acc 0.321\n","Epoch 19: train loss 2.497 - train acc 0.449 - valid loss 2.369 - valid acc 0.338\n","Epoch 20: train loss 2.482 - train acc 0.436 - valid loss 2.445 - valid acc 0.280\n","Epoch 21: train loss 2.462 - train acc 0.444 - valid loss 2.269 - valid acc 0.348\n","Epoch 22: train loss 2.453 - train acc 0.456 - valid loss 2.309 - valid acc 0.307\n","Epoch 23: train loss 2.413 - train acc 0.468 - valid loss 2.329 - valid acc 0.348\n","Epoch 24: train loss 2.398 - train acc 0.484 - valid loss 2.279 - valid acc 0.355\n","Epoch 25: train loss 2.368 - train acc 0.483 - valid loss 2.222 - valid acc 0.382\n","Epoch 26: train loss 2.378 - train acc 0.482 - valid loss 2.187 - valid acc 0.338\n","Epoch 27: train loss 2.373 - train acc 0.484 - valid loss 2.388 - valid acc 0.324\n","Epoch 28: train loss 2.393 - train acc 0.484 - valid loss 2.232 - valid acc 0.358\n","Epoch 29: train loss 2.351 - train acc 0.500 - valid loss 2.298 - valid acc 0.324\n","Epoch 30: train loss 2.354 - train acc 0.501 - valid loss 2.224 - valid acc 0.351\n","Epoch 31: train loss 2.337 - train acc 0.512 - valid loss 2.422 - valid acc 0.307\n","Epoch 32: train loss 2.342 - train acc 0.500 - valid loss 2.303 - valid acc 0.358\n","Epoch 33: train loss 2.307 - train acc 0.527 - valid loss 2.208 - valid acc 0.399\n","Epoch 34: train loss 2.313 - train acc 0.518 - valid loss 2.156 - valid acc 0.355\n","Epoch 35: train loss 2.341 - train acc 0.510 - valid loss 2.258 - valid acc 0.307\n","Epoch 36: train loss 2.318 - train acc 0.523 - valid loss 2.371 - valid acc 0.297\n","Epoch 37: train loss 2.305 - train acc 0.527 - valid loss 2.205 - valid acc 0.345\n","Epoch 38: train loss 2.303 - train acc 0.517 - valid loss 2.318 - valid acc 0.304\n","Epoch 39: train loss 2.303 - train acc 0.512 - valid loss 2.354 - valid acc 0.348\n","Epoch 40: train loss 2.310 - train acc 0.526 - valid loss 2.346 - valid acc 0.345\n","Epoch 41: train loss 2.299 - train acc 0.532 - valid loss 2.393 - valid acc 0.280\n","Epoch 42: train loss 2.306 - train acc 0.521 - valid loss 2.297 - valid acc 0.341\n","Epoch 43: train loss 2.303 - train acc 0.523 - valid loss 2.219 - valid acc 0.372\n","Epoch 44: train loss 2.309 - train acc 0.535 - valid loss 2.399 - valid acc 0.331\n","Epoch 45: train loss 2.309 - train acc 0.516 - valid loss 2.495 - valid acc 0.264\n","Epoch 46: train loss 2.290 - train acc 0.519 - valid loss 2.361 - valid acc 0.304\n","Epoch 47: train loss 2.284 - train acc 0.526 - valid loss 2.478 - valid acc 0.264\n","Epoch 48: train loss 2.273 - train acc 0.524 - valid loss 2.228 - valid acc 0.341\n","Epoch 49: train loss 2.276 - train acc 0.538 - valid loss 2.254 - valid acc 0.351\n","Epoch 50: train loss 2.272 - train acc 0.541 - valid loss 2.294 - valid acc 0.334\n","Epoch 51: train loss 2.262 - train acc 0.540 - valid loss 2.279 - valid acc 0.318\n","Epoch 52: train loss 2.283 - train acc 0.537 - valid loss 2.330 - valid acc 0.304\n","Epoch 53: train loss 2.274 - train acc 0.540 - valid loss 2.320 - valid acc 0.361\n","Epoch 54: train loss 2.266 - train acc 0.545 - valid loss 2.254 - valid acc 0.348\n","Epoch 55: train loss 2.268 - train acc 0.544 - valid loss 2.334 - valid acc 0.338\n","Epoch 56: train loss 2.262 - train acc 0.536 - valid loss 2.156 - valid acc 0.361\n","Epoch 57: train loss 2.218 - train acc 0.559 - valid loss 2.274 - valid acc 0.324\n","Epoch 58: train loss 2.281 - train acc 0.545 - valid loss 2.285 - valid acc 0.338\n","Epoch 59: train loss 2.269 - train acc 0.540 - valid loss 2.385 - valid acc 0.318\n","Epoch 60: train loss 2.233 - train acc 0.550 - valid loss 2.247 - valid acc 0.365\n","Epoch 61: train loss 2.253 - train acc 0.546 - valid loss 2.194 - valid acc 0.348\n","Epoch 62: train loss 2.236 - train acc 0.556 - valid loss 2.219 - valid acc 0.351\n","Epoch 63: train loss 2.242 - train acc 0.545 - valid loss 2.325 - valid acc 0.324\n","Epoch 64: train loss 2.237 - train acc 0.558 - valid loss 2.236 - valid acc 0.301\n","Epoch 65: train loss 2.258 - train acc 0.543 - valid loss 2.441 - valid acc 0.297\n","Epoch 66: train loss 2.234 - train acc 0.559 - valid loss 2.318 - valid acc 0.311\n","Epoch 67: train loss 2.254 - train acc 0.550 - valid loss 2.216 - valid acc 0.338\n","Epoch 68: train loss 2.217 - train acc 0.574 - valid loss 2.392 - valid acc 0.341\n","Epoch 69: train loss 2.234 - train acc 0.556 - valid loss 2.210 - valid acc 0.372\n","Epoch 70: train loss 2.253 - train acc 0.544 - valid loss 2.285 - valid acc 0.338\n","Epoch 71: train loss 2.232 - train acc 0.548 - valid loss 2.199 - valid acc 0.338\n","Epoch 72: train loss 2.213 - train acc 0.556 - valid loss 2.331 - valid acc 0.304\n","Epoch 73: train loss 2.236 - train acc 0.550 - valid loss 2.261 - valid acc 0.328\n","Epoch 74: train loss 2.222 - train acc 0.565 - valid loss 2.295 - valid acc 0.287\n","Epoch 75: train loss 2.228 - train acc 0.564 - valid loss 2.189 - valid acc 0.358\n","Epoch 76: train loss 2.216 - train acc 0.562 - valid loss 2.206 - valid acc 0.375\n","Epoch 77: train loss 2.206 - train acc 0.567 - valid loss 2.338 - valid acc 0.274\n","Epoch 78: train loss 2.205 - train acc 0.572 - valid loss 2.278 - valid acc 0.385\n","Epoch 79: train loss 2.198 - train acc 0.577 - valid loss 2.321 - valid acc 0.331\n","Best epoch 33, best acc 0.39864864864864863\n","Training with: weight_decay=0.001, label_smoothing=0.0, lr=0.001, channels=16, batch_size=8,test=11/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6180ea0a1b5b47afaf644706992e4911","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.091 - train acc 0.172 - valid loss 2.998 - valid acc 0.179\n","Epoch 1: train loss 2.429 - train acc 0.282 - valid loss 2.853 - valid acc 0.199\n","Epoch 2: train loss 2.167 - train acc 0.330 - valid loss 2.635 - valid acc 0.291\n","Epoch 3: train loss 2.000 - train acc 0.390 - valid loss 2.395 - valid acc 0.334\n","Epoch 4: train loss 1.751 - train acc 0.439 - valid loss 2.236 - valid acc 0.355\n","Epoch 5: train loss 1.669 - train acc 0.455 - valid loss 2.261 - valid acc 0.324\n","Epoch 6: train loss 1.550 - train acc 0.494 - valid loss 2.468 - valid acc 0.324\n","Epoch 7: train loss 1.432 - train acc 0.540 - valid loss 2.371 - valid acc 0.338\n","Epoch 8: train loss 1.414 - train acc 0.536 - valid loss 2.185 - valid acc 0.355\n","Epoch 9: train loss 1.398 - train acc 0.539 - valid loss 1.951 - valid acc 0.392\n","Epoch 10: train loss 1.325 - train acc 0.578 - valid loss 2.160 - valid acc 0.345\n","Epoch 11: train loss 1.291 - train acc 0.581 - valid loss 2.019 - valid acc 0.389\n","Epoch 12: train loss 1.244 - train acc 0.587 - valid loss 2.362 - valid acc 0.334\n","Epoch 13: train loss 1.261 - train acc 0.583 - valid loss 2.280 - valid acc 0.348\n","Epoch 14: train loss 1.213 - train acc 0.602 - valid loss 2.227 - valid acc 0.372\n","Epoch 15: train loss 1.211 - train acc 0.598 - valid loss 2.120 - valid acc 0.372\n","Epoch 16: train loss 1.169 - train acc 0.609 - valid loss 1.956 - valid acc 0.405\n","Epoch 17: train loss 1.127 - train acc 0.630 - valid loss 2.006 - valid acc 0.412\n","Epoch 18: train loss 1.097 - train acc 0.630 - valid loss 2.054 - valid acc 0.405\n","Epoch 19: train loss 1.085 - train acc 0.638 - valid loss 1.923 - valid acc 0.422\n","Epoch 20: train loss 1.119 - train acc 0.624 - valid loss 1.935 - valid acc 0.456\n","Epoch 21: train loss 1.074 - train acc 0.641 - valid loss 2.106 - valid acc 0.436\n","Epoch 22: train loss 1.025 - train acc 0.653 - valid loss 1.903 - valid acc 0.497\n","Epoch 23: train loss 1.049 - train acc 0.652 - valid loss 1.930 - valid acc 0.426\n","Epoch 24: train loss 1.046 - train acc 0.652 - valid loss 1.865 - valid acc 0.456\n","Epoch 25: train loss 1.050 - train acc 0.660 - valid loss 2.151 - valid acc 0.405\n","Epoch 26: train loss 1.025 - train acc 0.657 - valid loss 2.235 - valid acc 0.402\n","Epoch 27: train loss 1.000 - train acc 0.672 - valid loss 2.287 - valid acc 0.412\n","Epoch 28: train loss 0.969 - train acc 0.673 - valid loss 2.066 - valid acc 0.419\n","Epoch 29: train loss 0.968 - train acc 0.683 - valid loss 1.982 - valid acc 0.514\n","Epoch 30: train loss 0.971 - train acc 0.677 - valid loss 2.490 - valid acc 0.361\n","Epoch 31: train loss 0.927 - train acc 0.685 - valid loss 2.227 - valid acc 0.382\n","Epoch 32: train loss 0.898 - train acc 0.699 - valid loss 2.061 - valid acc 0.419\n","Epoch 33: train loss 0.973 - train acc 0.683 - valid loss 2.121 - valid acc 0.426\n","Epoch 34: train loss 0.929 - train acc 0.692 - valid loss 2.212 - valid acc 0.392\n","Epoch 35: train loss 0.922 - train acc 0.693 - valid loss 2.070 - valid acc 0.422\n","Epoch 36: train loss 0.919 - train acc 0.695 - valid loss 2.104 - valid acc 0.399\n","Epoch 37: train loss 0.895 - train acc 0.708 - valid loss 2.191 - valid acc 0.405\n","Epoch 38: train loss 0.893 - train acc 0.704 - valid loss 2.126 - valid acc 0.426\n","Epoch 39: train loss 0.865 - train acc 0.703 - valid loss 2.194 - valid acc 0.409\n","Epoch 40: train loss 0.884 - train acc 0.709 - valid loss 2.316 - valid acc 0.399\n","Epoch 41: train loss 0.880 - train acc 0.713 - valid loss 2.359 - valid acc 0.432\n","Epoch 42: train loss 0.845 - train acc 0.719 - valid loss 1.949 - valid acc 0.473\n","Epoch 43: train loss 0.859 - train acc 0.720 - valid loss 2.472 - valid acc 0.426\n","Epoch 44: train loss 0.891 - train acc 0.694 - valid loss 1.861 - valid acc 0.476\n","Epoch 45: train loss 0.841 - train acc 0.725 - valid loss 2.302 - valid acc 0.392\n","Epoch 46: train loss 0.865 - train acc 0.711 - valid loss 2.067 - valid acc 0.459\n","Epoch 47: train loss 0.833 - train acc 0.725 - valid loss 1.980 - valid acc 0.466\n","Epoch 48: train loss 0.816 - train acc 0.729 - valid loss 2.357 - valid acc 0.422\n","Epoch 49: train loss 0.796 - train acc 0.736 - valid loss 1.997 - valid acc 0.476\n","Epoch 50: train loss 0.821 - train acc 0.733 - valid loss 2.080 - valid acc 0.416\n","Epoch 51: train loss 0.792 - train acc 0.729 - valid loss 2.352 - valid acc 0.389\n","Epoch 52: train loss 0.799 - train acc 0.729 - valid loss 2.440 - valid acc 0.419\n","Epoch 53: train loss 0.785 - train acc 0.741 - valid loss 2.295 - valid acc 0.463\n","Epoch 54: train loss 0.803 - train acc 0.741 - valid loss 1.896 - valid acc 0.439\n","Epoch 55: train loss 0.800 - train acc 0.739 - valid loss 2.404 - valid acc 0.426\n","Epoch 56: train loss 0.804 - train acc 0.730 - valid loss 2.112 - valid acc 0.446\n","Epoch 57: train loss 0.787 - train acc 0.741 - valid loss 2.756 - valid acc 0.412\n","Epoch 58: train loss 0.785 - train acc 0.746 - valid loss 2.290 - valid acc 0.429\n","Epoch 59: train loss 0.780 - train acc 0.746 - valid loss 2.544 - valid acc 0.432\n","Epoch 60: train loss 0.765 - train acc 0.756 - valid loss 2.039 - valid acc 0.426\n","Epoch 61: train loss 0.769 - train acc 0.749 - valid loss 2.098 - valid acc 0.470\n","Epoch 62: train loss 0.774 - train acc 0.745 - valid loss 2.254 - valid acc 0.382\n","Epoch 63: train loss 0.770 - train acc 0.741 - valid loss 1.973 - valid acc 0.493\n","Epoch 64: train loss 0.775 - train acc 0.745 - valid loss 1.912 - valid acc 0.459\n","Epoch 65: train loss 0.737 - train acc 0.760 - valid loss 2.455 - valid acc 0.389\n","Epoch 66: train loss 0.770 - train acc 0.755 - valid loss 1.911 - valid acc 0.466\n","Epoch 67: train loss 0.735 - train acc 0.760 - valid loss 2.058 - valid acc 0.463\n","Epoch 68: train loss 0.731 - train acc 0.758 - valid loss 2.694 - valid acc 0.412\n","Epoch 69: train loss 0.764 - train acc 0.749 - valid loss 2.067 - valid acc 0.466\n","Epoch 70: train loss 0.769 - train acc 0.753 - valid loss 2.386 - valid acc 0.405\n","Epoch 71: train loss 0.794 - train acc 0.742 - valid loss 1.996 - valid acc 0.466\n","Epoch 72: train loss 0.772 - train acc 0.740 - valid loss 2.071 - valid acc 0.493\n","Epoch 73: train loss 0.706 - train acc 0.774 - valid loss 2.069 - valid acc 0.453\n","Epoch 74: train loss 0.754 - train acc 0.758 - valid loss 2.062 - valid acc 0.436\n","Epoch 75: train loss 0.689 - train acc 0.772 - valid loss 2.247 - valid acc 0.470\n","Epoch 76: train loss 0.737 - train acc 0.761 - valid loss 2.326 - valid acc 0.419\n","Epoch 77: train loss 0.735 - train acc 0.762 - valid loss 2.267 - valid acc 0.429\n","Epoch 78: train loss 0.709 - train acc 0.760 - valid loss 1.994 - valid acc 0.507\n","Epoch 79: train loss 0.687 - train acc 0.774 - valid loss 2.333 - valid acc 0.443\n","Best epoch 29, best acc 0.5135135135135135\n","Training with: weight_decay=0.001, label_smoothing=0.05, lr=0.001, channels=16, batch_size=8,test=12/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83de9b7c1bba4642ad0bddea8622d098","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.168 - train acc 0.165 - valid loss 2.898 - valid acc 0.182\n","Epoch 1: train loss 2.621 - train acc 0.268 - valid loss 2.616 - valid acc 0.291\n","Epoch 2: train loss 2.383 - train acc 0.338 - valid loss 2.691 - valid acc 0.257\n","Epoch 3: train loss 2.227 - train acc 0.387 - valid loss 2.405 - valid acc 0.287\n","Epoch 4: train loss 2.143 - train acc 0.416 - valid loss 2.446 - valid acc 0.294\n","Epoch 5: train loss 1.958 - train acc 0.456 - valid loss 2.340 - valid acc 0.361\n","Epoch 6: train loss 1.884 - train acc 0.485 - valid loss 2.085 - valid acc 0.419\n","Epoch 7: train loss 1.803 - train acc 0.506 - valid loss 1.978 - valid acc 0.409\n","Epoch 8: train loss 1.726 - train acc 0.521 - valid loss 1.962 - valid acc 0.419\n","Epoch 9: train loss 1.682 - train acc 0.543 - valid loss 1.992 - valid acc 0.368\n","Epoch 10: train loss 1.648 - train acc 0.546 - valid loss 1.977 - valid acc 0.392\n","Epoch 11: train loss 1.562 - train acc 0.597 - valid loss 1.876 - valid acc 0.446\n","Epoch 12: train loss 1.550 - train acc 0.595 - valid loss 2.088 - valid acc 0.382\n","Epoch 13: train loss 1.518 - train acc 0.601 - valid loss 1.981 - valid acc 0.409\n","Epoch 14: train loss 1.501 - train acc 0.604 - valid loss 1.933 - valid acc 0.426\n","Epoch 15: train loss 1.455 - train acc 0.632 - valid loss 2.085 - valid acc 0.368\n","Epoch 16: train loss 1.449 - train acc 0.631 - valid loss 1.837 - valid acc 0.395\n","Epoch 17: train loss 1.432 - train acc 0.640 - valid loss 1.722 - valid acc 0.446\n","Epoch 18: train loss 1.378 - train acc 0.654 - valid loss 1.944 - valid acc 0.419\n","Epoch 19: train loss 1.340 - train acc 0.684 - valid loss 1.987 - valid acc 0.395\n","Epoch 20: train loss 1.359 - train acc 0.660 - valid loss 1.888 - valid acc 0.382\n","Epoch 21: train loss 1.352 - train acc 0.672 - valid loss 1.913 - valid acc 0.412\n","Epoch 22: train loss 1.338 - train acc 0.681 - valid loss 1.970 - valid acc 0.392\n","Epoch 23: train loss 1.300 - train acc 0.692 - valid loss 1.848 - valid acc 0.480\n","Epoch 24: train loss 1.286 - train acc 0.694 - valid loss 1.622 - valid acc 0.500\n","Epoch 25: train loss 1.295 - train acc 0.686 - valid loss 1.763 - valid acc 0.459\n","Epoch 26: train loss 1.211 - train acc 0.716 - valid loss 1.775 - valid acc 0.486\n","Epoch 27: train loss 1.269 - train acc 0.705 - valid loss 1.711 - valid acc 0.470\n","Epoch 28: train loss 1.240 - train acc 0.713 - valid loss 2.070 - valid acc 0.422\n","Epoch 29: train loss 1.205 - train acc 0.723 - valid loss 1.993 - valid acc 0.493\n","Epoch 30: train loss 1.255 - train acc 0.707 - valid loss 1.818 - valid acc 0.463\n","Epoch 31: train loss 1.194 - train acc 0.734 - valid loss 1.929 - valid acc 0.412\n","Epoch 32: train loss 1.208 - train acc 0.724 - valid loss 1.919 - valid acc 0.473\n","Epoch 33: train loss 1.187 - train acc 0.734 - valid loss 1.876 - valid acc 0.449\n","Epoch 34: train loss 1.169 - train acc 0.744 - valid loss 1.671 - valid acc 0.490\n","Epoch 35: train loss 1.184 - train acc 0.733 - valid loss 1.652 - valid acc 0.497\n","Epoch 36: train loss 1.152 - train acc 0.742 - valid loss 1.868 - valid acc 0.463\n","Epoch 37: train loss 1.154 - train acc 0.739 - valid loss 1.803 - valid acc 0.503\n","Epoch 38: train loss 1.149 - train acc 0.752 - valid loss 1.821 - valid acc 0.500\n","Epoch 39: train loss 1.155 - train acc 0.747 - valid loss 1.804 - valid acc 0.480\n","Epoch 40: train loss 1.153 - train acc 0.750 - valid loss 1.820 - valid acc 0.493\n","Epoch 41: train loss 1.126 - train acc 0.753 - valid loss 1.827 - valid acc 0.459\n","Epoch 42: train loss 1.152 - train acc 0.747 - valid loss 2.018 - valid acc 0.456\n","Epoch 43: train loss 1.118 - train acc 0.764 - valid loss 1.731 - valid acc 0.476\n","Epoch 44: train loss 1.109 - train acc 0.766 - valid loss 1.858 - valid acc 0.470\n","Epoch 45: train loss 1.107 - train acc 0.761 - valid loss 1.839 - valid acc 0.443\n","Epoch 46: train loss 1.096 - train acc 0.769 - valid loss 1.836 - valid acc 0.470\n","Epoch 47: train loss 1.104 - train acc 0.759 - valid loss 1.793 - valid acc 0.459\n","Epoch 48: train loss 1.089 - train acc 0.762 - valid loss 2.065 - valid acc 0.486\n","Epoch 49: train loss 1.091 - train acc 0.775 - valid loss 1.815 - valid acc 0.453\n","Epoch 50: train loss 1.147 - train acc 0.757 - valid loss 1.618 - valid acc 0.507\n","Epoch 51: train loss 1.050 - train acc 0.789 - valid loss 1.959 - valid acc 0.429\n","Epoch 52: train loss 1.101 - train acc 0.772 - valid loss 1.905 - valid acc 0.476\n","Epoch 53: train loss 1.090 - train acc 0.768 - valid loss 1.930 - valid acc 0.422\n","Epoch 54: train loss 1.072 - train acc 0.775 - valid loss 1.858 - valid acc 0.470\n","Epoch 55: train loss 1.054 - train acc 0.779 - valid loss 1.857 - valid acc 0.449\n","Epoch 56: train loss 1.047 - train acc 0.784 - valid loss 1.732 - valid acc 0.473\n","Epoch 57: train loss 1.041 - train acc 0.794 - valid loss 1.776 - valid acc 0.483\n","Epoch 58: train loss 1.079 - train acc 0.772 - valid loss 1.741 - valid acc 0.500\n","Epoch 59: train loss 1.059 - train acc 0.782 - valid loss 1.750 - valid acc 0.517\n","Epoch 60: train loss 1.058 - train acc 0.776 - valid loss 1.928 - valid acc 0.416\n","Epoch 61: train loss 1.048 - train acc 0.775 - valid loss 1.812 - valid acc 0.459\n","Epoch 62: train loss 1.014 - train acc 0.800 - valid loss 1.804 - valid acc 0.480\n","Epoch 63: train loss 1.068 - train acc 0.777 - valid loss 2.115 - valid acc 0.439\n","Epoch 64: train loss 1.007 - train acc 0.805 - valid loss 1.960 - valid acc 0.483\n","Epoch 65: train loss 1.079 - train acc 0.769 - valid loss 1.746 - valid acc 0.497\n","Epoch 66: train loss 1.066 - train acc 0.782 - valid loss 2.065 - valid acc 0.456\n","Epoch 67: train loss 1.002 - train acc 0.804 - valid loss 1.814 - valid acc 0.510\n","Epoch 68: train loss 1.038 - train acc 0.795 - valid loss 1.806 - valid acc 0.463\n","Epoch 69: train loss 1.039 - train acc 0.790 - valid loss 1.878 - valid acc 0.514\n","Epoch 70: train loss 1.013 - train acc 0.794 - valid loss 1.774 - valid acc 0.466\n","Epoch 71: train loss 1.023 - train acc 0.792 - valid loss 1.711 - valid acc 0.493\n","Epoch 72: train loss 1.024 - train acc 0.794 - valid loss 1.885 - valid acc 0.466\n","Epoch 73: train loss 1.023 - train acc 0.803 - valid loss 1.960 - valid acc 0.443\n","Epoch 74: train loss 1.014 - train acc 0.797 - valid loss 1.597 - valid acc 0.534\n","Epoch 75: train loss 1.014 - train acc 0.799 - valid loss 2.127 - valid acc 0.389\n","Epoch 76: train loss 1.000 - train acc 0.807 - valid loss 1.862 - valid acc 0.497\n","Epoch 77: train loss 1.000 - train acc 0.801 - valid loss 1.842 - valid acc 0.503\n","Epoch 78: train loss 1.018 - train acc 0.796 - valid loss 1.878 - valid acc 0.463\n","Epoch 79: train loss 0.993 - train acc 0.803 - valid loss 1.697 - valid acc 0.466\n","Best epoch 74, best acc 0.5337837837837838\n","Training with: weight_decay=0.001, label_smoothing=0.1, lr=0.001, channels=16, batch_size=8,test=13/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7852317a7e041e688fa9a6ed0782096","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.203 - train acc 0.181 - valid loss 2.937 - valid acc 0.189\n","Epoch 1: train loss 2.798 - train acc 0.266 - valid loss 2.826 - valid acc 0.220\n","Epoch 2: train loss 2.597 - train acc 0.308 - valid loss 2.731 - valid acc 0.257\n","Epoch 3: train loss 2.461 - train acc 0.346 - valid loss 2.456 - valid acc 0.341\n","Epoch 4: train loss 2.288 - train acc 0.411 - valid loss 2.464 - valid acc 0.277\n","Epoch 5: train loss 2.201 - train acc 0.439 - valid loss 2.192 - valid acc 0.368\n","Epoch 6: train loss 2.106 - train acc 0.457 - valid loss 2.149 - valid acc 0.358\n","Epoch 7: train loss 2.026 - train acc 0.497 - valid loss 2.072 - valid acc 0.409\n","Epoch 8: train loss 1.939 - train acc 0.530 - valid loss 2.201 - valid acc 0.368\n","Epoch 9: train loss 1.888 - train acc 0.540 - valid loss 2.209 - valid acc 0.392\n","Epoch 10: train loss 1.878 - train acc 0.555 - valid loss 2.261 - valid acc 0.348\n","Epoch 11: train loss 1.839 - train acc 0.558 - valid loss 2.043 - valid acc 0.436\n","Epoch 12: train loss 1.784 - train acc 0.579 - valid loss 2.054 - valid acc 0.402\n","Epoch 13: train loss 1.753 - train acc 0.602 - valid loss 1.866 - valid acc 0.459\n","Epoch 14: train loss 1.750 - train acc 0.601 - valid loss 2.005 - valid acc 0.385\n","Epoch 15: train loss 1.716 - train acc 0.614 - valid loss 2.120 - valid acc 0.358\n","Epoch 16: train loss 1.668 - train acc 0.629 - valid loss 2.022 - valid acc 0.416\n","Epoch 17: train loss 1.679 - train acc 0.638 - valid loss 1.985 - valid acc 0.422\n","Epoch 18: train loss 1.639 - train acc 0.648 - valid loss 1.849 - valid acc 0.436\n","Epoch 19: train loss 1.638 - train acc 0.644 - valid loss 1.949 - valid acc 0.429\n","Epoch 20: train loss 1.613 - train acc 0.663 - valid loss 1.919 - valid acc 0.419\n","Epoch 21: train loss 1.615 - train acc 0.656 - valid loss 1.930 - valid acc 0.453\n","Epoch 22: train loss 1.565 - train acc 0.685 - valid loss 1.871 - valid acc 0.486\n","Epoch 23: train loss 1.573 - train acc 0.681 - valid loss 1.941 - valid acc 0.453\n","Epoch 24: train loss 1.535 - train acc 0.700 - valid loss 1.891 - valid acc 0.500\n","Epoch 25: train loss 1.527 - train acc 0.693 - valid loss 2.098 - valid acc 0.412\n","Epoch 26: train loss 1.525 - train acc 0.700 - valid loss 2.025 - valid acc 0.419\n","Epoch 27: train loss 1.524 - train acc 0.703 - valid loss 1.792 - valid acc 0.500\n","Epoch 28: train loss 1.502 - train acc 0.702 - valid loss 2.126 - valid acc 0.416\n","Epoch 29: train loss 1.522 - train acc 0.701 - valid loss 2.079 - valid acc 0.416\n","Epoch 30: train loss 1.475 - train acc 0.711 - valid loss 2.065 - valid acc 0.439\n","Epoch 31: train loss 1.498 - train acc 0.711 - valid loss 2.090 - valid acc 0.416\n","Epoch 32: train loss 1.487 - train acc 0.719 - valid loss 2.007 - valid acc 0.480\n","Epoch 33: train loss 1.470 - train acc 0.723 - valid loss 1.912 - valid acc 0.449\n","Epoch 34: train loss 1.446 - train acc 0.736 - valid loss 1.888 - valid acc 0.459\n","Epoch 35: train loss 1.462 - train acc 0.727 - valid loss 2.066 - valid acc 0.429\n","Epoch 36: train loss 1.431 - train acc 0.750 - valid loss 1.887 - valid acc 0.470\n","Epoch 37: train loss 1.423 - train acc 0.742 - valid loss 2.004 - valid acc 0.439\n","Epoch 38: train loss 1.451 - train acc 0.720 - valid loss 1.972 - valid acc 0.412\n","Epoch 39: train loss 1.399 - train acc 0.753 - valid loss 1.943 - valid acc 0.453\n","Epoch 40: train loss 1.407 - train acc 0.752 - valid loss 2.085 - valid acc 0.412\n","Epoch 41: train loss 1.392 - train acc 0.759 - valid loss 2.150 - valid acc 0.395\n","Epoch 42: train loss 1.434 - train acc 0.739 - valid loss 2.182 - valid acc 0.368\n","Epoch 43: train loss 1.398 - train acc 0.765 - valid loss 1.986 - valid acc 0.443\n","Epoch 44: train loss 1.431 - train acc 0.742 - valid loss 2.153 - valid acc 0.432\n","Epoch 45: train loss 1.395 - train acc 0.763 - valid loss 1.891 - valid acc 0.510\n","Epoch 46: train loss 1.371 - train acc 0.769 - valid loss 1.882 - valid acc 0.480\n","Epoch 47: train loss 1.398 - train acc 0.765 - valid loss 1.979 - valid acc 0.480\n","Epoch 48: train loss 1.373 - train acc 0.769 - valid loss 1.979 - valid acc 0.429\n","Epoch 49: train loss 1.354 - train acc 0.767 - valid loss 1.976 - valid acc 0.483\n","Epoch 50: train loss 1.390 - train acc 0.761 - valid loss 1.940 - valid acc 0.480\n","Epoch 51: train loss 1.372 - train acc 0.763 - valid loss 1.984 - valid acc 0.476\n","Epoch 52: train loss 1.384 - train acc 0.759 - valid loss 1.948 - valid acc 0.473\n","Epoch 53: train loss 1.365 - train acc 0.774 - valid loss 1.894 - valid acc 0.470\n","Epoch 54: train loss 1.361 - train acc 0.770 - valid loss 2.106 - valid acc 0.439\n","Epoch 55: train loss 1.380 - train acc 0.764 - valid loss 2.006 - valid acc 0.439\n","Epoch 56: train loss 1.341 - train acc 0.780 - valid loss 2.106 - valid acc 0.443\n","Epoch 57: train loss 1.341 - train acc 0.777 - valid loss 1.960 - valid acc 0.463\n","Epoch 58: train loss 1.341 - train acc 0.779 - valid loss 1.969 - valid acc 0.466\n","Epoch 59: train loss 1.380 - train acc 0.763 - valid loss 1.840 - valid acc 0.470\n","Epoch 60: train loss 1.354 - train acc 0.771 - valid loss 2.024 - valid acc 0.436\n","Epoch 61: train loss 1.326 - train acc 0.783 - valid loss 2.027 - valid acc 0.426\n","Epoch 62: train loss 1.361 - train acc 0.769 - valid loss 1.762 - valid acc 0.510\n","Epoch 63: train loss 1.291 - train acc 0.798 - valid loss 2.029 - valid acc 0.436\n","Epoch 64: train loss 1.290 - train acc 0.799 - valid loss 1.883 - valid acc 0.493\n","Epoch 65: train loss 1.323 - train acc 0.793 - valid loss 1.958 - valid acc 0.422\n","Epoch 66: train loss 1.319 - train acc 0.790 - valid loss 2.139 - valid acc 0.422\n","Epoch 67: train loss 1.331 - train acc 0.772 - valid loss 1.867 - valid acc 0.490\n","Epoch 68: train loss 1.299 - train acc 0.797 - valid loss 2.138 - valid acc 0.449\n","Epoch 69: train loss 1.270 - train acc 0.814 - valid loss 2.197 - valid acc 0.409\n","Epoch 70: train loss 1.296 - train acc 0.787 - valid loss 1.935 - valid acc 0.426\n","Epoch 71: train loss 1.293 - train acc 0.804 - valid loss 1.824 - valid acc 0.490\n","Epoch 72: train loss 1.322 - train acc 0.795 - valid loss 1.994 - valid acc 0.463\n","Epoch 73: train loss 1.291 - train acc 0.803 - valid loss 1.820 - valid acc 0.507\n","Epoch 74: train loss 1.295 - train acc 0.786 - valid loss 2.052 - valid acc 0.422\n","Epoch 75: train loss 1.301 - train acc 0.788 - valid loss 2.140 - valid acc 0.426\n","Epoch 76: train loss 1.277 - train acc 0.808 - valid loss 2.021 - valid acc 0.453\n","Epoch 77: train loss 1.291 - train acc 0.801 - valid loss 1.914 - valid acc 0.483\n","Epoch 78: train loss 1.305 - train acc 0.791 - valid loss 2.018 - valid acc 0.436\n","Epoch 79: train loss 1.293 - train acc 0.801 - valid loss 1.766 - valid acc 0.497\n","Best epoch 45, best acc 0.5101351351351351\n","Training with: weight_decay=0.001, label_smoothing=0.15, lr=0.001, channels=16, batch_size=8,test=14/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7d33ee98010438890ade08aaa08f74e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.307 - train acc 0.156 - valid loss 3.168 - valid acc 0.139\n","Epoch 1: train loss 2.998 - train acc 0.231 - valid loss 2.830 - valid acc 0.267\n","Epoch 2: train loss 2.832 - train acc 0.291 - valid loss 2.681 - valid acc 0.236\n","Epoch 3: train loss 2.691 - train acc 0.330 - valid loss 2.573 - valid acc 0.301\n","Epoch 4: train loss 2.551 - train acc 0.378 - valid loss 2.537 - valid acc 0.284\n","Epoch 5: train loss 2.458 - train acc 0.401 - valid loss 2.333 - valid acc 0.314\n","Epoch 6: train loss 2.363 - train acc 0.450 - valid loss 2.563 - valid acc 0.247\n","Epoch 7: train loss 2.299 - train acc 0.461 - valid loss 2.206 - valid acc 0.345\n","Epoch 8: train loss 2.219 - train acc 0.488 - valid loss 2.495 - valid acc 0.297\n","Epoch 9: train loss 2.142 - train acc 0.514 - valid loss 2.166 - valid acc 0.361\n","Epoch 10: train loss 2.124 - train acc 0.531 - valid loss 2.111 - valid acc 0.372\n","Epoch 11: train loss 2.064 - train acc 0.555 - valid loss 2.075 - valid acc 0.382\n","Epoch 12: train loss 2.044 - train acc 0.566 - valid loss 2.199 - valid acc 0.331\n","Epoch 13: train loss 2.005 - train acc 0.576 - valid loss 2.106 - valid acc 0.399\n","Epoch 14: train loss 1.992 - train acc 0.587 - valid loss 1.962 - valid acc 0.375\n","Epoch 15: train loss 1.988 - train acc 0.582 - valid loss 2.265 - valid acc 0.321\n","Epoch 16: train loss 1.954 - train acc 0.599 - valid loss 2.012 - valid acc 0.392\n","Epoch 17: train loss 1.938 - train acc 0.614 - valid loss 2.058 - valid acc 0.422\n","Epoch 18: train loss 1.936 - train acc 0.606 - valid loss 2.039 - valid acc 0.375\n","Epoch 19: train loss 1.910 - train acc 0.625 - valid loss 1.969 - valid acc 0.422\n","Epoch 20: train loss 1.907 - train acc 0.632 - valid loss 1.937 - valid acc 0.436\n","Epoch 21: train loss 1.895 - train acc 0.628 - valid loss 1.979 - valid acc 0.419\n","Epoch 22: train loss 1.876 - train acc 0.637 - valid loss 2.047 - valid acc 0.443\n","Epoch 23: train loss 1.874 - train acc 0.639 - valid loss 2.077 - valid acc 0.348\n","Epoch 24: train loss 1.861 - train acc 0.651 - valid loss 1.986 - valid acc 0.416\n","Epoch 25: train loss 1.825 - train acc 0.674 - valid loss 2.082 - valid acc 0.399\n","Epoch 26: train loss 1.824 - train acc 0.667 - valid loss 1.982 - valid acc 0.419\n","Epoch 27: train loss 1.806 - train acc 0.678 - valid loss 2.094 - valid acc 0.395\n","Epoch 28: train loss 1.820 - train acc 0.669 - valid loss 1.972 - valid acc 0.436\n","Epoch 29: train loss 1.789 - train acc 0.680 - valid loss 1.867 - valid acc 0.473\n","Epoch 30: train loss 1.768 - train acc 0.693 - valid loss 1.868 - valid acc 0.473\n","Epoch 31: train loss 1.780 - train acc 0.688 - valid loss 1.922 - valid acc 0.449\n","Epoch 32: train loss 1.771 - train acc 0.685 - valid loss 2.012 - valid acc 0.412\n","Epoch 33: train loss 1.771 - train acc 0.691 - valid loss 1.888 - valid acc 0.463\n","Epoch 34: train loss 1.770 - train acc 0.698 - valid loss 1.987 - valid acc 0.412\n","Epoch 35: train loss 1.757 - train acc 0.698 - valid loss 1.938 - valid acc 0.446\n","Epoch 36: train loss 1.728 - train acc 0.706 - valid loss 1.994 - valid acc 0.446\n","Epoch 37: train loss 1.723 - train acc 0.717 - valid loss 1.881 - valid acc 0.453\n","Epoch 38: train loss 1.744 - train acc 0.707 - valid loss 1.921 - valid acc 0.456\n","Epoch 39: train loss 1.758 - train acc 0.691 - valid loss 2.075 - valid acc 0.399\n","Epoch 40: train loss 1.746 - train acc 0.702 - valid loss 1.956 - valid acc 0.456\n","Epoch 41: train loss 1.728 - train acc 0.708 - valid loss 2.139 - valid acc 0.392\n","Epoch 42: train loss 1.690 - train acc 0.723 - valid loss 2.014 - valid acc 0.402\n","Epoch 43: train loss 1.718 - train acc 0.720 - valid loss 1.972 - valid acc 0.466\n","Epoch 44: train loss 1.728 - train acc 0.705 - valid loss 2.090 - valid acc 0.399\n","Epoch 45: train loss 1.701 - train acc 0.728 - valid loss 2.031 - valid acc 0.409\n","Epoch 46: train loss 1.692 - train acc 0.727 - valid loss 2.059 - valid acc 0.422\n","Epoch 47: train loss 1.710 - train acc 0.719 - valid loss 2.016 - valid acc 0.449\n","Epoch 48: train loss 1.707 - train acc 0.713 - valid loss 1.836 - valid acc 0.510\n","Epoch 49: train loss 1.705 - train acc 0.726 - valid loss 1.929 - valid acc 0.483\n","Epoch 50: train loss 1.707 - train acc 0.725 - valid loss 1.872 - valid acc 0.456\n","Epoch 51: train loss 1.670 - train acc 0.745 - valid loss 2.007 - valid acc 0.419\n","Epoch 52: train loss 1.692 - train acc 0.725 - valid loss 1.859 - valid acc 0.486\n","Epoch 53: train loss 1.696 - train acc 0.727 - valid loss 1.928 - valid acc 0.453\n","Epoch 54: train loss 1.669 - train acc 0.740 - valid loss 1.879 - valid acc 0.459\n","Epoch 55: train loss 1.670 - train acc 0.734 - valid loss 1.900 - valid acc 0.432\n","Epoch 56: train loss 1.640 - train acc 0.754 - valid loss 1.797 - valid acc 0.490\n","Epoch 57: train loss 1.665 - train acc 0.743 - valid loss 1.799 - valid acc 0.524\n","Epoch 58: train loss 1.683 - train acc 0.744 - valid loss 1.757 - valid acc 0.480\n","Epoch 59: train loss 1.634 - train acc 0.748 - valid loss 1.877 - valid acc 0.483\n","Epoch 60: train loss 1.635 - train acc 0.752 - valid loss 1.813 - valid acc 0.493\n","Epoch 61: train loss 1.660 - train acc 0.744 - valid loss 2.008 - valid acc 0.456\n","Epoch 62: train loss 1.624 - train acc 0.770 - valid loss 1.914 - valid acc 0.473\n","Epoch 63: train loss 1.634 - train acc 0.747 - valid loss 1.983 - valid acc 0.443\n","Epoch 64: train loss 1.635 - train acc 0.751 - valid loss 1.820 - valid acc 0.476\n","Epoch 65: train loss 1.628 - train acc 0.759 - valid loss 1.834 - valid acc 0.490\n","Epoch 66: train loss 1.631 - train acc 0.762 - valid loss 1.878 - valid acc 0.446\n","Epoch 67: train loss 1.648 - train acc 0.758 - valid loss 1.834 - valid acc 0.490\n","Epoch 68: train loss 1.624 - train acc 0.758 - valid loss 1.900 - valid acc 0.476\n","Epoch 69: train loss 1.608 - train acc 0.774 - valid loss 1.942 - valid acc 0.456\n","Epoch 70: train loss 1.611 - train acc 0.767 - valid loss 1.948 - valid acc 0.463\n","Epoch 71: train loss 1.624 - train acc 0.768 - valid loss 1.763 - valid acc 0.480\n","Epoch 72: train loss 1.624 - train acc 0.763 - valid loss 1.899 - valid acc 0.476\n","Epoch 73: train loss 1.631 - train acc 0.759 - valid loss 2.108 - valid acc 0.372\n","Epoch 74: train loss 1.604 - train acc 0.774 - valid loss 1.899 - valid acc 0.500\n","Epoch 75: train loss 1.614 - train acc 0.769 - valid loss 1.814 - valid acc 0.470\n","Epoch 76: train loss 1.577 - train acc 0.785 - valid loss 1.869 - valid acc 0.470\n","Epoch 77: train loss 1.608 - train acc 0.773 - valid loss 1.857 - valid acc 0.500\n","Epoch 78: train loss 1.603 - train acc 0.772 - valid loss 1.834 - valid acc 0.490\n","Epoch 79: train loss 1.594 - train acc 0.778 - valid loss 1.919 - valid acc 0.449\n","Best epoch 57, best acc 0.5236486486486487\n","Training with: weight_decay=0.001, label_smoothing=0.2, lr=0.001, channels=16, batch_size=8,test=15/15\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5caff1929bc4f13b6be061babaa5cb4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0: train loss 3.322 - train acc 0.178 - valid loss 3.073 - valid acc 0.179\n","Epoch 1: train loss 3.055 - train acc 0.237 - valid loss 2.793 - valid acc 0.236\n","Epoch 2: train loss 2.855 - train acc 0.312 - valid loss 2.577 - valid acc 0.311\n","Epoch 3: train loss 2.713 - train acc 0.381 - valid loss 2.453 - valid acc 0.324\n","Epoch 4: train loss 2.619 - train acc 0.403 - valid loss 2.315 - valid acc 0.345\n","Epoch 5: train loss 2.509 - train acc 0.438 - valid loss 2.332 - valid acc 0.331\n","Epoch 6: train loss 2.447 - train acc 0.466 - valid loss 2.345 - valid acc 0.338\n","Epoch 7: train loss 2.389 - train acc 0.494 - valid loss 2.191 - valid acc 0.429\n","Epoch 8: train loss 2.328 - train acc 0.516 - valid loss 2.305 - valid acc 0.358\n","Epoch 9: train loss 2.292 - train acc 0.540 - valid loss 2.263 - valid acc 0.321\n","Epoch 10: train loss 2.284 - train acc 0.549 - valid loss 2.143 - valid acc 0.351\n","Epoch 11: train loss 2.212 - train acc 0.569 - valid loss 2.141 - valid acc 0.361\n","Epoch 12: train loss 2.187 - train acc 0.578 - valid loss 2.205 - valid acc 0.416\n","Epoch 13: train loss 2.154 - train acc 0.599 - valid loss 2.068 - valid acc 0.449\n","Epoch 14: train loss 2.164 - train acc 0.591 - valid loss 2.195 - valid acc 0.382\n","Epoch 15: train loss 2.122 - train acc 0.611 - valid loss 2.161 - valid acc 0.429\n","Epoch 16: train loss 2.124 - train acc 0.617 - valid loss 2.174 - valid acc 0.382\n","Epoch 17: train loss 2.113 - train acc 0.623 - valid loss 2.122 - valid acc 0.405\n","Epoch 18: train loss 2.077 - train acc 0.622 - valid loss 2.545 - valid acc 0.307\n","Epoch 19: train loss 2.065 - train acc 0.644 - valid loss 1.946 - valid acc 0.446\n","Epoch 20: train loss 2.024 - train acc 0.660 - valid loss 2.114 - valid acc 0.426\n","Epoch 21: train loss 2.074 - train acc 0.636 - valid loss 2.043 - valid acc 0.412\n","Epoch 22: train loss 2.030 - train acc 0.669 - valid loss 1.986 - valid acc 0.456\n","Epoch 23: train loss 2.024 - train acc 0.664 - valid loss 2.088 - valid acc 0.405\n","Epoch 24: train loss 2.001 - train acc 0.680 - valid loss 2.035 - valid acc 0.439\n","Epoch 25: train loss 2.019 - train acc 0.662 - valid loss 2.012 - valid acc 0.483\n","Epoch 26: train loss 1.989 - train acc 0.672 - valid loss 2.193 - valid acc 0.463\n","Epoch 27: train loss 1.990 - train acc 0.680 - valid loss 2.148 - valid acc 0.378\n","Epoch 28: train loss 1.981 - train acc 0.682 - valid loss 2.049 - valid acc 0.422\n","Epoch 29: train loss 1.983 - train acc 0.681 - valid loss 2.119 - valid acc 0.419\n","Epoch 30: train loss 1.960 - train acc 0.697 - valid loss 2.036 - valid acc 0.453\n","Epoch 31: train loss 1.920 - train acc 0.711 - valid loss 1.981 - valid acc 0.459\n","Epoch 32: train loss 1.933 - train acc 0.701 - valid loss 2.240 - valid acc 0.368\n","Epoch 33: train loss 1.956 - train acc 0.700 - valid loss 2.225 - valid acc 0.368\n","Epoch 34: train loss 1.958 - train acc 0.701 - valid loss 2.088 - valid acc 0.429\n","Epoch 35: train loss 1.899 - train acc 0.724 - valid loss 1.978 - valid acc 0.456\n","Epoch 36: train loss 1.924 - train acc 0.710 - valid loss 2.016 - valid acc 0.439\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with: weight_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, label_smoothing=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_smoothing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, channels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,test=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_iteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m test_iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 29\u001b[0m best_val_acc, best_params, best_epoch, found \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[19], line 21\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_dl, epochs, opt, val_dl, verbose, label_smoothing)\u001b[0m\n\u001b[0;32m     19\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_data \u001b[38;5;129;01min\u001b[39;00m train_dl:\n\u001b[1;32m---> 21\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     labels \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m     scores \u001b[38;5;241m=\u001b[39m model(imgs)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["weight_decays = [0.0,0.01,0.001]\n","label_smoothings = [0.0, 0.05, 0.1, 0.15, 0.2]\n","lrs = [0.001]#, 0.0001]\n","channels = [16]\n","batches = [8]\n","#p_dropout = [0.1,0.3,0.5]\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\n","#test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n","\n","epochs = 80\n","test_iteration = 1\n","total_test = len(weight_decays)*len(label_smoothings)*len(lrs)*len(channels)*len(batches)#*len(p_dropout)\n","#Training with: weight_decay=0.0, label_smoothing=0.5, lr=0.001, channels=16, batch_size=8\n","\n","for weight_decay in weight_decays:\n","    for label_smoothing in label_smoothings:\n","        for lr in lrs:\n","            for channel in channels:\n","                for batch in batches:\n","                    model = ExtendedCNN(channels=channel, num_classes=num_classes,p_dropout=0)\n","                    model.to(device)\n","\n","                    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","                    print(f\"Training with: weight_decay={weight_decay}, label_smoothing={label_smoothing}, lr={lr}, channels={channel}, batch_size={batch},test={test_iteration}/{total_test}\")\n","                    test_iteration+=1\n","                    best_val_acc, best_params, best_epoch, found = train_loop(\n","                        model,\n","                        train_loader,\n","                        epochs,\n","                        optimizer,\n","                        val_loader,\n","                        verbose=True,\n","                        label_smoothing = label_smoothing,\n","                    )"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0619950dfc8441a08c3d501226374cee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"084d0b5e95cf4f508fedb093a9cace90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ab5b022aa5a419481a0e99ed82ef986":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_084d0b5e95cf4f508fedb093a9cace90","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_708edf09837642f58a4feaa64500ed66","value":20}},"0d21484dba744589823686ea95ce27f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1093b31ac743463a8d09fc710233e45e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c7f75b6754a4816961c65ea76e6368e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d44984a06f0489aa2f5cf44ec94d112","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73ea5c6898134be292c9559afc8201bd","value":0}},"1cf3e14913e74958a1b5d0453a3a8be6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"261d3c9cb1b142ebbff2e3d0098ad599":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0619950dfc8441a08c3d501226374cee","placeholder":"","style":"IPY_MODEL_ad7fa10fa9f342e1adfe9a9ee29da91d","value":"100%"}},"3041c773cfd344f39ab8e3c0eb917fe2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3119d29894d54b219d400a82f1c7040a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_668adb5e9fb645088bc2a794ba2218ce","placeholder":"","style":"IPY_MODEL_f8ddad473d2b4a66b3b16e4979fc31a9","value":"20/20[02:50&lt;00:00,8.37s/it]"}},"3c0341b996374df6b2ec05c8dac7a9b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_261d3c9cb1b142ebbff2e3d0098ad599","IPY_MODEL_de034decd79643eda084b3e563e2c1b9","IPY_MODEL_95ec778bedfb445487d331eda0258ff2"],"layout":"IPY_MODEL_f04623277a3043e892c87a9d5833b792"}},"3f145d6039234d51ad1b12a7598c31ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40c7957c4c7744bc8a3a576f0bf6cae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fcf225e3f414285bb25e16d8565f4ab","placeholder":"","style":"IPY_MODEL_e7bb5d3b6b364c39894e73eee97affe0","value":"100%"}},"4321149fa4db4cf8a4273d27b492e499":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6daa25dc2c0241d88866c7e9f1fd3968","placeholder":"","style":"IPY_MODEL_1093b31ac743463a8d09fc710233e45e","value":"0/30[00:04&lt;?,?it/s]"}},"4733ff38e6f54f72a8dca7b6d1d6e1f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd9473ac34347508ec6f23534b463b2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d21484dba744589823686ea95ce27f8","value":41}},"4d44984a06f0489aa2f5cf44ec94d112":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521788e7ab614c4bb1ec45d9853678db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d18c07c8179043df9447c93111a31dd0","IPY_MODEL_4733ff38e6f54f72a8dca7b6d1d6e1f5","IPY_MODEL_71a09f42d1f34c5faf7c012fbfe5fc1e"],"layout":"IPY_MODEL_f7ded3abfb644ed3aaa967d1bc313eb6"}},"5b30a7a67a894cffaa069bf252ccd513":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40c7957c4c7744bc8a3a576f0bf6cae3","IPY_MODEL_0ab5b022aa5a419481a0e99ed82ef986","IPY_MODEL_3119d29894d54b219d400a82f1c7040a"],"layout":"IPY_MODEL_3f145d6039234d51ad1b12a7598c31ed"}},"5b8080aef9a0413ea8d1f39245c1d35e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"668adb5e9fb645088bc2a794ba2218ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5d0a75de624cc5a80388acd0cafad1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6daa25dc2c0241d88866c7e9f1fd3968":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708edf09837642f58a4feaa64500ed66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71a09f42d1f34c5faf7c012fbfe5fc1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5d0a75de624cc5a80388acd0cafad1","placeholder":"","style":"IPY_MODEL_84f66999ecb34dd284cbb5b1961e009c","value":"41/50[07:47&lt;01:42,11.43s/it]"}},"7391de2c8cd74cf4926965845e9fed5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c6ed142a9a84a25a79130c1c4b36aaa","IPY_MODEL_1c7f75b6754a4816961c65ea76e6368e","IPY_MODEL_4321149fa4db4cf8a4273d27b492e499"],"layout":"IPY_MODEL_b6ae5d93eee346aeae217dd8721b0998"}},"73ea5c6898134be292c9559afc8201bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b39c4ee962d4b019efe256eb5bc4b42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cd9473ac34347508ec6f23534b463b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f66999ecb34dd284cbb5b1961e009c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ec778bedfb445487d331eda0258ff2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3041c773cfd344f39ab8e3c0eb917fe2","placeholder":"","style":"IPY_MODEL_1cf3e14913e74958a1b5d0453a3a8be6","value":"40/40[05:53&lt;00:00,8.80s/it]"}},"9c6ed142a9a84a25a79130c1c4b36aaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b8080aef9a0413ea8d1f39245c1d35e","placeholder":"","style":"IPY_MODEL_f50365a5670642eba65844a398822e12","value":"0%"}},"9fcf225e3f414285bb25e16d8565f4ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7fa10fa9f342e1adfe9a9ee29da91d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6ae5d93eee346aeae217dd8721b0998":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3db436601d4c7ba7a8f98441d17bb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4884041d23241fc98ab49a7f1ae0d7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d18c07c8179043df9447c93111a31dd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_febae8e0d3764652bbf57351fbfb5041","placeholder":"","style":"IPY_MODEL_7b39c4ee962d4b019efe256eb5bc4b42","value":"82%"}},"de034decd79643eda084b3e563e2c1b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3db436601d4c7ba7a8f98441d17bb3","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4884041d23241fc98ab49a7f1ae0d7b","value":40}},"e7bb5d3b6b364c39894e73eee97affe0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f04623277a3043e892c87a9d5833b792":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50365a5670642eba65844a398822e12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7ded3abfb644ed3aaa967d1bc313eb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8ddad473d2b4a66b3b16e4979fc31a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"febae8e0d3764652bbf57351fbfb5041":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}
